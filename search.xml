<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>十、证书可用时间修改</title>
    <url>/2020/03/10/kubernetes%E7%AC%94%E8%AE%B0/10.%E8%AF%81%E4%B9%A6%E5%8F%AF%E7%94%A8%E6%97%B6%E9%97%B4%E4%BF%AE%E6%94%B9/</url>
    <content><![CDATA[<p>70：本来 k8s 更新的时候会自动更新证书，每年一更新的话就不用考虑可用时间的问题了。这里为了考虑离线等情况，直接进行 kubeadm 可用时间的修改。</p>
<a id="more"></a>
<p><strong>1. go 环境部署</strong></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> wget https://dl.google.com/go/go1.12.7.linux-amd64.tar.gz</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> tar -zxvf go1.12.1.linux-amd64.tar.gz -C /usr/<span class="built_in">local</span></span></span><br><span class="line"><span class="meta">$</span><span class="bash"> vi /etc/profile</span></span><br><span class="line">    export PATH=$PATH:/usr/local/go/bin</span><br><span class="line"><span class="meta">$</span><span class="bash"> <span class="built_in">source</span> /etc/profile</span></span><br></pre></td></tr></table></figure>

<p><strong>2. 下载源码</strong></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> mkdir /root</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> <span class="built_in">cd</span> /data &amp;&amp; git <span class="built_in">clone</span> https://github.com/kubernetes/kubernetes.git</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> <span class="built_in">cd</span> kubernetes</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> git checkout -b remotes/origin/release-1.15.1 v1.15.1</span></span><br></pre></td></tr></table></figure>

<p><strong>3. 修改 kubeadm 源码包更新证书策略</strong></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> vim staging/src/k8s.io/client-go/util/cert/cert.go <span class="comment"># kubeadm 1.14 版本之前</span></span></span><br><span class="line"><span class="meta">$</span><span class="bash"> vim cmd/kubeadm/app/util/pkiutil/pki_helpers.go <span class="comment"># kubeadm 1.14 至今(查看开发者手册)</span></span></span><br><span class="line">    const duration365d = time.Hour * 24 * 365 * 100</span><br><span class="line">    NotAfter: time.Now().Add(duration365d).UTC(),</span><br><span class="line"><span class="meta">$</span><span class="bash"> make WHAT=cmd/kubeadm GOFLAGS=-v</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> cp _output/bin/kubeadm /root/kubeadm-new</span></span><br></pre></td></tr></table></figure>

<p><strong>4. 更新 kubeadm</strong></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 将 kubeadm 进行替换</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> cp /usr/bin/kubeadm /usr/bin/kubeadm.old</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> cp /root/kubeadm-new /usr/bin/kubeadm</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> chmod a+x /usr/bin/kubeadm</span></span><br></pre></td></tr></table></figure>

<p><strong>5. 更新各节点证书至 Master 节点</strong></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> cp -r /etc/kubernetes/pki /etc/kubernetes/pki.old</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> <span class="built_in">cd</span> /etc/kubernetes/pki</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> kubeadm alpha certs renew all --config=/root/kubeadm-config.yaml</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> openssl x509 -<span class="keyword">in</span> apiserver.crt -text -noout | grep Not</span></span><br></pre></td></tr></table></figure>

<p><strong>6. HA 集群其余 master 节点证书更新</strong></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">!/bin/bash</span></span><br><span class="line">masterNode="192.168.66.20 192.168.66.21"</span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="keyword">for</span> host <span class="keyword">in</span> <span class="variable">$&#123;masterNode&#125;</span>; <span class="keyword">do</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> scp /etc/kubernetes/pki/&#123;ca.crt,ca.key,sa.key,sa.pub,front-proxy-ca.crt,front-proxy-ca.key&#125;</span></span><br><span class="line">"$&#123;USER&#125;"@$host:/etc/kubernetes/pki/</span><br><span class="line"><span class="meta">#</span><span class="bash"> scp /etc/kubernetes/pki/etcd/&#123;ca.crt,ca.key&#125; <span class="string">"root"</span>@<span class="variable">$host</span>:/etc/kubernetes/pki/etcd</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> scp /etc/kubernetes/admin.conf <span class="string">"root"</span>@<span class="variable">$host</span>:/etc/kubernetes/</span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="keyword">done</span></span></span><br><span class="line">for host in $&#123;CONTROL_PLANE_IPS&#125;; do</span><br><span class="line">    scp /etc/kubernetes/pki/&#123;ca.crt,ca.key,sa.key,sa.pub,front-proxy-ca.crt,front-proxy-ca.key&#125; "$&#123;USER&#125;"@$host:/root/pki/</span><br><span class="line">    scp /etc/kubernetes/pki/etcd/&#123;ca.crt,ca.key&#125; "root"@$host:/root/etcd</span><br><span class="line">    scp /etc/kubernetes/admin.conf "root"@$host:/root/kubernetes/</span><br><span class="line">done</span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>Kubernetes</category>
      </categories>
  </entry>
  <entry>
    <title>九、Helm 及其他功能性组件</title>
    <url>/2020/03/09/kubernetes%E7%AC%94%E8%AE%B0/9.Helm%E5%8F%8A%E5%85%B6%E5%AE%83%E5%8A%9F%E8%83%BD%E6%80%A7%E7%BB%84%E4%BB%B6/</url>
    <content><![CDATA[<h1 id="1-部署-Helm-哈"><a href="#1-部署-Helm-哈" class="headerlink" title="1. 部署 Helm 哈"></a>1. 部署 Helm 哈</h1><h2 id="1-1-Helm-介绍"><a href="#1-1-Helm-介绍" class="headerlink" title="1.1 Helm 介绍"></a>1.1 Helm 介绍</h2><p> 在没使用 Helm 之前，向 kubernetes 部署应用，我们要依次部署 deployment、svc 等，步骤较繁琐。况且随着很多项目微服务化，复杂的应用在容器中部署以及管理显得较为复杂，<strong>Helm 通过打包的方式，支持发布的版本管理和控制，很大程度上简化了 Kubernetes 应用的部署和管理</strong>。</p>
<a id="more"></a>
<p><strong>Helm 本质就是让 K8s 的应用管理（Deployment,Service 等 ) 可配置，能动态生成。通过动态生成 K8s 资源清单文件（deployment.yaml，service.yaml）。然后调用 Kubectl 自动执行 K8s 资源部署。</strong></p>
<p><strong>Helm 是官方提供的类似于 YUM 的包管理器，是部署环境的流程封装。</strong>Helm 有<strong>两个重要的概念：**</strong>chart** 和 <strong>release</strong>：</p>
<ul>
<li><strong>chart 是创建一个应用的信息集合，包括各种 Kubernetes 对象的配置模板、参数定义、依赖关系、文档说明等。chart 是应用部署的自包含逻辑单元。可以将 chart 想象成 apt、yum 中的软件安装包。</strong></li>
<li><strong>release 是 chart 的运行实例，代表了一个正在运行的应用。当 chart 被安装到 Kubernetes 集群，就生成一个 release。chart 能够多次安装到同一个集群，每次安装都是一个 release。</strong></li>
</ul>
<p>Helm 包含<strong>两个组件</strong>：<strong>Helm 客户端</strong>和 <strong>Tiller 服务器</strong>，如下图所示：</p>
<img src="https://blog-love70-img.oss-cn-chengdu.aliyuncs.com/blog.love70.cn/image-20200324100118023.png" alt="image-20200324100118023" style="zoom:50%;" />

<p><strong>Helm 客户端负责 chart 和 release 的创建和管理以及和 Tiller 的交互。Tiller 服务器运行在 Kubernetes 集群中，它会处理 Helm 客户端的请求，与 Kubernetes API Server 交互。</strong></p>
<h2 id="1-2-Helm-部署"><a href="#1-2-Helm-部署" class="headerlink" title="1.2 Helm 部署"></a>1.2 Helm 部署</h2><p>越来越多的公司和团队开始使用 Helm 这个 Kubernetes 的包管理器，我们也将使用 Helm 安装 Kubernetes 的常用组件。 Helm 由客户端命 helm 令行工具和服务端 tiller 组成，Helm 的安装十分简单。 下载 helm 命令行工具到 master 节点的 /usr/local/bin 下，这里下载的 2.13. 1版本：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> ntpdate ntp1.aliyun.com</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> wget https://storage.googleapis.com/kubernetes-helm/helm-v2.13.1-linux-amd64.tar.gz</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> tar -zxvf helm-v2.13.1-linux-amd64.tar.gz</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> <span class="built_in">cd</span> linux-amd64/</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> cp -a helm /usr/<span class="built_in">local</span>/bin/</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> chmod a+x /usr/<span class="built_in">local</span>/bin/helm</span></span><br></pre></td></tr></table></figure>

<p>为了安装服务端 tiller，还需要在这台机器上配置好 kubectl 工具和 kubeconfig 文件，确保 kubectl 工具可以在这台机器上访问 apiserver 且正常使用。 这里的 node1 节点以及配置好了 kubectl。</p>
<p>因为 Kubernetes APIServer 开启了 RBAC 访问控制，所以需要创建 tiller 使用的 service account: tiller 并分配合适的角色给它。 详细内容可以查看helm文档中的 <a href="https://docs.helm.sh/using_helm/#role-based-access-control" target="_blank" rel="noopener">Role-based Access Control</a>。 这里简单起见直接分配 cluster- admin 这个集群内置的 ClusterRole 给它。创建 rbac-config.yaml 文件：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ServiceAccount</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">tiller</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">kube-system</span></span><br><span class="line">  </span><br><span class="line"><span class="meta">---</span></span><br><span class="line"></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ClusterRoleBinding</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">tiller</span></span><br><span class="line"><span class="attr">roleRef:</span></span><br><span class="line">  <span class="attr">apiGroup:</span> <span class="string">rbac.authorization.k8s.io</span></span><br><span class="line">  <span class="attr">kind:</span> <span class="string">ClusterRole</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">cluster-admin</span></span><br><span class="line"><span class="attr">subjects:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">kind:</span> <span class="string">ServiceAccount</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">tiller</span></span><br><span class="line">    <span class="attr">namespace:</span> <span class="string">kube-system</span></span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> kubectl create -f rbac-config.yaml</span></span><br><span class="line">serviceaccount/tiller created</span><br><span class="line">clusterrolebinding.rbac.authorization.k8s.io/tiller created</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> helm init --service-account tiller --skip-refresh</span></span><br></pre></td></tr></table></figure>

<p><strong>tiller 默认被部署在 k8s 集群中的 kube-system 这个 namespace 下</strong></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> kubectl get pod -n kube-system</span></span><br><span class="line">NAME                                   READY   STATUS    RESTARTS   AGE</span><br><span class="line">tiller-deploy-58565b5464-wcffm         1/1     Running   0          3h58m</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> helm version</span></span><br><span class="line">Client: &amp;version.Version&#123;SemVer:"v2.13.1", GitCommit:"618447cbf203d147601b4b9bd7f8c37a5d39fbb4", GitTreeState:"clean"&#125;</span><br><span class="line">Server: &amp;version.Version&#123;SemVer:"v2.13.1", GitCommit:"618447cbf203d147601b4b9bd7f8c37a5d39fbb4", GitTreeState:"clean"&#125;</span><br></pre></td></tr></table></figure>



<h2 id="1-3-Helm-Hub"><a href="#1-3-Helm-Hub" class="headerlink" title="1.3 Helm Hub"></a>1.3 Helm Hub</h2><p><strong>Helm Hub:</strong> <a href="https://hub.helm.sh/" target="_blank" rel="noopener">https://hub.helm.sh/</a></p>
<h2 id="1-4-Helm-自定义模板"><a href="#1-4-Helm-自定义模板" class="headerlink" title="1.4 Helm 自定义模板"></a>1.4 Helm 自定义模板</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 创建文件夹</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> mkdir ./hello-world</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> <span class="built_in">cd</span> ./hello-world</span></span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 创建自描述文件 Chart.yaml , 这个文件必须有 name 和 version 定义</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> cat &lt;&lt;<span class="string">'EOF'</span> &gt; ./Chart.yaml</span></span><br><span class="line">name: hello-world</span><br><span class="line">version: 1.0.0</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 创建模板文件， 用于生成 Kubernetes 资源清单（manifests）</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> mkdir ./templates</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> cat &lt;&lt;<span class="string">'EOF'</span> &gt; ./templates/deployment.yaml</span></span><br><span class="line">apiVersion: extensions/v1beta1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: hello-world</span><br><span class="line">spec:</span><br><span class="line">  replicas: 1</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: hello-world</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">        - name: hello-world</span><br><span class="line">          image: wangyanglinux/myapp:v1</span><br><span class="line">          ports:</span><br><span class="line">            - containerPort: 80</span><br><span class="line">              protocol: TCP</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line"><span class="meta">$</span><span class="bash"> cat &lt;&lt;<span class="string">'EOF'</span> &gt; ./templates/service.yaml</span></span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: hello-world</span><br><span class="line">spec:</span><br><span class="line">  type: NodePort</span><br><span class="line">  ports:</span><br><span class="line">    - port: 80</span><br><span class="line">      targetPort: 80</span><br><span class="line">      protocol: TCP</span><br><span class="line">  selector:</span><br><span class="line">    app: hello-world</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 使用命令 helm install RELATIVE_PATH_TO_CHART 创建一次Release</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> helm install .</span></span><br></pre></td></tr></table></figure>

<p>70：刚开始执行 install 的时候总是失败，好像是sa的问题，最后通过 delete 掉 tiller 的 svc 和 deployment，并删除掉 /root/.helm/ 目录，重新 init 解决了以上问题。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> helm install .</span></span><br><span class="line">Error: no available release name found</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 列出已经部署的 Release</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> helm ls</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 更新</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> helm upgrade xx .</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 查询历史记录</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> helm <span class="built_in">history</span> xxx</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 查询一个特定的 Release 的状态</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> helm status RELEASE_NAME</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 移除所有与这个 Release 相关的 Kubernetes 资源</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> helm delete cautious-shrimp</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> helm rollback RELEASE_NAME REVISION_NUMBER</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> helm rollback cautious-shrimp 1</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 使用 helm delete --purge RELEASE_NAME 移除所有与指定 Release 相关的 Kubernetes 资源和所有这个 Release 的记录</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> helm delete --purge cautious-shrimp</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> helm ls --deleted</span></span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 配置体现在配置文件 values.yaml</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> cat &lt;&lt;<span class="string">'EOF'</span> &gt; ./values.yaml</span></span><br><span class="line">image:</span><br><span class="line">  repository: gcr.io/google-samples/node-hello</span><br><span class="line">  tag: '1.0'</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 这个文件中定义的值，在模板文件中可以通过 .VAlues对象访问到</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> cat &lt;&lt;<span class="string">'EOF'</span> &gt; ./templates/deployment.yaml</span></span><br><span class="line">apiVersion: extensions/v1beta1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: hello-world</span><br><span class="line">spec:</span><br><span class="line">  replicas: 1</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: hello-world</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">        - name: hello-world</span><br><span class="line">          image: &#123;&#123; .Values.image.repository &#125;&#125;:&#123;&#123; .Values.image.tag &#125;&#125;</span><br><span class="line">          ports:</span><br><span class="line">            - containerPort: 80</span><br><span class="line">              protocol: TCP</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 在 values.yaml 中的值可以被部署 release 时用到的参数 --values YAML_FILE_PATH 或 --<span class="built_in">set</span> key1=value1, key2=value2 覆盖掉</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> helm install --<span class="built_in">set</span> image.tag=<span class="string">'latest'</span> .</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 升级版本</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> helm upgrade -f values.yaml <span class="built_in">test</span> .</span></span><br></pre></td></tr></table></figure>

<p><strong>debug</strong></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 使用模板动态生成K8s资源清单，非常需要能提前预览生成的结果。</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 使用--dry-run --debug 选项来打印出生成的清单文件内容，而不执行部署</span></span><br><span class="line">helm install . --dry-run --debug --set image.tag=latest</span><br></pre></td></tr></table></figure>



<h1 id="2-使用-Helm-部署-dashboard"><a href="#2-使用-Helm-部署-dashboard" class="headerlink" title="2. 使用 Helm 部署 dashboard"></a>2. 使用 Helm 部署 dashboard</h1><p>kubernetes-dashboard.yaml</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">image:</span></span><br><span class="line">  <span class="attr">repository:</span> <span class="string">k8s.gcr.io/kubernetes-dashboard-amd64</span></span><br><span class="line">  <span class="attr">tag:</span> <span class="string">v1.10.1</span></span><br><span class="line"><span class="attr">ingress:</span></span><br><span class="line">  <span class="attr">enabled:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">hosts:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">k8s.frognew.com</span></span><br><span class="line">  <span class="attr">annotations:</span></span><br><span class="line">    <span class="attr">nginx.ingress.kubernetes.io/ssl-redirect:</span> <span class="string">"true"</span></span><br><span class="line">    <span class="attr">nginx.ingress.kubernetes.io/backend-protocol:</span> <span class="string">"HTTPS"</span></span><br><span class="line">  <span class="attr">tls:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">secretName:</span> <span class="string">frognew-com-tls-secret</span></span><br><span class="line">      <span class="attr">hosts:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="string">k8s.frognew.com</span></span><br><span class="line"><span class="attr">rbac:</span></span><br><span class="line">  <span class="attr">clusterAdminRole:</span> <span class="literal">true</span></span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> helm repo update</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 使用原有源在update时会卡住，可以将其配置为国内源</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 删除默认的源</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> helm repo remove stable</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 添加国内源</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> helm repo add stable https://burdenbear.github.io/kube-charts-mirror/</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 或者</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> helm repo add stable https://kubernetes.oss-cn-hangzhou.aliyuncs.com/charts</span></span><br><span class="line"></span><br><span class="line"><span class="meta">$</span><span class="bash"> helm repo list</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> helm fetch stable/kubernetes-dashboard</span></span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> helm install stable/kubernetes-dashboard \</span></span><br><span class="line">-n kubernetes-dashboard \</span><br><span class="line">--namespace kube-system \</span><br><span class="line">-f kubernetes-dashboard.yaml</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> kubectl edit svc kubernetes-dashboard -n kube-system</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 修改 ClusterIP 为 NodePort</span></span><br></pre></td></tr></table></figure>

<p>70：注意：部署完成后使用火狐浏览器进行访问，并且使用 https 进行访问。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> kubectl -n kube-system get secret | grep kubernetes-dashboard-token</span></span><br><span class="line">kubernetes-dashboard-token-sj8gj     kubernetes.io/service-account-token   3      20m</span><br><span class="line"></span><br><span class="line"><span class="meta">$</span><span class="bash"> kubectl describe secret kubernetes-dashboard-token-sj8gj -n kube-system</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 复制token进行登录</span></span><br></pre></td></tr></table></figure>



<h1 id="3-使用-Helm-部署-metrics-server"><a href="#3-使用-Helm-部署-metrics-server" class="headerlink" title="3. 使用 Helm 部署 metrics-server"></a>3. 使用 Helm 部署 metrics-server</h1><p>70: Prometheus 中包含了一个 metric-server，所以不需要再单独安装一个了。</p>
<p>从 Heapster 的 <a href="https://github.com/kubernetes/heapster" target="_blank" rel="noopener">github</a> 中可以看到已经，heapster 已经DEPRECATED。这里是 <a href="https://github.com/kubernetes-retired/heapster/blob/master/docs/deprecation.md" target="_blank" rel="noopener">heapster的deprecation timeline</a>。 可以看出 heapster 从 Kubernetes 1.12 开始将从 Kubernetes 各种安装脚本中移除。<strong>Kubernetes 推荐使用 <a href="https://github.com/kubernetes-sigs/metrics-server" target="_blank" rel="noopener">metrics-server</a>。</strong>我们这里也使用helm来部署metrics-server。</p>
<p>metrics-server.yaml</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">args:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">--logtostderr</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">--kubelet-insecure-tls</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">--kubelet-preferred-address-types=InternalIP</span></span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> helm install stable/metrics-server \</span></span><br><span class="line">-n metrics-server \</span><br><span class="line">--namespace kube-system \</span><br><span class="line">-f metrics-server.yaml</span><br></pre></td></tr></table></figure>

<p>使用下面的命令可以获取到关于集群节点基本的指标信息：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> kubectl top node</span></span><br><span class="line">NAME           CPU(cores)   CPU%   MEMORY(bytes)   MEMORY%   </span><br><span class="line">k8s-master01   171m         8%     1285Mi          68%       </span><br><span class="line">k8s-node01     163m         8%     1507Mi          39%</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> kubectl top pod --all-namespaces</span></span><br><span class="line">NAMESPACE       NAME                                        CPU(cores)   MEMORY(bytes) </span><br><span class="line">default         dashtest1-dbdb459cf-2f7qb                   0m           1Mi           </span><br><span class="line">ingress-nginx   nginx-ingress-controller-7fcf8df75d-wstjz   1m           97Mi         </span><br><span class="line">kube-system     coredns-5c98db65d4-bmrgj                    5m           27Mi         </span><br><span class="line">kube-system     coredns-5c98db65d4-qdxvg                    5m           14Mi         </span><br><span class="line">kube-system     etcd-k8s-master01                           26m          138Mi         </span><br><span class="line">kube-system     kube-apiserver-k8s-master01                 45m          548Mi         </span><br><span class="line">kube-system     kube-controller-manager-k8s-master01        19m          99Mi         </span><br><span class="line">kube-system     kube-flannel-ds-amd64-snh7z                 2m           10Mi         </span><br><span class="line">kube-system     kube-flannel-ds-amd64-zxffq                 2m           23Mi         </span><br><span class="line">kube-system     kube-proxy-ffq2n                            2m           18Mi         </span><br><span class="line">kube-system     kube-proxy-tttbg                            2m           32Mi         </span><br><span class="line">kube-system     kube-scheduler-k8s-master01                 1m           32Mi         </span><br><span class="line">kube-system     kubernetes-dashboard-6f5b7fcbb-96ksm        0m           12Mi         </span><br><span class="line">kube-system     tiller-deploy-58565b5464-2ttzz              0m           44Mi         </span><br><span class="line">monitoring      alertmanager-main-0                         3m           15Mi         </span><br><span class="line">monitoring      alertmanager-main-1                         3m           17Mi         </span><br><span class="line">monitoring      alertmanager-main-2                         2m           15Mi         </span><br><span class="line">monitoring      grafana-7dc5f8f9f6-m8tbb                    1m           29Mi         </span><br><span class="line">monitoring      kube-state-metrics-56998d67b9-m7qm9         0m           43Mi         </span><br><span class="line">monitoring      node-exporter-69rqn                         1m           26Mi         </span><br><span class="line">monitoring      node-exporter-trq59                         0m           17Mi         </span><br><span class="line">monitoring      prometheus-adapter-668748ddbd-xp6d8         0m           11Mi         </span><br><span class="line">monitoring      prometheus-k8s-0                            34m          247Mi         </span><br><span class="line">monitoring      prometheus-k8s-1                            36m          241Mi         </span><br><span class="line">monitoring      prometheus-operator-7447bf4dcb-rbr96        1m           23Mi</span><br></pre></td></tr></table></figure>



<h1 id="4-部署-Prometheus"><a href="#4-部署-Prometheus" class="headerlink" title="4. 部署 Prometheus"></a>4. 部署 Prometheus</h1><h2 id="4-1-Prometheus-介绍"><a href="#4-1-Prometheus-介绍" class="headerlink" title="4.1 Prometheus 介绍"></a>4.1 Prometheus 介绍</h2><p>Prometheus github 地址：<a href="https://github.com/coreos/kube-prometheus" target="_blank" rel="noopener">https://github.com/coreos/kube-prometheus</a></p>
<p>组件说明：</p>
<ul>
<li>MetricServer：是 kubernetes 集群资源使用情况的聚合器，收集数据给 kubernetes 集群内使用，如kubectl，hpa，scheduler 等。</li>
<li>PrometheusOperator：是一个系统监测和警报工具箱，用来存储监控数据。</li>
<li>NodeExporter：用于各 node 的关键度量指标状态数据。</li>
<li>KubeStateMetrics：收集 kubernetes 集群内资源对象数据，制定告警规则。</li>
<li>Prometheus：采用 pull 方式收集 apiserver，scheduler，controller-manager，kubelet 组件数据，通过http 协议传输。</li>
<li>Grafana：是可视化数据统计和监控平台。</li>
</ul>
<h2 id="4-2-安装"><a href="#4-2-安装" class="headerlink" title="4.2 安装"></a>4.2 安装</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> git <span class="built_in">clone</span> https://github.com/coreos/kube-prometheus.git</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> <span class="built_in">cd</span> /kube-prometheus/manifests</span></span><br></pre></td></tr></table></figure>

<p>修改 grafana-service.yaml 文件，使用 nodeport 方式访问 granfana：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">grafana</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">monitoring</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">type:</span> <span class="string">NodePort</span> <span class="comment">#添加内容</span></span><br><span class="line">  <span class="attr">ports:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">http</span></span><br><span class="line">      <span class="attr">port:</span> <span class="number">3000</span></span><br><span class="line">      <span class="attr">targetPort:</span> <span class="string">http</span></span><br><span class="line">      <span class="attr">nodePort:</span> <span class="number">30100</span> <span class="comment">#添加内容</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">grafana</span></span><br></pre></td></tr></table></figure>

<p>修改 prometheus-service.yaml，改为 nodeport：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">prometheus:</span> <span class="string">k8s</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">prometheus-k8s</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">monitoring</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">type:</span> <span class="string">NodePort</span></span><br><span class="line">  <span class="attr">ports:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">web</span></span><br><span class="line">      <span class="attr">port:</span> <span class="number">9090</span></span><br><span class="line">      <span class="attr">targetPort:</span> <span class="string">web</span></span><br><span class="line">      <span class="attr">nodePort:</span> <span class="number">30200</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">prometheus</span></span><br><span class="line">    <span class="attr">prometheus:</span> <span class="string">k8s</span></span><br></pre></td></tr></table></figure>

<p>修改 alertmanager-service.yaml，改为 nodeport：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">alertmanager:</span> <span class="string">main</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">alertmanager-main</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">monitoring</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">type:</span> <span class="string">NodePort</span></span><br><span class="line">  <span class="attr">ports:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">web</span></span><br><span class="line">      <span class="attr">port:</span> <span class="number">9093</span></span><br><span class="line">      <span class="attr">targetPort:</span> <span class="string">web</span></span><br><span class="line">      <span class="attr">nodePort:</span> <span class="number">30300</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">alertmanager:</span> <span class="string">main</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">alertmanager</span></span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> Create the namespace and CRDs, and <span class="keyword">then</span> <span class="built_in">wait</span> <span class="keyword">for</span> them to be availble before creating the remaining resources</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> kubectl create -f manifests/setup</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> kubectl create -f manifests/</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> until kubectl get servicemonitors --all-namespaces ; <span class="keyword">do</span> date; sleep 1; <span class="built_in">echo</span> <span class="string">""</span>; <span class="keyword">done</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 删除</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> kubectl delete --ignore-not-found=<span class="literal">true</span> -f manifests/ -f manifests/setup</span></span><br></pre></td></tr></table></figure>



<h2 id="4-3-Horizontal-Pod-Autoscaling"><a href="#4-3-Horizontal-Pod-Autoscaling" class="headerlink" title="4.3 Horizontal Pod Autoscaling"></a>4.3 Horizontal Pod Autoscaling</h2><p><strong>Horizontal Pod Autoscaling 可以根据 CPU 利用率自动伸缩一个 Replication Controller、Deployment 或者Replica Set 中的 Pod 数量。</strong></p>
<p>70：目前 HPA 稳定版仅支持根据 CPU 和 内存来自动伸缩。</p>
<p>为了演示 Horizontal Pod Autoscaling，我们将使用一个基于 php-apache 镜像的定制 Docker 镜像。在<a href="https://k8smeetup.github.io/docs/user-guide/horizontal-pod-autoscaling/image/Dockerfile" target="_blank" rel="noopener">这里</a>可以查看完整的 Dockerfile 定义。镜像中包括一个 <a href="https://k8smeetup.github.io/docs/user-guide/horizontal-pod-autoscaling/image/index.php" target="_blank" rel="noopener">index.php</a> 页面，其中包含了一些可以运行 CPU 密集计算任务的代码。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> kubectl run php-apache --image=gcr.io/google_containers/hpa-example:latest  \</span></span><br><span class="line">--image-pull-policy=IfNotPresent --requests=cpu=200m --expose --port=80</span><br></pre></td></tr></table></figure>

<p>创建 HPA 控制器 - 相关算法的详情请参阅<a href="https://github.com/kubernetes/community/blob/master/contributors/design-proposals/horizontal-pod-autoscaler.md#autoscaling-algorithm" target="_blank" rel="noopener">这篇文档</a></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> kubectl autoscale deployment php-apache --cpu-percent=50 --min=1 --max=10</span></span><br></pre></td></tr></table></figure>

<p>增加负载</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> kubectl run -i --tty load-generator --image=busybox /bin/sh</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> <span class="keyword">while</span> <span class="literal">true</span>; <span class="keyword">do</span> wget -q -O- http://php-apache.default.svc.cluster.local; <span class="keyword">done</span></span></span><br></pre></td></tr></table></figure>

<p>查看负载节点数目</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> kubectl get hpa -w</span></span><br><span class="line">NAME         REFERENCE               TARGETS   MINPODS   MAXPODS   REPLICAS   AGE</span><br><span class="line">php-apache   Deployment/php-apache   0%/50%    1         10        1          4m20s</span><br><span class="line">php-apache   Deployment/php-apache   0%/50%    1         10        1          4m33s</span><br><span class="line">php-apache   Deployment/php-apache   329%/50%   1         10        1          6m9s</span><br><span class="line">php-apache   Deployment/php-apache   329%/50%   1         10        4          6m25s</span><br><span class="line">php-apache   Deployment/php-apache   246%/50%   1         10        7          6m40s</span><br><span class="line">php-apache   Deployment/php-apache   146%/50%   1         10        7          7m12s</span><br><span class="line">php-apache   Deployment/php-apache   146%/50%   1         10        9          7m27s</span><br><span class="line">php-apache   Deployment/php-apache   149%/50%   1         10        9          7m42s</span><br><span class="line">php-apache   Deployment/php-apache   126%/50%   1         10        9          8m13s</span><br></pre></td></tr></table></figure>



<h2 id="4-4-资源限制-Pod"><a href="#4-4-资源限制-Pod" class="headerlink" title="4.4 资源限制 - Pod"></a>4.4 资源限制 - Pod</h2><p><strong>Kubernetes 对资源的限制实际上是通过 cgroup 来控制的，cgroup 是容器的一组用来控制内核如何运行进程的相关属性集合。针对内存、CPU 和各种设备都有对应的 cgroup。</strong></p>
<p><strong>默认情况下，Pod 运行没有 CPU 和内存的限额。 这意味着系统中的任何 Pod 将能够像执行该 Pod 所在的节点一样，消耗足够多的 CPU 和内存 。一般会针对某些应用的 pod 资源进行资源限制，这个资源限制是通过 resources 的 requests 和 limits 来实现。</strong></p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">image:</span> <span class="string">xxxx</span></span><br><span class="line">      <span class="attr">imagePullPolicy:</span> <span class="string">Always</span></span><br><span class="line">      <span class="attr">name:</span> <span class="string">auth</span></span><br><span class="line">      <span class="attr">ports:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">8080</span></span><br><span class="line">          <span class="attr">protocol:</span> <span class="string">TCP</span></span><br><span class="line">      <span class="attr">resources:</span></span><br><span class="line">        <span class="attr">limits:</span></span><br><span class="line">          <span class="attr">cpu:</span> <span class="string">"4"</span></span><br><span class="line">          <span class="attr">memory:</span> <span class="string">2Gi</span></span><br><span class="line">        <span class="attr">requests:</span></span><br><span class="line">          <span class="attr">cpu:</span> <span class="string">250m</span></span><br><span class="line">          <span class="attr">memory:</span> <span class="string">250Mi</span></span><br></pre></td></tr></table></figure>

<p><strong>requests 要分分配的资源，limits 为最高请求的资源值。可以简单理解为初始值和最大值。</strong></p>
<h2 id="4-5-资源限制-名称空间"><a href="#4-5-资源限制-名称空间" class="headerlink" title="4.5 资源限制 - 名称空间"></a>4.5 资源限制 - 名称空间</h2><p><strong>Ⅰ、计算资源配额</strong></p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ResourceQuota</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">compute-resources</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">spark-cluster</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">hard:</span></span><br><span class="line">    <span class="attr">pods:</span> <span class="string">"20"</span></span><br><span class="line">    <span class="attr">requests.cpu:</span> <span class="string">"20"</span></span><br><span class="line">    <span class="attr">requests.memory:</span> <span class="string">100Gi</span></span><br><span class="line">    <span class="attr">limits.cpu:</span> <span class="string">"40"</span></span><br><span class="line">    <span class="attr">limits.memory:</span> <span class="string">200Gi</span></span><br></pre></td></tr></table></figure>

<p><strong>Ⅱ、配置对象数量配额限制</strong></p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ResourceQuota</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">object-counts</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">spark-cluster</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">hard:</span></span><br><span class="line">    <span class="attr">configmaps:</span> <span class="string">"10"</span></span><br><span class="line">    <span class="attr">persistentvolumeclaims:</span> <span class="string">"4"</span></span><br><span class="line">    <span class="attr">replicationcontrollers:</span> <span class="string">"20"</span></span><br><span class="line">    <span class="attr">secrets:</span> <span class="string">"10"</span></span><br><span class="line">    <span class="attr">services:</span> <span class="string">"10"</span></span><br><span class="line">    <span class="attr">services.loadbalancers:</span> <span class="string">"2"</span></span><br></pre></td></tr></table></figure>

<p><strong>Ⅲ、配置 CPU 和 内存 LimitRange</strong></p>
<p>70：设置 Pod 使用的默认值（Pod 中没有 resource 字段）</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">LimitRange</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">mem-limit-range</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">limits:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">default:</span></span><br><span class="line">        <span class="attr">memory:</span> <span class="string">50Gi</span></span><br><span class="line">        <span class="attr">cpu:</span> <span class="number">5</span></span><br><span class="line">      <span class="attr">defaultRequest:</span></span><br><span class="line">        <span class="attr">memory:</span> <span class="string">1Gi</span></span><br><span class="line">        <span class="attr">cpu:</span> <span class="number">1</span></span><br><span class="line">      <span class="attr">type:</span> <span class="string">Container</span></span><br></pre></td></tr></table></figure>

<ul>
<li><strong>default 即 limit 的值</strong></li>
<li><strong>defaultRequest 即 request 的值</strong></li>
</ul>
<h2 id="4-6-访问-prometheus"><a href="#4-6-访问-prometheus" class="headerlink" title="4.6 访问 prometheus"></a>4.6 访问 prometheus</h2><p>prometheus 对应的 nodeport 端口为 30200，访问 <a href="http://MasterIP:30200" target="_blank" rel="noopener">http://MasterIP:30200</a></p>
<p><img src="https://blog-love70-img.oss-cn-chengdu.aliyuncs.com/blog.love70.cn/image-20200326004348070.png" alt="image-20200326004348070"></p>
<p>通过访问 <a href="http://MasterIP:30200/target" target="_blank" rel="noopener">http://MasterIP:30200/target</a> 可以看到 prometheus 已经成功连接上了 k8s 的 apiserver</p>
<p><img src="https://blog-love70-img.oss-cn-chengdu.aliyuncs.com/blog.love70.cn/image-20200326004526310.png" alt="image-20200326004526310"></p>
<p>查看 service-discovery</p>
<p><img src="https://blog-love70-img.oss-cn-chengdu.aliyuncs.com/blog.love70.cn/image-20200326004713280.png" alt="image-20200326004713280"></p>
<p>Prometheus 自己的指标</p>
<p><img src="https://blog-love70-img.oss-cn-chengdu.aliyuncs.com/blog.love70.cn/image-20200326005517420.png" alt="image-20200326004946636"></p>
<p>prometheus 的 WEB 界面上提供了基本的查询 K8S 集群中每个 POD 的 CPU 使用情况，查询条件如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sum by (pod_name)( rate(container_cpu_usage_seconds_total&#123;image!&#x3D;&quot;&quot;, pod_name!&#x3D;&quot;&quot;&#125;[1m] ) )</span><br></pre></td></tr></table></figure>

<p><img src="https://blog-love70-img.oss-cn-chengdu.aliyuncs.com/blog.love70.cn/image-20200326004946636.png" alt="image-20200326005305683"></p>
<p>上述的查询有出现数据，说明 node-exporter 往 prometheus 中写入数据正常，接下来我们就可以部署<br>grafana 组件，实现更友好的 webui 展示数据了。</p>
<h2 id="4-7-访问-grafana"><a href="#4-7-访问-grafana" class="headerlink" title="4.7 访问 grafana"></a>4.7 访问 grafana</h2><p>查看 grafana 服务暴露的端口号：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> kubectl get service -n monitoring | grep grafana</span></span><br><span class="line">grafana         NodePort    10.108.240.126   &lt;none&gt;        3000:30100/TCP      23m</span><br></pre></td></tr></table></figure>

<p>如上可以看到 grafana 的端口号是 30100，浏览器访问 <a href="http://MasterIP:30100" target="_blank" rel="noopener">http://MasterIP:30100</a> 用户名密码默认 admin/admin</p>
<p><img src="https://blog-love70-img.oss-cn-chengdu.aliyuncs.com/blog.love70.cn/image-20200326005305683.png" alt="image-20200326005517420"></p>
<p>修改密码并登陆</p>
<p><img src="https://blog-love70-img.oss-cn-chengdu.aliyuncs.com/blog.love70.cn/image-20200326005654423.png" alt="image-20200326005654423"></p>
<p>添加数据源 grafana 默认已经添加了 Prometheus 数据源，grafana 支持多种时序数据源，每种数据源都有各自的查询编辑器</p>
<p><img src="https://blog-love70-img.oss-cn-chengdu.aliyuncs.com/blog.love70.cn/image-20200326005820423.png" alt="image-20200326005820423"></p>
<p>Prometheus 数据源的相关参数：</p>
<p><img src="https://blog-love70-img.oss-cn-chengdu.aliyuncs.com/blog.love70.cn/image-20200326010214152.png" alt="image-20200326005853710"></p>
<p>目前官方支持了如下几种数据源：</p>
<p><img src="https://blog-love70-img.oss-cn-chengdu.aliyuncs.com/blog.love70.cn/image-20200326005853710.png" alt="image-20200326010214152"></p>
<h1 id="5-部署-EFK-平台"><a href="#5-部署-EFK-平台" class="headerlink" title="5. 部署 EFK 平台"></a>5. 部署 EFK 平台</h1><p>70：日志收集方案 EFK ELK</p>
<p><strong>添加 Google incubator 仓库</strong></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> helm repo add incubator http://storage.googleapis.com/kubernetes-charts-incubator</span></span><br></pre></td></tr></table></figure>

<p><strong>部署 Elasticsearch</strong></p>
<p>70：换源</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> helm repo add stable http://mirror.azure.cn/kubernetes/charts/</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> helm repo add incubator http://mirror.azure.cn/kubernetes/charts-incubator/</span></span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> kubectl create namespace efk</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> helm fetch incubator/elasticsearch</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 根据实验条件修改 values.yaml</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> helm install --name els1 --namespace=efk -f values.yaml incubator/elasticsearch</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> kubectl run cirror-<span class="variable">$RANDOM</span> --rm -it --image=cirros -- /bin/sh</span></span><br><span class="line"><span class="meta">  $</span><span class="bash"> curl Elasticsearch:Port/_cat/nodes</span></span><br></pre></td></tr></table></figure>

<p><strong>部署 Fluentd</strong></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> helm fetch stable/fluentd-elasticsearch</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> vim values.yaml</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 更改其中 Elasticsearch 访问地址</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> helm install --name flu1 --namespace=efk -f values.yaml stable/fluentd-elasticsearch</span></span><br></pre></td></tr></table></figure>

<p><strong>部署 kibana</strong></p>
<p>70：E 和 K 的版本一定要一致</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> helm fetch stable/kibana --version 0.14.8</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> helm install --name kib1 --namespace=efk -f values.yaml stable/kibana --version 0.14.8</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 将 kibana svc 修改为 NodePort</span></span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>Kubernetes</category>
      </categories>
  </entry>
  <entry>
    <title>八、Kubernetes 安全</title>
    <url>/2020/03/08/kubernetes%E7%AC%94%E8%AE%B0/8.Kubernetes%E5%AE%89%E5%85%A8/</url>
    <content><![CDATA[<h1 id="1-机制说明"><a href="#1-机制说明" class="headerlink" title="1. 机制说明"></a>1. 机制说明</h1><p>Kubernetes 作为一个分布式集群的管理工具，保证集群的安全性是其一个重要的任务。<strong>API Server 是集群内部各个组件通信的中介，也是外部控制的入口。</strong>所以 Kubernetes 的安全机制基本就是<strong>围绕保护 API Server 来设计的。</strong>Kubernetes 使用了<strong>认证（Authentication）</strong>、<strong>鉴权（Authorization）</strong>、<strong>准入控制（Admission Control）</strong>三步来保证API Server的安全。</p>
<a id="more"></a>
<img src="https://blog-love70-img.oss-cn-chengdu.aliyuncs.com/blog.love70.cn/image-20200322095843242.png" alt="image-20200322095843242" style="zoom:50%;" />



<h1 id="2-认证-Authentication"><a href="#2-认证-Authentication" class="headerlink" title="2. 认证 Authentication"></a>2. 认证 Authentication</h1><ul>
<li><p><strong>HTTP Token 认证</strong>：通过一个 Token 来识别合法用户</p>
<ul>
<li>HTTP Token 的认证是用一个很长的特殊编码方式的并且难以被模仿的字符串 - Token 来表达客户的一种方式。Token 是一个很长的很复杂的字符串，每一个 Token 对应一个用户名存储在 API Server 能访问的文件中。当客户端发起 API 调用请求时，需要在 HTTP Header 里放入 Token。</li>
</ul>
</li>
<li><p><strong>HTTP Base 认证</strong>：通过 用户名 + 密码 的方式认证</p>
<ul>
<li>用户名 + 密码 用 BASE64 算法进行编码后的字符串放在 HTTP Request 中的 Heather Authorization 域里发送给服务端，服务端收到后进行编码，获取用户名及密码。</li>
</ul>
</li>
<li><p>最严格的 <strong>HTTPS 证书认证</strong>：基于 CA 根证书签名的客户端身份认证方式。</p>
</li>
</ul>
<p><strong>Ⅰ、HTTPS 证书认证</strong></p>
<p>70：双向认证</p>
<p>70：企业基本上会选择 HTTPS 证书认证，安全性</p>
<img src="https://blog-love70-img.oss-cn-chengdu.aliyuncs.com/blog.love70.cn/image-20200322100312353.png" alt="image-20200322100312353" style="zoom:50%;" />

<p><strong>Ⅱ、需要认证的节点</strong></p>
<img src="https://blog-love70-img.oss-cn-chengdu.aliyuncs.com/blog.love70.cn/image-20200322100342463.png" alt="image-20200322100342463" style="zoom:50%;" />

<p>两种类型：</p>
<ul>
<li><strong>Kubenetes 组件对 API Server 的访问：kubectl、Controller Manager、Scheduler、kubelet、kube-proxy</strong></li>
<li><strong>Kubernetes 管理的 Pod 对容器的访问：Pod（dashborad 也是以 Pod 形式运行）</strong></li>
</ul>
<p>安全性说明：</p>
<ul>
<li><strong>Controller Manager、Scheduler 与 API Server 在同一台机器，所以直接使用 API Server 的非安全端口访问， <code>--insecure-bind-address=127.0.0.1</code></strong></li>
<li><strong>kubectl、kubelet、kube-proxy 访问 API Server 就都需要证书进行 HTTPS 双向认证</strong></li>
<li><strong>Pod 访问 API Server，SA</strong></li>
</ul>
<p>证书颁发：</p>
<ul>
<li><strong>手动签发：通过 k8s 集群的跟 ca 进行签发 HTTPS 证书</strong></li>
<li><strong>自动签发：kubelet 首次访问 API Server 时，使用 token 做认证，通过后，Controller Manager 会为kubelet 生成一个证书，以后的访问都是用证书做认证了</strong></li>
</ul>
<p><strong>Ⅲ、kubeconfig</strong></p>
<p><strong>kubeconfig 文件（.kube/config）包含集群参数（CA证书、API Server地址），客户端参数（上面生成的证书和私钥），集群context 信息（集群名称、用户名）。Kubenetes 组件通过启动时指定不同的 kubeconfig 文件可以切换到不同的集群。</strong></p>
<p><strong>Ⅳ、ServiceAccount</strong></p>
<p>Pod 中的容器访问 API Server。因为Pod的创建、销毁是动态的，所以要为它手动生成证书就不可行了。<strong>Kubenetes 使用了 Service Account解决 Pod 访问API Server的认证问题</strong>。</p>
<p><strong>Ⅴ、Secret 与 SA 的关系</strong></p>
<p>Kubernetes 设计了一种资源对象叫做 Secret，分为两类，一种是用于 ServiceAccount 的 service-account-token，另一种是用于保存用户自定义保密信息的 Opaque。ServiceAccount 中用到包含三个部分：Token、ca.crt、namespace。</p>
<ul>
<li><strong>token</strong>是使用 API Server 私钥签名的 JWT。用于访问API Server时，Server端认证</li>
<li><strong>ca.crt</strong>，根证书。用于Client端验证API Server发送的证书</li>
<li><strong>namespace</strong>, 标识这个service-account-token的作用域名空间</li>
</ul>
<p>Json web token（JWT），是为了在网络应用环境间传递声明而执行的一种基于 JSON 的开放标准（RFC 7519），该 token 被设计为紧凑且安全的，特别适用于分布式站点的单点登录（sso）场景。JWT 的声明一般被用来在身份提供者和服务提供者间传递被认证的用户身份信息，以便于从资源服务器获取资源，也可以增加一些额外的其他业务逻辑所必须的声明信息，该 token 也可直接被用于认证，也可被加密。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> kubectl get secret --all-namespaces</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> kubectl describe secret default-token-5gm9r --namespace=kube-system</span></span><br></pre></td></tr></table></figure>

<p>默认情况下，每个 namespace 都会有一个 ServiceAccount，如果 Pod 在创建时没有指定 ServiceAccount，就会使用 Pod 所属的 namespace 的 ServiceAccount。</p>
<p>默认挂载目录：/run/secret/kubernets.io/serviceaccount/</p>
<p><strong>Ⅵ、总结</strong></p>
<img src="https://blog-love70-img.oss-cn-chengdu.aliyuncs.com/blog.love70.cn/image-20200322101017701.png" alt="image-20200322101017701" style="zoom:50%;" />



<h1 id="3-鉴权-Authorization"><a href="#3-鉴权-Authorization" class="headerlink" title="3. 鉴权 Authorization"></a>3. 鉴权 Authorization</h1><p><strong>上面认证过程，只是确认通信的双方都确认了对方是可信的，可以相互通信。而鉴权是确定请求方有哪些资源的权限。</strong>API Server 目前支持以下几种授权策略 （通过 API Server 的启动参数 “–authorization-mode” 设置）</p>
<ul>
<li><strong>AlwaysDeny</strong>：表示拒绝所有的请求，一般用于测试。</li>
<li><strong>AlwaysAllow</strong>：允许接收所有请求，如果集群不需要授权流程，则可以采用该策略。</li>
<li><strong>ABAC（Attribute-Based Access Control</strong>）：基于属性的访问控制，表示使用用户配置的授权规则对用户请求进行匹配和控制。</li>
<li><strong>Webbook</strong>：通过调用外部 REST 服务对用户进行授权。</li>
<li><strong>RBAC（Role-Based Access Control）</strong>：基于角色的访问控制，<strong>现行默认规则</strong>。</li>
</ul>
<h2 id="3-1-RBAC-授权模式"><a href="#3-1-RBAC-授权模式" class="headerlink" title="3.1 RBAC 授权模式"></a>3.1 RBAC 授权模式</h2><p>RBAC（Role-Based Access Control）基于角色的访问控制，在 Kubernetes 1.5 中引入，<strong>现行版本成为默认标准</strong>。相对其它访问控制方式，拥有以下优势：</p>
<ul>
<li><strong>对集群中的资源和非资源均拥有完整的覆盖。</strong></li>
<li><strong>整个 RBAC 完全由几个 API 对象完成，同其它 API 对象一样，可以用 kubectl 或 API 进行操作。</strong></li>
<li><strong>可以在运行时进行调整，无需重启 API Server。</strong></li>
</ul>
<p><strong>Ⅰ、RBAC 的 API 资源对象说明</strong></p>
<p>RBAC 引入了 4 个新的顶级资源对象：<strong>Role</strong>、<strong>ClusterRole</strong>、<strong>RoleBinding</strong>、<strong>ClusterRoleBinding</strong>，4 种对象类型均可以通过 kubectl 与 API 操作。</p>
<img src="https://blog-love70-img.oss-cn-chengdu.aliyuncs.com/blog.love70.cn/image-20200322101413438.png" alt="image-20200322101413438" style="zoom:50%;" />

<p><strong>需要注意的是 Kubenetes 并不会提供用户管理（70：创建用户需要在linux系统中完成）</strong>，那么 User、Group、ServiceAccount 指定的用户又是从哪里来的呢？ Kubenetes 组件（kubectl、kube-proxy）或是其他自定义的用户在向 CA 申请证书时，需要提供一个证书请求文件</p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="attr">"CN"</span>: <span class="string">"admin"</span>,</span><br><span class="line">  <span class="attr">"hosts"</span>: [],</span><br><span class="line">  <span class="attr">"key"</span>: &#123;</span><br><span class="line">    <span class="attr">"algo"</span>: <span class="string">"rsa"</span>,</span><br><span class="line">    <span class="attr">"size"</span>: <span class="number">2048</span></span><br><span class="line">  &#125;,</span><br><span class="line">  <span class="attr">"names"</span>: [</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="attr">"C"</span>: <span class="string">"CN"</span>,</span><br><span class="line">      <span class="attr">"ST"</span>: <span class="string">"HangZhou"</span>,</span><br><span class="line">      <span class="attr">"L"</span>: <span class="string">"XS"</span>,</span><br><span class="line">      <span class="attr">"O"</span>: <span class="string">"system:masters"</span>,</span><br><span class="line">      <span class="attr">"OU"</span>: <span class="string">"System"</span></span><br><span class="line">    &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><strong>API Server会把客户端证书的CN 字段作为User，把names.O 字段作为Group。</strong></p>
<p><strong>kubelet 使用 TLS Bootstaping 认证时，API Server 可以使用 Bootstrap Tokens 或者 Token authentication file 验证 =token，无论哪一种，Kubenetes 都会为 token 绑定一个默认的 User 和 Group。</strong></p>
<p><strong>Pod 使用 ServiceAccount 认证时，service-account-token 中的 JWT 会保存 User 信息。</strong></p>
<p><strong>有了用户信息，再创建一对角色/角色绑定(集群角色/集群角色绑定)资源对象，就可以完成权限绑定了。</strong></p>
<h2 id="3-2-Role-and-ClusterRole"><a href="#3-2-Role-and-ClusterRole" class="headerlink" title="3.2 Role and ClusterRole"></a>3.2 Role and ClusterRole</h2><p><strong>在 RBAC API 中，Role 表示一组规则权限，权限只会增加(累加权限)，不存在一个资源一开始就有很多权限而通过 RBAC 对其进行减少的操作；Role 可以定义在一个 namespace 中，如果想要跨 namespace 则可以创建 ClusterRole。</strong></p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">kind:</span> <span class="string">Role</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1beta1</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">default</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">pod-reader</span></span><br><span class="line"><span class="attr">rules:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">apiGroups:</span> <span class="string">[""]</span> <span class="comment"># "" indicates the core API group</span></span><br><span class="line">    <span class="attr">resources:</span> <span class="string">["pods"]</span></span><br><span class="line">    <span class="attr">verbs:</span> <span class="string">["get",</span> <span class="string">"watch"</span><span class="string">,</span> <span class="string">"list"</span><span class="string">]</span></span><br></pre></td></tr></table></figure>

<p>ClusterRole 具有与 Role 相同的权限角色控制能力，不同的是 ClusterRole 是集群级别的，ClusterRole 可以用于:</p>
<ul>
<li><strong>集群级别的资源控制( 例如 node 访问权限 )</strong></li>
<li><strong>非资源型 endpoints( 例如 /healthz 访问 )</strong></li>
<li><strong>所有命名空间资源控制(例如 pods )</strong></li>
</ul>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">kind:</span> <span class="string">ClusterRole</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1beta1</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="comment"># "namespace" omitted since ClusterRoles are not namespaced</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">secret-reader</span></span><br><span class="line"><span class="attr">rules:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">apiGroups:</span> <span class="string">[""]</span></span><br><span class="line">    <span class="attr">resources:</span> <span class="string">["secrets"]</span></span><br><span class="line">    <span class="attr">verbs:</span> <span class="string">["get",</span> <span class="string">"watch"</span><span class="string">,</span> <span class="string">"list"</span><span class="string">]</span></span><br></pre></td></tr></table></figure>



<h2 id="3-3-RoleBinding-and-ClusterRoleBinding"><a href="#3-3-RoleBinding-and-ClusterRoleBinding" class="headerlink" title="3.3 RoleBinding and ClusterRoleBinding"></a>3.3 RoleBinding and ClusterRoleBinding</h2><p><strong>RoloBinding 可以将角色中定义的权限授予用户或用户组，RoleBinding 包含一组权限列表(subjects)，权限列表中包含有不同形式的待授予权限资源类型(users, groups, or service accounts)；RoloBinding 同样包含对被Bind 的 Role 引用；RoleBinding 适用于某个命名空间内授权，而 ClusterRoleBinding 适用于集群范围内的授。</strong></p>
<p>将 default 命名空间的 pod-reader Role 授予 jane 用户，此后 jane 用户在 default 命名空间中将具有 pod-reader 的权限。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kind: RoleBinding</span><br><span class="line">apiVersion: rbac.authorization.k8s.io&#x2F;v1beta1</span><br><span class="line">metadata:</span><br><span class="line">  name: read-pods</span><br><span class="line">  namespace: default</span><br><span class="line">subjects:</span><br><span class="line">  - kind: User</span><br><span class="line">    name: jane</span><br><span class="line">    apiGroup: rbac.authorization.k8s.io</span><br><span class="line">roleRef:</span><br><span class="line">  kind: Role</span><br><span class="line">  name: pod-reader</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br></pre></td></tr></table></figure>

<p><strong>RoleBinding 同样可以引用 ClusterRole 来对当前 namespace 内用户、用户组或 ServiceAccount 进行授权，这种操作允许集群管理员在整个集群内定义一些通用的 ClusterRole，然后在不同的 namespace 中使用RoleBinding 来引用。</strong></p>
<p>例如，以下 RoleBinding 引用了一个 ClusterRole，这个 ClusterRole 具有整个集群内对 secrets 的访问权限；但是其授权用户 dave 只能访问 development 空间中的 secrets（因为 RoleBinding 定义在 development 命名空间）。</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># This role binding allows "dave" to read secrets in the "development" namespace.</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">RoleBinding</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1beta1</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">read-secrets</span></span><br><span class="line">   <span class="comment"># This only grants permissions within the "development" namespace.</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">development</span></span><br><span class="line"><span class="attr">subjects:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">kind:</span> <span class="string">User</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">dave</span></span><br><span class="line">    <span class="attr">apiGroup:</span> <span class="string">rbac.authorization.k8s.io</span></span><br><span class="line"><span class="attr">roleRef:</span></span><br><span class="line">  <span class="attr">kind:</span> <span class="string">ClusterRole</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">secret-reader</span></span><br><span class="line">  <span class="attr">apiGroup:</span> <span class="string">rbac.authorization.k8s.io</span></span><br></pre></td></tr></table></figure>

<p>使用 ClusterRoleBinding 可以对整个集群中的所有命名空间资源权限进行授权；以下 ClusterRoleBinding 样例展示了授权 manager 组内所有用户在全部命名空间中对 secrets 进行访问</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># This cluster role binding allows anyone in the "manager" group to read secrets in any namespace.</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ClusterRoleBinding</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1beta1</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">read-secrets-global</span></span><br><span class="line"><span class="attr">subjects:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">kind:</span> <span class="string">Group</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">manager</span></span><br><span class="line">    <span class="attr">apiGroup:</span> <span class="string">rbac.authorization.k8s.io</span></span><br><span class="line"><span class="attr">roleRef:</span></span><br><span class="line">  <span class="attr">kind:</span> <span class="string">ClusterRole</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">secret-reader</span></span><br><span class="line">  <span class="attr">apiGroup:</span> <span class="string">rbac.authorization.k8s.io</span></span><br></pre></td></tr></table></figure>



<h2 id="3-4-Resources"><a href="#3-4-Resources" class="headerlink" title="3.4 Resources"></a>3.4 Resources</h2><p><strong>Kubernetes 集群内一些资源一般以其名称字符串来表示，这些字符串一般会在 API 的 URL 地址中出现；同时某些资源也会包含子资源</strong>，例如 logs 资源就属于 pods 的子资源，API 中 URL 样例如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">GET &#x2F;api&#x2F;v1&#x2F;namespaces&#x2F;&#123;namespace&#125;&#x2F;pods&#x2F;&#123;name&#125;&#x2F;log</span><br></pre></td></tr></table></figure>

<p><strong>如果要在 RBAC 授权模型中控制这些子资源的访问权限，可以通过 / 分隔符来实现</strong>，以下是一个定义 pods 资资源 logs 访问权限的 Role 定义样例：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">kind:</span> <span class="string">Role</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1beta1</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">default</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">pod-and-pod-logs-reader</span></span><br><span class="line"><span class="attr">rules:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">apiGroups:</span> <span class="string">[""]</span></span><br><span class="line">    <span class="attr">resources:</span> <span class="string">["pods/log"]</span></span><br><span class="line">    <span class="attr">verbs:</span> <span class="string">["get",</span> <span class="string">"list"</span><span class="string">]</span></span><br></pre></td></tr></table></figure>



<h2 id="3-5-to-Subjects"><a href="#3-5-to-Subjects" class="headerlink" title="3.5 to Subjects"></a>3.5 to Subjects</h2><p><strong>RoleBinding 和 ClusterRoleBinding 可以将 Role 绑定到 Subjects；Subjects 可以是 groups、users 或者 service accounts。</strong></p>
<p>Subjects 中 Users 使用字符串表示，它可以是一个普通的名字字符串，如 “alice”；也可以是 email 格式的邮箱地址，如 “<a href="mailto:wangyanglinux@163.com">wangyanglinux@163.com</a>”；甚至是一组字符串形式的数字 ID 。但是 Users 的前缀 <strong>system:</strong> 是系统保留的，集群管理员应该确保普通用户不会使用这个前缀格式。</p>
<p>Groups 书写格式与 Users 相同，都为一个字符串，并且没有特定的格式要求；同样 system: 前缀为系统保留。</p>
<p><strong>实践：创建一个用户只能管理 dev 空间</strong></p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="attr">"CN"</span>: <span class="string">"devuser"</span>,</span><br><span class="line">  <span class="attr">"hosts"</span>: [],</span><br><span class="line">  <span class="attr">"key"</span>: &#123;</span><br><span class="line">    <span class="attr">"algo"</span>: <span class="string">"rsa"</span>,</span><br><span class="line">    <span class="attr">"size"</span>: <span class="number">2048</span></span><br><span class="line">  &#125;,</span><br><span class="line">  <span class="attr">"names"</span>: [</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="attr">"C"</span>: <span class="string">"CN"</span>,</span><br><span class="line">      <span class="attr">"ST"</span>: <span class="string">"BeiJing"</span>,</span><br><span class="line">      <span class="attr">"L"</span>: <span class="string">"BeiJing"</span>,</span><br><span class="line">      <span class="attr">"O"</span>: <span class="string">"k8s"</span>,</span><br><span class="line">      <span class="attr">"OU"</span>: <span class="string">"System"</span></span><br><span class="line">    &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 下载证书生成工具</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> wget https://pkg.cfssl.org/R1.2/cfssl_linux-amd64</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> mv cfssl_linux-amd64 /usr/<span class="built_in">local</span>/bin/cfssl</span></span><br><span class="line"></span><br><span class="line"><span class="meta">$</span><span class="bash"> wget https://pkg.cfssl.org/R1.2/cfssljson_linux-amd64</span></span><br><span class="line"></span><br><span class="line"><span class="meta">$</span><span class="bash"> mv cfssljson_linux-amd64 /usr/<span class="built_in">local</span>/bin/cfssljson</span></span><br><span class="line"></span><br><span class="line"><span class="meta">$</span><span class="bash"> wget https://pkg.cfssl.org/R1.2/cfssl-certinfo_linux-amd64</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> mv cfssl-certinfo_linux-amd64 /usr/<span class="built_in">local</span>/bin/cfssl-certinfo</span></span><br><span class="line"></span><br><span class="line"><span class="meta">$</span><span class="bash"> <span class="built_in">cd</span> /etc/kubernetes/pki/</span></span><br><span class="line"></span><br><span class="line"><span class="meta">$</span><span class="bash"> cfssl gencert -ca=ca.crt -ca-key=ca.key -profile=kubernetes /root/devuser-csr.json | cfssljson -bare devuser</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 设置集群参数</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> <span class="built_in">export</span> KUBE_APISERVER=<span class="string">"https://172.20.0.113:6443"</span></span></span><br><span class="line"><span class="meta">$</span><span class="bash"> kubectl config <span class="built_in">set</span>-cluster kubernetes \</span></span><br><span class="line">--certificate-authority=/etc/kubernetes/ssl/ca.pem \</span><br><span class="line">--embed-certs=true \</span><br><span class="line">--server=$&#123;KUBE_APISERVER&#125; \</span><br><span class="line">--kubeconfig=devuser.kubeconfig</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 设置客户端认证参数</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> kubectl config <span class="built_in">set</span>-credentials devuser \</span></span><br><span class="line">--client-certificate=/etc/kubernetes/ssl/devuser.pem \</span><br><span class="line">--client-key=/etc/kubernetes/ssl/devuser-key.pem \</span><br><span class="line">--embed-certs=true \</span><br><span class="line">--kubeconfig=devuser.kubeconfig</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 设置上下文参数</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> kubectl config <span class="built_in">set</span>-context kubernetes \</span></span><br><span class="line">--cluster=kubernetes \</span><br><span class="line">--user=devuser \</span><br><span class="line">--namespace=dev \</span><br><span class="line">--kubeconfig=devuser.kubeconfig</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 设置默认上下文</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> kubectl config use-context kubernetes --kubeconfig=devuser.kubeconfig</span></span><br><span class="line"></span><br><span class="line"><span class="meta">$</span><span class="bash"> cp -f ./devuser.kubeconfig /home/devuser/.kube/config</span></span><br><span class="line"></span><br><span class="line"><span class="meta">$</span><span class="bash"> kubectl create rolebinding devuser-admin-binding --clusterrole=admin --user=devuser --namespace=dev</span></span><br></pre></td></tr></table></figure>



<h1 id="4-准入控制-Admission-Control"><a href="#4-准入控制-Admission-Control" class="headerlink" title="4. 准入控制 Admission Control"></a>4. 准入控制 Admission Control</h1><p><strong>准入控制是 API Server 的插件集合，通过添加不同的插件，实现额外的准入控制规则。</strong>甚至于API Server的一些主要的功能都需要通过 Admission Controllers 实现，比如 ServiceAccount。</p>
<p>官方文档上有一份针对不同版本的准入控制器推荐列表，其中最新的 1.14 的推荐列表是：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">NamespaceLifecycle,LimitRanger,ServiceAccount,DefaultStorageClass,DefaultTolerationSeconds,MutatingAdmissionWebhook,ValidatingAdmissionWebhook,ResourceQuota</span><br></pre></td></tr></table></figure>

<p>列举几个插件的功能：</p>
<ul>
<li><strong>NamespaceLifecycle</strong>： 防止在不存在的 namespace 上创建对象，防止删除系统预置 namespace，删除 namespace 时，连带删除它的所有资源对象。</li>
<li><strong>LimitRanger</strong>：确保请求的资源不会超过资源所在 Namespace 的 LimitRange 的限制。</li>
<li><strong>ServiceAccount</strong>： 实现了自动化添加 ServiceAccount。</li>
<li><strong>ResourceQuota</strong>：确保请求的资源不会超过资源的 ResourceQuota 限制。</li>
</ul>
]]></content>
      <categories>
        <category>Kubernetes</category>
      </categories>
  </entry>
  <entry>
    <title>七、Kubernets 集群调度</title>
    <url>/2020/03/07/kubernetes%E7%AC%94%E8%AE%B0/7.Kubernetes%E9%9B%86%E7%BE%A4%E8%B0%83%E5%BA%A6/</url>
    <content><![CDATA[<h1 id="1-调度说明"><a href="#1-调度说明" class="headerlink" title="1. 调度说明"></a>1. 调度说明</h1><h2 id="1-1-Scheduler-介绍"><a href="#1-1-Scheduler-介绍" class="headerlink" title="1.1 Scheduler 介绍"></a>1.1 Scheduler 介绍</h2><p><strong>Scheduler 是 kubernetes 的调度器，主要的任务是把定义的 pod 分配到集群的节点上。</strong>听起来非常简单，但有很多要考虑的问题：</p>
<a id="more"></a>
<ul>
<li><strong>公平</strong>：如何保证每个节点都能被分配资源</li>
<li><strong>资源高效利用</strong>：集群所有资源最大化被使用</li>
<li><strong>效率</strong>：调度的性能要好，能够尽快地对大批量的 pod 完成调度工作</li>
<li><strong>灵活</strong>：允许用户根据自己的需求控制调度的逻辑</li>
</ul>
<p><strong>Sheduler 是作为单独的程序运行的，启动之后会一直监听 API Server，获取 PodSpec.NodeName 为空的 pod，对每个 pod 都会创建一个 binding，表明该 pod 应该放到哪个节点上。</strong></p>
<h2 id="1-2-调度过程"><a href="#1-2-调度过程" class="headerlink" title="1.2 调度过程"></a>1.2 调度过程</h2><p>调度分为几个部分：（70：预选 + 优选）</p>
<p><strong>首先是过滤掉不满足条件的节点，这个过程称为 predicate ；</strong></p>
<p><strong>然后对通过的节点按照优先级排序，这个是 priority ；</strong></p>
<p><strong>最后从中选择优先级最高的节点。如果中间任何一步骤有错误，就直接返回错误。</strong></p>
<p>Predicate 有一系列的算法可以使用：</p>
<ul>
<li>PodFitsResources ：节点上剩余的资源是否大于 pod 请求的资源</li>
<li>PodFitsHost ：如果 pod 指定了 NodeName，检查节点名称是否和 NodeName 匹配</li>
<li>PodFitsHostPorts ：节点上已经使用的 port 是否和 pod 申请的 port 冲突</li>
<li>PodSelectorMatches ：过滤掉和 pod 指定的 label 不匹配的节点</li>
<li>NoDiskConflict ：已经 mount 的 volume 和 pod 指定的 volume 不冲突，除非它们都是只读</li>
</ul>
<p><strong>如果在 predicate 过程中没有合适的节点，pod 会一直在 pending 状态，不断重试调度，直到有节点满足条件。经过这个步骤，如果有多个节点满足条件，就继续 priorities 过程： 按照优先级大小对节点排序。</strong></p>
<p>优先级由一系列键值对组成，键是该优先级项的名称，值是它的权重（该项的重要性）。这些优先级选项包括：</p>
<ul>
<li>LeastRequestedPriority ：通过计算 CPU 和 Memory 的使用率来决定权重，使用率越低权重越高。换句话<br>  说，这个优先级指标倾向于资源使用比例更低的节点。</li>
<li>BalancedResourceAllocation ：节点上 CPU 和 Memory 使用率越接近，权重越高。这个应该和上面的一起使用，不应该单独使用。</li>
<li>ImageLocalityPriority ：倾向于已经有要使用镜像的节点，镜像总大小值越大，权重越高。</li>
</ul>
<p><strong>通过算法对所有的优先级项目和权重进行计算，得出最终的结果。</strong></p>
<h2 id="1-3-自定义调度器"><a href="#1-3-自定义调度器" class="headerlink" title="1.3 自定义调度器"></a>1.3 自定义调度器</h2><p>除了 kubernetes 自带的调度器，你也可以编写自己的调度器。通过 spec:schedulername 参数指定调度器的名<br>字，可以为 pod 选择某个调度器进行调度。比如下面的 pod 选择 my-scheduler 进行调度，而不是默认的<br>default-scheduler ：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">annotation-second-scheduler</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">multischeduler-example</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">schedulername:</span> <span class="string">my-scheduler</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">pod-with-second-annotation-container</span></span><br><span class="line">      <span class="attr">image:</span> <span class="string">gcr.io/google_containers/pause:2.0</span></span><br></pre></td></tr></table></figure>



<h1 id="2-调度亲和性"><a href="#2-调度亲和性" class="headerlink" title="2. 调度亲和性"></a>2. 调度亲和性</h1><h2 id="2-1-节点亲和性"><a href="#2-1-节点亲和性" class="headerlink" title="2.1 节点亲和性"></a>2.1 节点亲和性</h2><p>pod.spec.nodeAffinity</p>
<ul>
<li>preferredDuringSchedulingIgnoredDuringExecution：软策略</li>
<li>requiredDuringSchedulingIgnoredDuringExecution：硬策略</li>
</ul>
<p>硬策略：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">affinity</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">node-affinity-pod</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">with-node-affinity</span></span><br><span class="line">      <span class="attr">image:</span> <span class="string">hub.atguigu.com/library/myapp:v1</span></span><br><span class="line">  <span class="attr">affinity:</span></span><br><span class="line">    <span class="attr">nodeAffinity:</span></span><br><span class="line">      <span class="attr">requiredDuringSchedulingIgnoredDuringExecution:</span></span><br><span class="line">        <span class="attr">nodeSelectorTerms:</span></span><br><span class="line">          <span class="bullet">-</span> <span class="attr">matchExpressions:</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">key:</span> <span class="string">kubernetes.io/hostname</span></span><br><span class="line">              <span class="attr">operator:</span> <span class="string">NotIn</span></span><br><span class="line">              <span class="attr">values:</span></span><br><span class="line">                <span class="bullet">-</span> <span class="string">k8s-node02</span></span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> kubectl get node --show-labels</span></span><br></pre></td></tr></table></figure>

<p>软策略：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">affinity</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">node-affinity-pod</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">with-node-affinity</span></span><br><span class="line">      <span class="attr">image:</span> <span class="string">hub.atguigu.com/library/myapp:v1</span></span><br><span class="line">  <span class="attr">affinity:</span></span><br><span class="line">    <span class="attr">nodeAffinity:</span></span><br><span class="line">      <span class="attr">preferredDuringSchedulingIgnoredDuringExecution:</span></span><br><span class="line">        <span class="comment"># 如果有多个软策略，可以给不同的策略不同的 weight，越大越亲和</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">weight:</span> <span class="number">1</span></span><br><span class="line">          <span class="attr">preference:</span></span><br><span class="line">            <span class="attr">matchExpressions:</span></span><br><span class="line">              <span class="bullet">-</span> <span class="attr">key:</span> <span class="string">source</span></span><br><span class="line">                <span class="attr">operator:</span> <span class="string">In</span></span><br><span class="line">                <span class="attr">values:</span></span><br><span class="line">                  <span class="bullet">-</span> <span class="string">qikqiak</span></span><br></pre></td></tr></table></figure>

<p>合体：（先考虑硬策略，再考虑软策略）</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">affinity</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">node-affinity-pod</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">with-node-affinity</span></span><br><span class="line">      <span class="attr">image:</span> <span class="string">hub.atguigu.com/library/myapp:v1</span></span><br><span class="line">  <span class="attr">affinity:</span></span><br><span class="line">    <span class="attr">nodeAffinity:</span></span><br><span class="line">      <span class="attr">requiredDuringSchedulingIgnoredDuringExecution:</span></span><br><span class="line">        <span class="attr">nodeSelectorTerms:</span></span><br><span class="line">          <span class="bullet">-</span> <span class="attr">matchExpressions:</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">key:</span> <span class="string">kubernetes.io/hostname</span></span><br><span class="line">              <span class="attr">operator:</span> <span class="string">NotIn</span></span><br><span class="line">              <span class="attr">values:</span></span><br><span class="line">                <span class="bullet">-</span> <span class="string">k8s-node02</span></span><br><span class="line">      <span class="attr">preferredDuringSchedulingIgnoredDuringExecution:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">weight:</span> <span class="number">1</span></span><br><span class="line">          <span class="attr">preference:</span></span><br><span class="line">            <span class="attr">matchExpressions:</span></span><br><span class="line">              <span class="bullet">-</span> <span class="attr">key:</span> <span class="string">source</span></span><br><span class="line">                <span class="attr">operator:</span> <span class="string">In</span></span><br><span class="line">                <span class="attr">values:</span></span><br><span class="line">                  <span class="bullet">-</span> <span class="string">qikqiak</span></span><br></pre></td></tr></table></figure>

<p><strong>键值运算关系：</strong></p>
<ul>
<li>In：label 的值在某个列表中</li>
<li>NotIn：label 的值不在某个列表中</li>
<li>Gt：label 的值大于某个值</li>
<li>Lt：label 的值小于某个值</li>
<li>Exists：某个 label 存在</li>
<li>DoesNotExist：某个 label 不存在</li>
</ul>
<p>如果 nodeSelectorTerms 下面有多个选项的话，满足任何一个条件就可以了；如果 matchExpressions 下面有多个选项的话，则必须同时满足这些条件才能正常调度 Pod。</p>
<h2 id="2-2-Pod-亲和性"><a href="#2-2-Pod-亲和性" class="headerlink" title="2.2 Pod 亲和性"></a>2.2 Pod 亲和性</h2><p>pod.spec.affinity.podAffinity/podAntiAffinity</p>
<ul>
<li>preferredDuringSchedulingIgnoredDuringExecution：软策略</li>
<li>requiredDuringSchedulingIgnoredDuringExecution：硬策略</li>
</ul>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">pod-3</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">pod-3</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">pod-3</span></span><br><span class="line">      <span class="attr">image:</span> <span class="string">hub.atguigu.com/library/myapp:v1</span></span><br><span class="line">  <span class="attr">affinity:</span></span><br><span class="line">    <span class="attr">podAffinity:</span></span><br><span class="line">      <span class="attr">requiredDuringSchedulingIgnoredDuringExecution:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">labelSelector:</span></span><br><span class="line">            <span class="attr">matchExpressions:</span></span><br><span class="line">              <span class="bullet">-</span> <span class="attr">key:</span> <span class="string">app</span></span><br><span class="line">                <span class="attr">operator:</span> <span class="string">In</span></span><br><span class="line">                <span class="attr">values:</span></span><br><span class="line">                  <span class="bullet">-</span> <span class="string">pod-1</span></span><br><span class="line">            <span class="attr">topologyKey:</span> <span class="string">kubernetes.io/hostname</span></span><br><span class="line">    <span class="attr">podAntiAffinity:</span></span><br><span class="line">      <span class="attr">preferredDuringSchedulingIgnoredDuringExecution:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">weight:</span> <span class="number">1</span></span><br><span class="line">          <span class="attr">podAffinityTerm:</span></span><br><span class="line">            <span class="attr">labelSelector:</span></span><br><span class="line">              <span class="attr">matchExpressions:</span></span><br><span class="line">                <span class="bullet">-</span> <span class="attr">key:</span> <span class="string">app</span></span><br><span class="line">                  <span class="attr">operator:</span> <span class="string">In</span></span><br><span class="line">                  <span class="attr">values:</span></span><br><span class="line">                    <span class="bullet">-</span> <span class="string">pod-2</span></span><br><span class="line">            <span class="attr">topologyKey:</span> <span class="string">kubernetes.io/hostname</span></span><br></pre></td></tr></table></figure>

<p>亲和性/反亲和性调度策略比较如下：</p>
<table>
<thead>
<tr>
<th align="center">调度策略</th>
<th align="center">匹配标签</th>
<th align="center">操作符</th>
<th align="center">拓扑域支持</th>
<th align="center">调度目标</th>
</tr>
</thead>
<tbody><tr>
<td align="center">nodeAffinity</td>
<td align="center">主机</td>
<td align="center">In, NotIn, Exists, DoesNotExist, Gt, Lt</td>
<td align="center">否</td>
<td align="center">指定主机</td>
</tr>
<tr>
<td align="center">podAffinity</td>
<td align="center">Pod</td>
<td align="center">In, NotIn, Exists, DoesNotExist</td>
<td align="center">是</td>
<td align="center">Pod 与指定 Pod 同一拓扑域</td>
</tr>
<tr>
<td align="center">podAnitAffinity</td>
<td align="center">Pod</td>
<td align="center">In, NotIn, Exists, DoesNotExist</td>
<td align="center">是</td>
<td align="center">Pod 与指定 Pod 不再同一拓扑域</td>
</tr>
</tbody></table>
<h1 id="3-污点"><a href="#3-污点" class="headerlink" title="3. 污点"></a>3. 污点</h1><h2 id="3-1-Taint-和-Toleration"><a href="#3-1-Taint-和-Toleration" class="headerlink" title="3.1 Taint 和 Toleration"></a>3.1 Taint 和 Toleration</h2><p>节点亲和性，是 pod 的一种属性（偏好或硬性要求），它使 pod 被吸引到一类特定的节点。<strong>Taint 则相反，它使节点能够排斥一类特定的 pod</strong>。</p>
<p><strong>Taint 和 Toleration 相互配合，可以用来避免 pod 被分配到不合适的节点上。</strong>每个节点上都可以应用一个或多个 taint ，这表示对于那些不能容忍这些 taint 的 pod，是不会被该节点接受的。如果将 toleration 应用于 pod<br>上，则表示这些 pod <strong>可以（但不要求）</strong>被调度到具有匹配 taint 的节点上。</p>
<h2 id="3-2-污点（Taint）"><a href="#3-2-污点（Taint）" class="headerlink" title="3.2 污点（Taint）"></a>3.2 污点（Taint）</h2><p><strong>Ⅰ、污点（Taint）的组成</strong></p>
<p><strong>使用 <code>kubectl taint</code> 命令可以给某个 Node 节点设置污点，Node 被设置上污点之后就和 Pod 之间存在了一种相斥的关系，可以让 Node 拒绝 Pod 的调度执行，甚至将 Node 已经存在的 Pod 驱逐出去。</strong></p>
<p>每个污点的组成如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">key&#x3D;value:effect</span><br></pre></td></tr></table></figure>

<p>每个污点有一个 key 和 value 作为污点的标签，其中 value 可以为空，effect 描述污点的作用。当前 taint<br>effect 支持如下三个选项：</p>
<ul>
<li>NoSchedule ：表示 k8s 将不会将 Pod 调度到具有该污点的 Node 上。</li>
<li>PreferNoSchedule ：表示 k8s 将尽量避免将 Pod 调度到具有该污点的 Node 上。</li>
<li>NoExecute ：表示 k8s 将不会将 Pod 调度到具有该污点的 Node 上，同时会将 Node 上已经存在的 Pod 驱<br>  逐出去。</li>
</ul>
<p>可以通过 <code>kubectl describe node xxx</code> 来查看现有的 taint。</p>
<p>70：如果某个节点如：k8s-node01需要被维护，而 k8s-node01 上运行了很多Pod，如果直接关闭 Node，可能会对网络访问造成一些影响。所以可以先对 k83-node01 打一个 NoExecute 的污点，先将所有的 Pod 驱逐出去，然后再将该节点从集群中清除，再进行维护。（和直接关闭该 Node 的区别在哪儿？）</p>
<p><strong>Ⅱ、污点的设置、查看和去除</strong></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 设置污点</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> kubectl taint nodes k8s-node01 key1=value1:NoSchedule</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 节点说明中，查找 Taints 字段</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> kubectl describe node node-name</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 去除污点</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> kubectl taint nodes k8s-node01 key1:NoSchedule-</span></span><br></pre></td></tr></table></figure>



<h2 id="3-3-容忍（Tolerations）"><a href="#3-3-容忍（Tolerations）" class="headerlink" title="3.3 容忍（Tolerations）"></a>3.3 容忍（Tolerations）</h2><p><strong>设置了污点的 Node 将根据 taint 的 effect：NoSchedule、PreferNoSchedule、NoExecute 和 Pod 之间产生互斥的关系，Pod 将在一定程度上不会被调度到 Node 上。 但我们可以在 Pod 上设置容忍 ( Toleration ) ，意思是设置了容忍的 Pod 将可以容忍污点的存在，可以被调度到存在污点的 Node 上。</strong></p>
<p><strong>pod.spec.tolerations</strong></p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">tolerations:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">key:</span> <span class="string">"key1"</span></span><br><span class="line">    <span class="attr">operator:</span> <span class="string">"Equal"</span></span><br><span class="line">    <span class="attr">value:</span> <span class="string">"value1"</span></span><br><span class="line">    <span class="attr">effect:</span> <span class="string">"NoSchedule"</span></span><br><span class="line">    <span class="attr">tolerationSeconds:</span> <span class="number">3600</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">key:</span> <span class="string">"key1"</span></span><br><span class="line">    <span class="attr">operator:</span> <span class="string">"Equal"</span></span><br><span class="line">    <span class="attr">value:</span> <span class="string">"value1"</span></span><br><span class="line">    <span class="attr">effect:</span> <span class="string">"NoExecute"</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">key:</span> <span class="string">"key2"</span></span><br><span class="line">    <span class="attr">operator:</span> <span class="string">"Exists"</span></span><br><span class="line">    <span class="attr">effect:</span> <span class="string">"NoSchedule"</span></span><br></pre></td></tr></table></figure>

<ul>
<li><strong>其中 key, vaule, effect 要与 Node 上设置的 taint 保持一致</strong></li>
<li><strong>operator 的值为 Exists 将会忽略 value 值</strong></li>
<li><strong>tolerationSeconds 用于描述当 Pod 需要被驱逐时可以在 Pod 上继续保留运行的时间</strong></li>
</ul>
<p><strong>Ⅰ、当不指定 key 值时，表示容忍所有的污点 key</strong></p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">tolerations:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">operator:</span> <span class="string">"Exists"</span></span><br></pre></td></tr></table></figure>

<p><strong>Ⅱ、当不指定 effect 值时，表示容忍所有的污点作用</strong></p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">tolerations:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">key:</span> <span class="string">"key"</span></span><br><span class="line">    <span class="attr">operator:</span> <span class="string">"Exists"</span></span><br></pre></td></tr></table></figure>

<p><strong>Ⅲ、有多个 Master 存在时，防止资源浪费，可以如下设置：</strong></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> kubectl taint nodes Node-Name node-role.kubernetes.io/master=:PreferNoSchedule</span></span><br></pre></td></tr></table></figure>



<h1 id="4-指定调度节点"><a href="#4-指定调度节点" class="headerlink" title="4. 指定调度节点"></a>4. 指定调度节点</h1><p><strong>Ⅰ、Pod.spec.nodeName 将 Pod 直接调度到指定的 Node 节点上，会跳过 Scheduler 的调度策略，该匹配规则是强制匹配</strong></p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">extensions/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Deployment</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">myweb</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">replicas:</span> <span class="number">7</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">app:</span> <span class="string">myweb</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">nodeName:</span> <span class="string">k8s-node01</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">myweb</span></span><br><span class="line">          <span class="attr">image:</span> <span class="string">hub.atguigu.com/library/myapp:v1</span></span><br><span class="line">          <span class="attr">ports:</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">80</span></span><br></pre></td></tr></table></figure>

<p><strong>Ⅱ、Pod.spec.nodeSelector：通过 kubernetes 的 label-selector 机制选择节点，由调度器调度策略匹配 label，而后调度 Pod 到目标节点，该匹配规则属于强制约束</strong></p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">extensions/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Deployment</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">myweb</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">replicas:</span> <span class="number">2</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">app:</span> <span class="string">myweb</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">nodeSelector:</span></span><br><span class="line">        <span class="comment"># 通过 node 的 labels 进行选择</span></span><br><span class="line">        <span class="attr">type:</span> <span class="string">backEndNode1</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">myweb</span></span><br><span class="line">          <span class="attr">image:</span> <span class="string">harbor/tomcat:8.5-jre8</span></span><br><span class="line">          <span class="attr">ports:</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">80</span></span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>Kubernetes</category>
      </categories>
  </entry>
  <entry>
    <title>六、Kubernetes 存储</title>
    <url>/2020/03/06/kubernetes%E7%AC%94%E8%AE%B0/6.Kubernetes%E5%AD%98%E5%82%A8/</url>
    <content><![CDATA[<h1 id="1-ConfigMap"><a href="#1-ConfigMap" class="headerlink" title="1. ConfigMap"></a>1. ConfigMap</h1><h2 id="1-1-ConfigMap-介绍"><a href="#1-1-ConfigMap-介绍" class="headerlink" title="1.1 ConfigMap 介绍"></a>1.1 ConfigMap 介绍</h2><p>ConfigMap 功能在 Kubernetes 1.2版本中引入，许多应用程序会从配置文件、命令行参数或环境变量中读取配置信息。<strong>ConfigMap API 给我们提供了向容器中注入配置信息的机制，ConfigMap 可以被用来保存单个属性，也可以用来保存整个配置文件或者 JSON 二进制大对象。</strong></p>
<a id="more"></a>

<p>70： ConfigMap 存储配置信息。</p>
<p>70：生产环境中使用配置文件注册中心（目前还没有比较好的开源方案），服务向配置文件注册中心去索要它的配置信息，配置文件注册中心根据匹配信息（如：主机名、IP地址范围）分配配置文件。以后要修改配置文件，只需要在配置文件注册中心进行更新，这样就会触发每个服务的修改和运行。</p>
<h2 id="1-2-ConfigMap-的创建"><a href="#1-2-ConfigMap-的创建" class="headerlink" title="1.2 ConfigMap 的创建"></a>1.2 ConfigMap 的创建</h2><p><strong>Ⅰ、使用目录创建</strong></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> ls docs/user-guide/configmap/kubectl/</span></span><br><span class="line">game.properties</span><br><span class="line">ui.properties</span><br><span class="line"></span><br><span class="line"><span class="meta">$</span><span class="bash"> cat docs/user-guide/configmap/kubectl/game.properties</span></span><br><span class="line">enemies=aliens</span><br><span class="line">lives=3</span><br><span class="line">enemies.cheat=true</span><br><span class="line">enemies.cheat.level=noGoodRotten</span><br><span class="line">secret.code.passphrase=UUDDLRLRBABAS</span><br><span class="line">secret.code.allowed=true</span><br><span class="line">secret.code.lives=30</span><br><span class="line"></span><br><span class="line"><span class="meta">$</span><span class="bash"> cat docs/user-guide/configmap/kubectl/ui.properties</span></span><br><span class="line">color.good=purple</span><br><span class="line">color.bad=yellow</span><br><span class="line">allow.textmode=true</span><br><span class="line">how.nice.to.look=fairlyNice</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 创建 ConfigMap</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> kubectl create configmap game-config --from-file=xxx/configmap/</span></span><br></pre></td></tr></table></figure>

<p><code>--from-file</code> 指定在目录下的所有文件都会被用在 ConfigMap 里面创建一个键值对，<strong>键的名字就是文件名，值就是文件的内容</strong>。</p>
<p><strong>Ⅱ、使用文件创建</strong></p>
<p>只要指定为一个文件就可以从单个文件中创建ConfigMap</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> kubectl create configmap game-config2 --from-file=./game.properties --from-file=./ui.properties</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看 ConfigMap 信息</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> kubectl get configmap game-config2 -o yaml</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> kubectl describe configmap game-config2</span></span><br></pre></td></tr></table></figure>

<p><code>--from-file</code>  这个参数可以使用多次，你可以使用两次分别指定上个实例中的那两个配置文件，效果就跟指定整个目录是一样的。</p>
<p><strong>Ⅲ、使用字面值创建</strong></p>
<p>使用文字值创建，利用 <code>--from-literal</code> 参数传递配置信息，该参数可以使用多次，格式如下：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> kubectl create configmap special-config --from-literal=special.how=very --from-literal=special.type=charm</span></span><br><span class="line"></span><br><span class="line"><span class="meta">$</span><span class="bash"> kubectl get configmaps special-config -o yaml</span></span><br></pre></td></tr></table></figure>

<p><strong>Ⅳ、通过资源清单创建</strong></p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ConfigMap</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">special-config</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">default</span></span><br><span class="line"><span class="attr">data:</span></span><br><span class="line">  <span class="attr">special.how:</span> <span class="string">very</span></span><br><span class="line">  <span class="attr">special.type:</span> <span class="string">charm</span></span><br></pre></td></tr></table></figure>



<h2 id="1-3-Pod-中使用-ConfigMap"><a href="#1-3-Pod-中使用-ConfigMap" class="headerlink" title="1.3 Pod 中使用 ConfigMap"></a>1.3 Pod 中使用 ConfigMap</h2><p><strong>Ⅰ、使用 ConfigMap 来替代环境变量</strong></p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ConfigMap</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">special-config</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">default</span></span><br><span class="line"><span class="attr">data:</span></span><br><span class="line">  <span class="attr">special.how:</span> <span class="string">very</span></span><br><span class="line">  <span class="attr">special.type:</span> <span class="string">charm</span></span><br></pre></td></tr></table></figure>

<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ConfigMap</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">env-config</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">default</span></span><br><span class="line"><span class="attr">data:</span></span><br><span class="line">  <span class="attr">log_level:</span> <span class="string">INFO</span></span><br></pre></td></tr></table></figure>

<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">dapi-test-pod</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">test-container</span></span><br><span class="line">      <span class="attr">image:</span> <span class="string">hub.atguigu.com/library/myapp:v1</span></span><br><span class="line">      <span class="attr">command:</span> <span class="string">[</span> <span class="string">"/bin/sh"</span><span class="string">,</span> <span class="string">"-c"</span><span class="string">,</span> <span class="string">"env"</span> <span class="string">]</span></span><br><span class="line">      <span class="attr">env:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">SPECIAL_LEVEL_KEY</span></span><br><span class="line">          <span class="attr">valueFrom:</span></span><br><span class="line">            <span class="attr">configMapKeyRef:</span></span><br><span class="line">              <span class="attr">name:</span> <span class="string">special-config</span></span><br><span class="line">              <span class="attr">key:</span> <span class="string">special.how</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">SPECIAL_TYPE_KEY</span></span><br><span class="line">          <span class="attr">valueFrom:</span></span><br><span class="line">            <span class="attr">configMapKeyRef:</span></span><br><span class="line">              <span class="attr">name:</span> <span class="string">special-config</span></span><br><span class="line">              <span class="attr">key:</span> <span class="string">special.type</span></span><br><span class="line">      <span class="attr">envFrom:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">configMapRef:</span></span><br><span class="line">            <span class="attr">name:</span> <span class="string">env-config</span></span><br><span class="line">  <span class="attr">restartPolicy:</span> <span class="string">Never</span></span><br></pre></td></tr></table></figure>

<p><strong>Ⅱ、用 ConfigMap 设置命令行参数</strong></p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ConfigMap</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">special-config</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">default</span></span><br><span class="line"><span class="attr">data:</span></span><br><span class="line">  <span class="attr">special.how:</span> <span class="string">very</span></span><br><span class="line">  <span class="attr">special.type:</span> <span class="string">charm</span></span><br></pre></td></tr></table></figure>

<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">dapi-test-pod</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">test-container</span></span><br><span class="line">      <span class="attr">image:</span> <span class="string">hub.atguigu.com/library/myapp:v1</span></span><br><span class="line">      <span class="attr">command:</span> <span class="string">[</span> <span class="string">"/bin/sh"</span><span class="string">,</span> <span class="string">"-c"</span><span class="string">,</span> <span class="string">"echo $(SPECIAL_LEVEL_KEY) $(SPECIAL_TYPE_KEY)"</span> <span class="string">]</span></span><br><span class="line">      <span class="attr">env:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">SPECIAL_LEVEL_KEY</span></span><br><span class="line">          <span class="attr">valueFrom:</span></span><br><span class="line">            <span class="attr">configMapKeyRef:</span></span><br><span class="line">              <span class="attr">name:</span> <span class="string">special-config</span></span><br><span class="line">              <span class="attr">key:</span> <span class="string">special.how</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">SPECIAL_TYPE_KEY</span></span><br><span class="line">          <span class="attr">valueFrom:</span></span><br><span class="line">            <span class="attr">configMapKeyRef:</span></span><br><span class="line">              <span class="attr">name:</span> <span class="string">special-config</span></span><br><span class="line">              <span class="attr">key:</span> <span class="string">special.type</span></span><br><span class="line">  <span class="attr">restartPolicy:</span> <span class="string">Never</span></span><br></pre></td></tr></table></figure>

<p><strong>Ⅲ、通过数据卷插件使用 ConfigMap</strong></p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ConfigMap</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">special-config</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">default</span></span><br><span class="line"><span class="attr">data:</span></span><br><span class="line">  <span class="attr">special.how:</span> <span class="string">very</span></span><br><span class="line">  <span class="attr">special.type:</span> <span class="string">charm</span></span><br></pre></td></tr></table></figure>

<p>在数据卷里面使用这个 ConfigMap，有不同的选项。<strong>最基本的就是将文件填入数据卷，在这个文件中，键就是文件名，键值就是文件内容。</strong></p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">dapi-test-pod</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">test-container</span></span><br><span class="line">      <span class="attr">image:</span> <span class="string">hub.atguigu.com/library/myapp:v1</span></span><br><span class="line">      <span class="attr">command:</span> <span class="string">[</span> <span class="string">"/bin/sh"</span><span class="string">,</span> <span class="string">"-c"</span><span class="string">,</span> <span class="string">"cat /etc/config/special.how"</span> <span class="string">]</span></span><br><span class="line">      <span class="attr">volumeMounts:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">config-volume</span></span><br><span class="line">          <span class="attr">mountPath:</span> <span class="string">/etc/config</span></span><br><span class="line">  <span class="attr">volumes:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">config-volume</span></span><br><span class="line">      <span class="attr">configMap:</span></span><br><span class="line">        <span class="attr">name:</span> <span class="string">special-config</span></span><br><span class="line">  <span class="attr">restartPolicy:</span> <span class="string">Never</span></span><br></pre></td></tr></table></figure>



<h2 id="1-4-ConfigMap-的热更新"><a href="#1-4-ConfigMap-的热更新" class="headerlink" title="1.4 ConfigMap 的热更新"></a>1.4 ConfigMap 的热更新</h2><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ConfigMap</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">log-config</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">default</span></span><br><span class="line"><span class="attr">data:</span></span><br><span class="line">  <span class="attr">log_level:</span> <span class="string">INFO</span></span><br><span class="line">  </span><br><span class="line"><span class="meta">---</span></span><br><span class="line"></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">extensions/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Deployment</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">my-nginx</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">replicas:</span> <span class="number">1</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">run:</span> <span class="string">my-nginx</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">my-nginx</span></span><br><span class="line">          <span class="attr">image:</span> <span class="string">hub.atguigu.com/library/myapp:v1</span></span><br><span class="line">          <span class="attr">ports:</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">80</span></span><br><span class="line">          <span class="attr">volumeMounts:</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">config-volume</span></span><br><span class="line">              <span class="attr">mountPath:</span> <span class="string">/etc/config</span></span><br><span class="line">      <span class="attr">volumes:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">config-volume</span></span><br><span class="line">          <span class="attr">configMap:</span></span><br><span class="line">            <span class="attr">name:</span> <span class="string">log-config</span></span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> kubectl <span class="built_in">exec</span> `kubectl get pods -l run=my-nginx -o=name|cut -d <span class="string">"/"</span> -f2` cat</span></span><br><span class="line">/etc/config/log_level</span><br><span class="line">INFO</span><br></pre></td></tr></table></figure>

<p><strong>修改 ConfigMap</strong></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> kubectl edit configmap <span class="built_in">log</span>-config</span></span><br></pre></td></tr></table></figure>

<p><strong>修改 log_level 的值为 DEBUG ，等待大概 10秒钟时间，再次查看环境变量的值</strong></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> kubectl <span class="built_in">exec</span> `kubectl get pods -l run=my-nginx -o=name|cut -d <span class="string">"/"</span> -f2` cat /tmp/log_level</span></span><br><span class="line">DEBUG</span><br></pre></td></tr></table></figure>

<p><strong>ConfigMap 更新后滚动更新 Pod</strong></p>
<p><strong>注意：更新 ConfigMap 目前并不会触发相关 Pod 的滚动更新，可以通过修改 pod annotations 的方式强制触发滚动更新。</strong></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> kubectl patch deployment my-nginx --patch <span class="string">'&#123;"spec": &#123;"template": &#123;"metadata": &#123;"annotations": &#123;"version/config": "20190411" &#125;&#125;&#125;&#125;&#125;'</span></span></span><br></pre></td></tr></table></figure>

<p>这个例子里我们在 .spec.template.metadata.annotations 中添加 version/config ，每次通过修改version/config 来触发滚动更新。</p>
<p><strong>更新 ConfigMap后：</strong></p>
<ul>
<li><strong>使用该 ConfigMap 挂载的 Env 不会同步更新</strong></li>
<li><strong>使用该 ConfigMap 挂载的 Volume 中的数据需要一段时间（实测大概10秒）才能同步更新</strong></li>
</ul>
<h1 id="2-Secret"><a href="#2-Secret" class="headerlink" title="2. Secret"></a>2. Secret</h1><h2 id="2-1-Secret-介绍"><a href="#2-1-Secret-介绍" class="headerlink" title="2.1 Secret 介绍"></a>2.1 Secret 介绍</h2><p><strong>Secrect 解决了密码、token、密钥等敏感数据的配置问题</strong>，而不需要把这些敏感数据暴露到镜像或者 Pod Spec 中。Secret 可以以 Volume 或者环境变量的方式使用。</p>
<p>70：Secret 存储敏感数据。</p>
<p><strong>Secret 有三种类型：</strong></p>
<ul>
<li><strong>Service Account：用来访问 Kubernetes API，由 Kubernetes 自动创建，并且会自动挂载到 Pod 的 /run/secret/kubernetes.io/serviceaccount 目录中。</strong></li>
<li><strong>Opaque：base64 编码格式的 Secret，用来存储密码、密钥等。</strong></li>
<li><strong>kubernets.io/dockerconfigjson：用来存储私有 docker registry 的认知信息。</strong></li>
</ul>
<h2 id="2-2-Service-Account"><a href="#2-2-Service-Account" class="headerlink" title="2.2 Service Account"></a>2.2 Service Account</h2><p>Service Account 用来访问 Kubernetes API，由 Kubernetes 自动创建，并且会自动挂载到 Pod的<br>/run/secrets/kubernetes.io/serviceaccount 目录中。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> kubectl <span class="built_in">exec</span> kube-proxy-ffq2n -n kube-system -it /bin/sh</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> ls /run/secrets/kubernetes.io/serviceaccount</span></span><br><span class="line">ca.crt	namespace  token</span><br></pre></td></tr></table></figure>



<h2 id="2-3-Opaque-Secret"><a href="#2-3-Opaque-Secret" class="headerlink" title="2.3 Opaque Secret"></a>2.3 Opaque Secret</h2><p><strong>Ⅰ、创建说明</strong></p>
<p><strong>Opaque 类型的数据是一个 map 类型，要求 value 是 base64 编码格式：</strong></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> <span class="built_in">echo</span> -n <span class="string">"admin"</span> | base64</span></span><br><span class="line">YWRtaW4=</span><br><span class="line"><span class="meta">$</span><span class="bash"> <span class="built_in">echo</span> -n <span class="string">"1f2d1e2e67df"</span> | base64</span></span><br><span class="line">MWYyZDFlMmU2N2Rm</span><br></pre></td></tr></table></figure>

<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Secret</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">mysecret</span></span><br><span class="line"><span class="attr">type:</span> <span class="string">Opaque</span></span><br><span class="line"><span class="attr">data:</span></span><br><span class="line">  <span class="attr">password:</span> <span class="string">MWYyZDFlMmU2N2Rm</span></span><br><span class="line">  <span class="attr">username:</span> <span class="string">YWRtaW4=</span></span><br></pre></td></tr></table></figure>

<p><strong>Ⅱ、使用方式</strong><br><strong>1、将 Secret 挂载到 Volume 中</strong></p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">secret-test</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">secret-test</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">volumes:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">secrets</span></span><br><span class="line">      <span class="attr">secret:</span></span><br><span class="line">        <span class="attr">secretName:</span> <span class="string">mysecret</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">image:</span> <span class="string">wangyanglinux/myapp:v1</span></span><br><span class="line">      <span class="attr">name:</span> <span class="string">db</span></span><br><span class="line">      <span class="attr">volumeMounts:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">secrets</span></span><br><span class="line">          <span class="attr">mountPath:</span> <span class="string">"/etc/secrets"</span></span><br><span class="line">          <span class="attr">readOnly:</span> <span class="literal">true</span></span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> kubectl <span class="built_in">exec</span> seret-test -it /bin/sh</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> <span class="built_in">cd</span> /etc/secrets</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> ls </span></span><br><span class="line">password  username</span><br><span class="line"><span class="meta">$</span><span class="bash"> cat password</span></span><br><span class="line">1f2d1e2e67df</span><br><span class="line"><span class="meta">$</span><span class="bash"> cat username</span></span><br><span class="line">admin</span><br></pre></td></tr></table></figure>

<p><strong>在创建的时候使用 base64 加密保存，在使用时会自己进行解密。</strong></p>
<p><strong>2、将 Secret 导出到环境变量中</strong></p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">extensions/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Deployment</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">pod-deployment</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">replicas:</span> <span class="number">2</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">app:</span> <span class="string">pod-deployment</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">pod-1</span></span><br><span class="line">          <span class="attr">image:</span> <span class="string">wangyanglinux/myapp:v1</span></span><br><span class="line">          <span class="attr">ports:</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">80</span></span><br><span class="line">          <span class="attr">env:</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">TEST_USER</span></span><br><span class="line">              <span class="attr">valueFrom:</span></span><br><span class="line">                <span class="attr">secretKeyRef:</span></span><br><span class="line">                  <span class="attr">name:</span> <span class="string">mysecret</span></span><br><span class="line">                  <span class="attr">key:</span> <span class="string">username</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">TEST_PASSWORD</span></span><br><span class="line">              <span class="attr">valueFrom:</span></span><br><span class="line">                <span class="attr">secretKeyRef:</span></span><br><span class="line">                  <span class="attr">name:</span> <span class="string">mysecret</span></span><br><span class="line">                  <span class="attr">key:</span> <span class="string">password</span></span><br></pre></td></tr></table></figure>



<h2 id="2-4-kubernetes-io-dockerconfigjson"><a href="#2-4-kubernetes-io-dockerconfigjson" class="headerlink" title="2.4 kubernetes.io/dockerconfigjson"></a>2.4 kubernetes.io/dockerconfigjson</h2><p>使用 kubectl 创建 docker registry 认证的 secret</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> kubectl create secret docker-registry myregistrykey \</span></span><br><span class="line">--docker-server=DOCKER_REGISTRY_SERVER --docker-username=DOCKER_USER \</span><br><span class="line">--docker-password=DOCKER_PASSWORD --docker-email=DOCKER_EMAIL</span><br><span class="line">secret "myregistrykey" created.</span><br></pre></td></tr></table></figure>

<p>在创建 Pod 的时候，通过 <strong>imagePullSecret</strong> 来引用刚创建的 myregistry</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">foo</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">foo</span></span><br><span class="line">      <span class="attr">image:</span> <span class="string">hub.atguigu.com/private/myapp:v1</span></span><br><span class="line">      <span class="attr">imagePullSecrets:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">myregistrykey</span></span><br></pre></td></tr></table></figure>



<h1 id="3-Volume"><a href="#3-Volume" class="headerlink" title="3. Volume"></a>3. Volume</h1><h2 id="3-1-Volume-介绍"><a href="#3-1-Volume-介绍" class="headerlink" title="3.1 Volume 介绍"></a>3.1 Volume 介绍</h2><p>容器磁盘上的文件的生命周期是短暂的，这就使得在容器中运行重要应用时会出现一些问题：</p>
<ul>
<li>首先，当容器崩溃时，kubelet 会重启它，但是容器中的文件将丢失——容器以干净的状态（镜像最初的状态）重新启动。（70：这里和docker还是有所区别，docker中如果启动命令中加上restart: always，当容器内部进程关闭后，docker会负责重新引导启动进程，但不是以干净状态启动，而是保留里面的数据）</li>
<li>其次，在 Pod 中同时运行多个容器时，这些容器之间通常需要共享文件。Kubernetes 中的 Volume 抽象就很好的解决了这些问题。</li>
</ul>
<p><strong>Kubernetes 中的卷有明确的寿命——与封装它的 Pod 相同。所以，卷的生命比 Pod 中的所有的容器都长，当这个容器重启时数据仍然得以保存。当然，当 Pod 不再存在时，卷也将不复存在。也许更重要的是，Kubernetes 支持多种类型的卷，Pod 可以同时使用任意数量的卷。</strong></p>
<p>70：原理：pause 挂载绑定 Volume，而 Pod 所有容器共享 pause 的网络栈和存储卷。</p>
<p><strong>Kubernetes 支持以下类型的卷：</strong></p>
<p><code>awsElasticBlockStore</code> <code>azureDisk</code> <code>azureFile</code> <code>cephfs</code> <code>csi</code> <code>downwardAPI</code> <code>emptyDir</code><br><code>fc</code> <code>flocker</code> <code>gcePersistentDisk</code> <code>gitRepo</code> <code>glusterfs</code> <code>hostPath</code> <code>iscsi</code> <code>local</code> <code>nfs</code><br><code>persistentVolumeClaim</code> <code>projected</code> <code>portworxVolume</code> <code>quobyte</code> <code>rbd</code> <code>scaleIO</code> <code>secret</code><br><code>storageos</code> <code>vsphereVolume</code></p>
<h2 id="3-2-emptyDir"><a href="#3-2-emptyDir" class="headerlink" title="3.2 emptyDir"></a>3.2 emptyDir</h2><p><strong>当 Pod 被分配给节点时，首先创建 emptyDir 卷，并且只要该 Pod 在该节点上运行，该卷就会存在。正如卷的名字所述，它最初是空的。Pod 中的容器可以读取和写入 emptyDir 卷中的相同文件，尽管该卷可以挂载到每个容器中的相同或不同路径上。当出于任何原因从节点中删除 Pod 时， emptyDir 中的数据将被永久删除。</strong></p>
<p><strong>注意：容器崩溃不会从节点中移除 Pod，因此 emptyDir 卷中的数据在容器崩溃时是安全的。</strong></p>
<p><strong>emptyDir 的用法有：</strong></p>
<ul>
<li><strong>暂存空间，例如用于基于磁盘的合并排序</strong></li>
<li><strong>用作长时间计算崩溃恢复时的检查点</strong></li>
<li><strong>Web服务器容器提供数据时，保存内容管理器容器提取的文件</strong></li>
</ul>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">test-pd</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">image:</span> <span class="string">k8s.gcr.io/test-webserver</span></span><br><span class="line">      <span class="attr">name:</span> <span class="string">test-container</span></span><br><span class="line">      <span class="attr">volumeMounts:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">mountPath:</span> <span class="string">/cache</span></span><br><span class="line">          <span class="attr">name:</span> <span class="string">cache-volume</span></span><br><span class="line">  <span class="attr">volumes:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">cache-volume</span></span><br><span class="line">      <span class="attr">emptyDir:</span> <span class="string">&#123;&#125;</span></span><br></pre></td></tr></table></figure>



<h2 id="3-3-hostPath"><a href="#3-3-hostPath" class="headerlink" title="3.3 hostPath"></a>3.3 hostPath</h2><p><strong>hostPath 卷将主机节点的文件系统中的文件或目录挂载到集群中。</strong></p>
<p><strong>hostPath 的用途如下：</strong></p>
<ul>
<li><p><strong>运行需要访问 Docker 内部的容器；使用 /var/lib/docker 的 hostPath</strong></p>
</li>
<li><p><strong>在容器中运行 cAdvisor；使用 /dev/cgroups 的 hostPath</strong></p>
</li>
<li><p><strong>允许 pod 指定给定的 hostPath 是否应该在 pod 运行之前存在，是否应该创建，以及它应该以什么形式存在</strong></p>
</li>
</ul>
<p>除了所需的 path 属性之外，用户还可以为 hostPath 卷指定 <strong>type</strong>：</p>
<table>
<thead>
<tr>
<th>值</th>
<th>行为</th>
</tr>
</thead>
<tbody><tr>
<td></td>
<td>空字符串（默认）用于向后兼容，这意味着在挂载 hostPath 卷之前不会执行任何检查。</td>
</tr>
<tr>
<td>DirectoryOrCreate</td>
<td>如果在给定的路径上没有任何东西存在，那么将根据需要在那里创建一个空目录，权限设置为 0755，与 Kubelet 具有相同的组和所有权。</td>
</tr>
<tr>
<td>Directory</td>
<td>给定的路径下必须存在目录</td>
</tr>
<tr>
<td>FileOrCreate</td>
<td>如果在给定的路径上没有任何东西存在，那么会根据需要创建一个空文件，权限设置为 0644，与 Kubelet 具有相同的组和所有权。</td>
</tr>
<tr>
<td>File</td>
<td>给定的路径下必须存在文件</td>
</tr>
<tr>
<td>Socket</td>
<td>给定的路径下必须存在 UNIX 套接字</td>
</tr>
<tr>
<td>CharDevice</td>
<td>给定的路径下必须存在字符设备</td>
</tr>
<tr>
<td>BlockDevice</td>
<td>给定的路径下必须存在块设备</td>
</tr>
</tbody></table>
<p><strong>使用这种卷类型是请注意：</strong></p>
<ul>
<li><strong>由于每个节点上的文件都不同，具有相同配置（例如从 podTemplate 创建的）的 pod 在不同节点上的行为可能会有所不同。</strong>（70：一个Node上有mfs目录，而另一个Node上没有）</li>
<li><strong>当 Kubernetes 按照计划添加资源感知调度时，将无法考虑 hostPath 使用的资源。</strong></li>
<li><strong>在底层主机上创建的文件或目录只能由 root 写入。您需要在特权容器中以 root 身份运行进程，或修改主机上的文件权限以便写入 hostPath 卷。</strong></li>
</ul>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">test-pd</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">image:</span> <span class="string">k8s.gcr.io/test-webserver</span></span><br><span class="line">      <span class="attr">name:</span> <span class="string">test-container</span></span><br><span class="line">      <span class="attr">volumeMounts:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">mountPath:</span> <span class="string">/test-pd</span></span><br><span class="line">          <span class="attr">name:</span> <span class="string">test-volume</span></span><br><span class="line">  <span class="attr">volumes:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">test-volume</span></span><br><span class="line">      <span class="attr">hostPath:</span></span><br><span class="line">        <span class="comment"># directory location on host</span></span><br><span class="line">        <span class="attr">path:</span> <span class="string">/data</span></span><br><span class="line">        <span class="comment"># this field is optional</span></span><br><span class="line">        <span class="attr">type:</span> <span class="string">Directory</span></span><br></pre></td></tr></table></figure>



<h1 id="4-Persistent-Volume"><a href="#4-Persistent-Volume" class="headerlink" title="4. Persistent Volume"></a>4. Persistent Volume</h1><h2 id="4-1-PersistentVolume-介绍"><a href="#4-1-PersistentVolume-介绍" class="headerlink" title="4.1 PersistentVolume 介绍"></a>4.1 PersistentVolume 介绍</h2><p><strong>PersistentVolume（PV）</strong>是由管理员设置的存储，它是集群的一部分。就像节点是集群中的资源一样，PV 也是集群中的资源。 PV 是 Volume 之类的卷插件，但具有<strong>独立于使用 PV 的 Pod 的生命周期</strong>。此 API 对象包含存储实现的细节，即 NFS、iSCSI 或特定于云供应商的存储系统。</p>
<p>70：K8S 外部可能有存储工程师创建的不同存储资源，如nfs、mfs、iscsi等。k8s中提供了一种新的对象资源 PV，先在K8S集群中创建出 PV，不同的 PV 对应不同的存储资源。这样应用程序工程师在部署 Pod 时直接调用集群内部的 PV 即可完成存储的使用，不用去管后端的实现。</p>
<p><strong>PersistentVolumeClaim（PVC）</strong>是用户存储的请求。它与 Pod 相似。Pod 消耗节点资源，PVC 消耗 PV 资源。Pod 可以请求特定级别的资源（CPU 和内存）。<strong>PVC 可以请求特定的大小和访问模式</strong>（例如，可以以读/写一次或只读多次模式挂载）。</p>
<p>70：不同的 PV 具有不同的速度、大小，所以在使用时还需要判断该 PV 是否满足需求。如果有上万个 PV，在使用时需要一个一个去匹配，很费时。所以在创建 Pod 时可以给它附带一个 PVC 请求，PVC 请求即根据需求去寻找一个合适的 PV 进行绑定。PVC 会选择满足需求但资源量更 小的 PV。</p>
<p><strong>静态 PV</strong> 是集群管理员创建一些 PV。它们带有可供集群用户使用的实际存储的细节。它们存在于 Kubernetes API 中，可用于消费。</p>
<p><strong>动态 PV</strong> ：当管理员创建的静态 PV 都不匹配用户的 PersistentVolumeClaim 时，集群可能会尝试动态地为 PVC 创建卷。此配置基于 StorageClasses ：PVC 必须请求 [存储类]，并且管理员必须创建并配置该类才能进行动态创建。声明该类为 “” 可以有效地禁用其动态配置。要启用基于存储级别的动态存储配置，集群管理员需要启用 API server 上的 DefaultStorageClass [准入控制器]。例如，通过确保 DefaultStorageClass 位于 API server 组件的 –admission-control 标志，使用逗号分隔的有序值列表中，可以完成此操作。</p>
<p><strong>绑定</strong>：master 中的控制环路监视新的 PVC，寻找匹配的 PV（如果可能），并将它们绑定在一起。如果为新的 PVC 动态调配 PV，则该环路将始终将该 PV 绑定到 PVC。否则，<strong>用户总会得到他们所请求的存储，但是容量可能超出要求的数量</strong>。一旦 PV 和 PVC 绑定后， PersistentVolumeClaim 绑定是<strong>排他性的</strong>，不管它们是如何绑定的。 <strong>PVC 跟 PV 绑定是一对一的映射</strong>。</p>
<h2 id="4-2-持久化卷声明的保护"><a href="#4-2-持久化卷声明的保护" class="headerlink" title="4.2 持久化卷声明的保护"></a>4.2 持久化卷声明的保护</h2><p><strong>PVC 保护</strong>的目的是<strong>确保由 pod 正在使用的 PVC 不会从系统中移除</strong>，因为如果被移除的话可能会导致数据丢失。<strong>当启用PVC 保护 alpha 功能时，如果用户删除了一个 pod 正在使用的 PVC，则该 PVC 不会被立即删除。PVC 的删除将被推迟，直到 PVC 不再被任何 pod 使用。</strong></p>
<h2 id="4-3-持久化卷类型"><a href="#4-3-持久化卷类型" class="headerlink" title="4.3 持久化卷类型"></a>4.3 持久化卷类型</h2><p>PersistentVolume 类型以插件形式实现。Kubernetes 目前支持以下插件类型：</p>
<p><code>GCEPersistentDisk</code> <code>AWSElasticBlockStore</code> <code>AzureFile</code> <code>AzureDisk</code> <code>FC (Fibre Channel)</code><br><code>FlexVolume</code> <code>Flocker</code> <code>NFS</code> <code>iSCSI</code> <code>RBD (Ceph Block Device)</code> <code>CephFS</code><br><code>Cinder (OpenStack block storage)</code> <code>Glusterfs</code> <code>VsphereVolume</code> <code>Quobyte</code> <code>Volumes</code><br><code>HostPath</code> <code>VMware</code> <code>Photon</code> <code>Portworx</code> <code>Volumes</code> <code>ScaleIO</code> <code>Volumes</code> <code>StorageOS</code></p>
<p>持久卷演示代码：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">PersistentVolume</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">pv0003</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">capacity:</span></span><br><span class="line">    <span class="attr">storage:</span> <span class="string">5Gi</span></span><br><span class="line">  <span class="attr">volumeMode:</span> <span class="string">Filesystem</span></span><br><span class="line">  <span class="attr">accessModes:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">ReadWriteOnce</span></span><br><span class="line">  <span class="attr">persistentVolumeReclaimPolicy:</span> <span class="string">Retain</span></span><br><span class="line">  <span class="attr">storageClassName:</span> <span class="string">slow</span></span><br><span class="line">  <span class="attr">mountOptions:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">hard</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">nfsvers=4.1</span></span><br><span class="line">  <span class="attr">nfs:</span></span><br><span class="line">    <span class="attr">path:</span> <span class="string">/tmp</span></span><br><span class="line">    <span class="attr">server:</span> <span class="number">172.17</span><span class="number">.0</span><span class="number">.2</span></span><br></pre></td></tr></table></figure>



<h2 id="4-4-PV-访问模式"><a href="#4-4-PV-访问模式" class="headerlink" title="4.4 PV 访问模式"></a>4.4 PV 访问模式</h2><p>PersistentVolume 可以以资源提供者支持的任何方式挂载到主机上。如下表所示，供应商具有不同的功能，每个 PV 的访问模式都将被设置为该卷支持的特定模式。例如，NFS 可以支持多个读/写客户端，但特定的 NFS PV 可能以只读方式导出到服务器上。每个 PV 都有一套自己的用来描述特定功能的访问模式。</p>
<ul>
<li><strong>ReadWriteOnce——该卷可以被单个节点以读/写模式挂载</strong></li>
<li><strong>ReadOnlyMany——该卷可以被多个节点以只读模式挂载</strong></li>
<li><strong>ReadWriteMany——该卷可以被多个节点以读/写模式挂载</strong></li>
</ul>
<p>在命令行中，访问模式缩写为：</p>
<ul>
<li><strong>RWO - ReadWriteOnce</strong></li>
<li><strong>ROX - ReadOnlyMany</strong></li>
<li><strong>RWX - ReadWriteMany</strong></li>
</ul>
<p><strong>注意：一个卷一次只能使用一种访问模式挂载，即使它支持很多访问模式。例如：GCEPersistentDisk 可以由单个节点作为 ReadWriteOnce 模式挂载，或由多个节点以  ReadOnlyMany 模式挂载，但不能同时挂载</strong></p>
<table>
<thead>
<tr>
<th align="center">Volume 插件</th>
<th align="center">ReadWriteOnce</th>
<th align="center">ReadOnlyMany</th>
<th align="center">ReadWriteMany</th>
</tr>
</thead>
<tbody><tr>
<td align="center">AWSElasticBlockStoreAWSElasticBlockStore</td>
<td align="center">✓</td>
<td align="center">-</td>
<td align="center">-</td>
</tr>
<tr>
<td align="center">AzureFile</td>
<td align="center">✓</td>
<td align="center">✓</td>
<td align="center">✓</td>
</tr>
<tr>
<td align="center">AzureDisk</td>
<td align="center">✓</td>
<td align="center">-</td>
<td align="center">-</td>
</tr>
<tr>
<td align="center">CephFS</td>
<td align="center">✓</td>
<td align="center">✓</td>
<td align="center">✓</td>
</tr>
<tr>
<td align="center">Cinder</td>
<td align="center">✓</td>
<td align="center">-</td>
<td align="center">-</td>
</tr>
<tr>
<td align="center">FC</td>
<td align="center">✓</td>
<td align="center">✓</td>
<td align="center">-</td>
</tr>
<tr>
<td align="center">FlexVolume</td>
<td align="center">✓</td>
<td align="center">✓</td>
<td align="center">-</td>
</tr>
<tr>
<td align="center">Flocker</td>
<td align="center">✓</td>
<td align="center">-</td>
<td align="center">-</td>
</tr>
<tr>
<td align="center">GCEPersistentDisk</td>
<td align="center">✓</td>
<td align="center">✓</td>
<td align="center">-</td>
</tr>
<tr>
<td align="center">Glusterfs</td>
<td align="center">✓</td>
<td align="center">✓</td>
<td align="center">✓</td>
</tr>
<tr>
<td align="center">HostPath</td>
<td align="center">✓</td>
<td align="center">-</td>
<td align="center">-</td>
</tr>
<tr>
<td align="center">iSCSI</td>
<td align="center">✓</td>
<td align="center">✓</td>
<td align="center">-</td>
</tr>
<tr>
<td align="center">PhotonPersistentDisk</td>
<td align="center">✓</td>
<td align="center">-</td>
<td align="center">-</td>
</tr>
<tr>
<td align="center">Quobyte</td>
<td align="center">✓</td>
<td align="center">✓</td>
<td align="center">✓</td>
</tr>
<tr>
<td align="center">NFS</td>
<td align="center">✓</td>
<td align="center">✓</td>
<td align="center">✓</td>
</tr>
<tr>
<td align="center">RBD</td>
<td align="center">✓</td>
<td align="center">✓</td>
<td align="center">-</td>
</tr>
<tr>
<td align="center">VsphereVolume</td>
<td align="center">✓</td>
<td align="center">-</td>
<td align="center">-（当 pod 并列时有效）</td>
</tr>
<tr>
<td align="center">PortworxVolume</td>
<td align="center">✓</td>
<td align="center">-</td>
<td align="center">✓</td>
</tr>
<tr>
<td align="center">ScaleIO</td>
<td align="center">✓</td>
<td align="center">✓</td>
<td align="center">-</td>
</tr>
<tr>
<td align="center">StorageOS</td>
<td align="center">✓</td>
<td align="center">-</td>
<td align="center">-</td>
</tr>
</tbody></table>
<h2 id="4-5-回收策略"><a href="#4-5-回收策略" class="headerlink" title="4.5 回收策略"></a>4.5 回收策略</h2><ul>
<li><strong>Retain（保留）—— 手动回收（kubectl edit 进去手动删除）</strong></li>
<li><strong>Recycle（回收）—— 基本擦除（ rm -rf /thevolume/* ）</strong></li>
<li><strong>Delete（删除）—— 关联的存储资产（例如 AWS EBS、GCE PD、Azure Disk 和 OpenStack Cinder 卷）将被删除</strong></li>
</ul>
<p>当前，只有 NFS 和 HostPath 支持回收策略。AWS EBS、GCE PD、Azure Disk 和 Cinder 卷支持删除策略。</p>
<p>70：目前 NFS 好像不支持 Recycle 了，以最新文档为准。</p>
<h2 id="4-6-状态"><a href="#4-6-状态" class="headerlink" title="4.6 状态"></a>4.6 状态</h2><p>卷可以处于以下的某种状态：</p>
<ul>
<li><strong>Available（可用）—— 一块空闲资源还没有被任何声明绑定</strong></li>
<li><strong>Bound（已绑定）—— 卷已经被声明绑定</strong></li>
<li><strong>Released（已释放）—— 声明被删除，但是资源还未被集群重新声明</strong></li>
<li><strong>Failed（失败）—— 该卷的自动回收失败</strong></li>
</ul>
<p><strong>命令行会显示绑定到 PV 的 PVC 的名称</strong></p>
<img src="https://blog-love70-img.oss-cn-chengdu.aliyuncs.com/blog.love70.cn/image-20200321174040532.png" alt="image-20200321173909408" style="zoom:50%;" />

<img src="https://blog-love70-img.oss-cn-chengdu.aliyuncs.com/blog.love70.cn/image-20200321173909408.png" alt="image-20200321174040532" style="zoom:50%;" />



<h2 id="4-7-持久化演示说明-NFS"><a href="#4-7-持久化演示说明-NFS" class="headerlink" title="4.7 持久化演示说明 - NFS"></a>4.7 持久化演示说明 - NFS</h2><p><strong>Ⅰ、安装 NFS 服务器</strong></p>
<p>NFS 服务器端：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> yum install -y nfs-common nfs-utils rpcbind</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> mkdir /nfs</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> chmod 666 /nfs</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> chown nfsnobody /nfs</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> cat /etc/exports</span></span><br><span class="line">/nfs *(rw,no_root_squash,no_all_squash,sync)</span><br><span class="line"><span class="meta">$</span><span class="bash"> systemctl start rpcbind</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> systemctl start nfs</span></span><br></pre></td></tr></table></figure>

<p>客户端（所有K8S节点）：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> yum install -y nfs-utils rpcbind</span></span><br></pre></td></tr></table></figure>

<p><strong>Ⅱ、部署 PV</strong></p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">PersistentVolume</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">nfspv1</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">capacity:</span></span><br><span class="line">    <span class="attr">storage:</span> <span class="string">1Gi</span></span><br><span class="line">  <span class="attr">accessModes:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">ReadWriteOnce</span></span><br><span class="line">  <span class="attr">persistentVolumeReclaimPolicy:</span> <span class="string">Retain</span></span><br><span class="line">  <span class="attr">storageClassName:</span> <span class="string">nfs</span></span><br><span class="line">  <span class="attr">nfs:</span></span><br><span class="line">    <span class="attr">path:</span> <span class="string">/nfs</span></span><br><span class="line">    <span class="attr">server:</span> <span class="number">10.66</span><span class="number">.66</span><span class="number">.10</span></span><br></pre></td></tr></table></figure>

<p><strong>Ⅲ、创建服务并使用 PVC</strong></p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">clusterIP:</span> <span class="string">None</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">nginx</span></span><br><span class="line">  <span class="attr">ports:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">web</span></span><br><span class="line">      <span class="attr">port:</span> <span class="number">80</span></span><br><span class="line">      </span><br><span class="line"><span class="meta">---</span></span><br><span class="line"></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">StatefulSet</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">web</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">app:</span> <span class="string">nginx</span></span><br><span class="line">  <span class="attr">serviceName:</span> <span class="string">"nginx"</span></span><br><span class="line">  <span class="attr">replicas:</span> <span class="number">3</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">app:</span> <span class="string">nginx</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line">          <span class="attr">image:</span> <span class="string">k8s.gcr.io/nginx-slim:0.8</span></span><br><span class="line">          <span class="attr">ports:</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">web</span></span><br><span class="line">              <span class="attr">containerPort:</span> <span class="number">80</span>              </span><br><span class="line">          <span class="attr">volumeMounts:</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">www</span></span><br><span class="line">              <span class="attr">mountPath:</span> <span class="string">/usr/share/nginx/html</span></span><br><span class="line">    <span class="attr">volumeClaimTemplates:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">metadata:</span></span><br><span class="line">          <span class="attr">name:</span> <span class="string">www</span></span><br><span class="line">          <span class="attr">spec:</span></span><br><span class="line">            <span class="attr">accessModes:</span> <span class="string">[</span> <span class="string">"ReadWriteOnce"</span> <span class="string">]</span></span><br><span class="line">            <span class="attr">storageClassName:</span> <span class="string">"nfs"</span></span><br><span class="line">            <span class="attr">resources:</span></span><br><span class="line">              <span class="attr">requests:</span></span><br><span class="line">                <span class="attr">storage:</span> <span class="string">1Gi</span></span><br></pre></td></tr></table></figure>



<h2 id="4-8-关于-StatefulSet"><a href="#4-8-关于-StatefulSet" class="headerlink" title="4.8 关于 StatefulSet"></a>4.8 关于 StatefulSet</h2><ul>
<li><strong>匹配 Pod name ( 网络标识 ) 的模式为：$(statefulset名称)-$(序号)，比如上面的示例：web-0，web-1，</strong><br>  <strong>web-2。</strong></li>
<li><strong>StatefulSet 为每个 Pod 副本创建了一个 DNS 域名，这个域名的格式为： $(podname).(headless server name)，也就意味着服务间是通过Pod域名来通信而非 Pod IP，因为当Pod所在Node发生故障时， Pod 会被飘移到其它 Node 上，Pod IP 会发生变化，但是 Pod 域名不会有变化。</strong></li>
<li><strong>StatefulSet 使用 Headless 服务来控制 Pod 的域名，这个域名的 FQDN 为：$(service</strong><br>  <strong>name).$(namespace).svc.cluster.local，其中，“cluster.local” 指的是集群的域名。</strong></li>
<li><strong>根据 volumeClaimTemplates，为每个 Pod 创建一个 pvc，pvc 的命名规则匹配模式：</strong><br>  <strong>(volumeClaimTemplates.name)-(pod_name)，比如上面的 volumeMounts.name=www， Pod</strong><br>  <strong>name=web-[0-2]，因此创建出来的 PVC 是 www-web-0、www-web-1、www-web-2。</strong></li>
<li><strong>删除 Pod 不会删除其 pvc，手动删除 pvc 将自动释放 pv。</strong></li>
</ul>
<p>StatefulSet 的启停顺序：</p>
<ul>
<li><strong>有序部署：部署StatefulSet时，如果有多个Pod副本，它们会被顺序地创建（从0到N-1）并且，在下一个</strong><br>  <strong>Pod运行之前所有之前的Pod必须都是Running和Ready状态。</strong></li>
<li><strong>有序删除：当Pod被删除时，它们被终止的顺序是从N-1到0。</strong></li>
<li><strong>有序扩展：当对Pod执行扩展操作时，与部署一样，它前面的Pod必须都处于Running和Ready状态。</strong></li>
</ul>
<p>StatefulSet 使用场景：</p>
<ul>
<li><strong>稳定的持久化存储，即Pod重新调度后还是能访问到相同的持久化数据，基于 PVC 来实现。</strong></li>
<li><strong>稳定的网络标识符，即 Pod 重新调度后其 PodName 和 HostName 不变。</strong></li>
<li><strong>有序部署，有序扩展，基于 init containers 来实现。</strong></li>
<li><strong>有序收缩。</strong></li>
</ul>
]]></content>
      <categories>
        <category>Kubernetes</category>
      </categories>
  </entry>
  <entry>
    <title>五、Kubernetes 服务</title>
    <url>/2020/03/05/kubernetes%E7%AC%94%E8%AE%B0/5.Kubernete%E6%9C%8D%E5%8A%A1/</url>
    <content><![CDATA[<h1 id="1-Service-的概念"><a href="#1-Service-的概念" class="headerlink" title="1. Service 的概念"></a>1. Service 的概念</h1><p>Kubernetes <strong>Service</strong>定义了这样一种抽象：<strong>一个Pod的逻辑分组，一种可以访问它们的策略——通常称为微服务</strong>。这一组Pod能够被Service访问到，通常是通过<strong>Label Selector</strong>。</p>
<a id="more"></a>
<img src="https://blog-love70-img.oss-cn-chengdu.aliyuncs.com/blog.love70.cn/image-20200317111050561.png" alt="image-20200317111050561" style="zoom:50%;" />

<p>Service能够提供<strong>负载均衡</strong>的能力，但是在使用上有以下限制：</p>
<ul>
<li><strong>只能提供4层负载均衡的能力</strong>，而没有7层功能，但有时我们可能需要更多的匹配规则来转发请求，这点上4层负载均衡是不支持的。</li>
</ul>
<h1 id="2-VIP-和-Service-代理"><a href="#2-VIP-和-Service-代理" class="headerlink" title="2. VIP 和 Service 代理"></a>2. VIP 和 Service 代理</h1><p>在Kubernetes集群中，每个Node运行一个<strong>kube-proxy</strong>进程。kube-proxy负载为Service实现了一种<strong>VIP（虚拟IP）</strong>的形式，而不是ExternalName的形式。在Kubernetes v1.0版本，代理完全在<strong>userspace</strong>。在Kubernetes v1.1版本，新增<strong>iptable</strong>代理，但并不是默认的运行模式。从Kubernetes v1.2起，默认就是iptables代理。在Kubernetes v1.8.0-beta.0中，添加了<strong>ipvs</strong>代理。</p>
<p><strong>在Kubernetes 1.14版本开始默认使用ipvs代理</strong></p>
<p>在Kubernetes v1.0版本，Service是“4层”（TCP/UDP over IP）概念。在Kubernetes v1.1版本，新增了<strong>Ingress</strong> API（beta版），用来表示“7层”（HTTP）服务<strong>。</strong></p>
<p><strong>为何不使用round-robin DNS？</strong></p>
<p>70：DNS会在客户端上进行缓存，一旦有某个地址信息，之后访问都是该地址。</p>
<h1 id="3-代理模式的分类"><a href="#3-代理模式的分类" class="headerlink" title="3. 代理模式的分类"></a>3. 代理模式的分类</h1><h2 id="3-1-userspace-代理模式"><a href="#3-1-userspace-代理模式" class="headerlink" title="3.1 userspace 代理模式"></a>3.1 userspace 代理模式</h2><img src="https://blog-love70-img.oss-cn-chengdu.aliyuncs.com/blog.love70.cn/image-20200317112600628.png" alt="image-20200317112600628" style="zoom:50%;" />



<h2 id="3-2-iptables-代理模式"><a href="#3-2-iptables-代理模式" class="headerlink" title="3.2 iptables 代理模式"></a>3.2 iptables 代理模式</h2><img src="https://blog-love70-img.oss-cn-chengdu.aliyuncs.com/blog.love70.cn/image-20200317112636720.png" alt="image-20200317112636720" style="zoom:50%;" />



<h2 id="3-3-ipvs-代理模式"><a href="#3-3-ipvs-代理模式" class="headerlink" title="3.3 ipvs 代理模式"></a>3.3 ipvs 代理模式</h2><p><strong>这种模式，kube-proxy会监视Kubernetes Service对象和Endpoints，调用netlink接口以相应地创建ipvs规则并定期与Kubernetes Service对象和Endpoints对象同步ipvs规则，以确保ipvs状态与期望一致。访问服务时，流量将被重定向到其中一个后端。</strong></p>
<p>与iptables类似，ipvs有netfilter的hook功能，但使用哈希表作为底层数据结构并在内核空间中工作。这意味着ipvs可以<strong>更快地重定向流量</strong>，并且在同步代理规则时具有<strong>更好地性能</strong>。此外，ipvs<strong>为负载均衡算法提供了更多选项</strong>，例如：</p>
<ul>
<li><strong>rr</strong>：轮询调度</li>
<li><strong>lc</strong>：最小连接数</li>
<li><strong>dh</strong>：目标哈希</li>
<li><strong>sh</strong>：源哈希</li>
<li><strong>sed</strong>：最短期望延迟</li>
<li><strong>nq</strong>：不排队调度</li>
</ul>
<p><strong>注意：</strong>ipvs模式假定在运行kube-proxy之前在节点上都已经安装了IPVS内核模块。当kube-proxy以ipvs代理模式启动时，kube-proxy将验证节点上是否安装了IPVS模块，如果未安装，则kube-proxy将回退到iptables代理模式。</p>
<img src="https://blog-love70-img.oss-cn-chengdu.aliyuncs.com/blog.love70.cn/image-20200319154604544.png" alt="image-20200317113258867" style="zoom:50%;" />



<h1 id="4-Service-的类型"><a href="#4-Service-的类型" class="headerlink" title="4. Service 的类型"></a>4. Service 的类型</h1><p>Service在Kubernetes中有以下四种类型：</p>
<ul>
<li><strong>ClusterIP</strong>：默认类型，自动分配一个仅 Cluster 内部可以访问的虚拟IP。</li>
<li><strong>NodePort</strong>：在 ClusterIP 基础上为 Service 在每台机器上绑定一个端口，这样就可以通过 : NodePort 来访问服务。</li>
<li><strong>LoadBalancer</strong>：在 NodePort 的基础上，借助 cloud provider 创建一个外部负载均衡器，并将请求转发到 : NodePort。</li>
<li><strong>ExternalName</strong>：把集群外部的服务进入到集群内部来，在集群内部直接使用。没有任何类型代理被创建，这只有Kubernetes 1.7或更高版本的kube-dns才支持。</li>
</ul>
<img src="https://blog-love70-img.oss-cn-chengdu.aliyuncs.com/blog.love70.cn/image-20200317114117470.png" alt="image-20200319154604544" style="zoom:50%;" />

<p>70：我删除一个SVC后IPVS规则并没有立即发生改变，通过原有地址仍然可以访问，不知道要过多久才会自动改变？重启主机后，IPVS规则是重新一条条的写入，删除前SVC的规则就不会再写入了。</p>
<h2 id="4-1-Cluster-IP"><a href="#4-1-Cluster-IP" class="headerlink" title="4.1 Cluster IP"></a>4.1 Cluster IP</h2><p><strong>Cluster IP主要在每个Node节点使用ipvs（iptables），将发向Cluster IP对应端口的数据，转发到kube-proxy中。然后kube-proxy自己内部实现有负载均衡的方法，并可以查询到这个Service下对应Pod的地址和端口，进而把数据转发给对应的Pod的地址和端口。</strong>（70：转发到kube-proxy，不是只有userspace才会转发到kube-proxy吗？）</p>
<img src="https://blog-love70-img.oss-cn-chengdu.aliyuncs.com/blog.love70.cn/image-20200317161145733.png" alt="image-20200317114117470" style="zoom:50%;" />

<p>为了实现图上的功能，主要需要以下几个组件的协同工作：</p>
<ul>
<li><strong>apiserver</strong>：用户通过kubectl命令向apiserver发送创建Service的命令，apiserver接收到请求后将数据存储到etcd中。</li>
<li><strong>kube-proxy</strong>：Kubernetesd的每个节点中都有一个叫做kube-proxy的进程，这个进程负责感知Service，Pod的变化，并将变化的信息写入本地的ipvs（iptables）规则中。</li>
<li><strong>ipvs（iptables）</strong>使用<strong>NAT</strong>等技术将virtualIP的流量转至endpoint中。</li>
</ul>
<p><strong>创建myapp-deployment.yaml文件</strong></p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Deployment</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">myapp-deploy</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">default</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">replicas:</span> <span class="number">3</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">app:</span> <span class="string">myapp</span></span><br><span class="line">      <span class="attr">release:</span> <span class="string">stable</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">app:</span> <span class="string">myapp</span></span><br><span class="line">        <span class="attr">release:</span> <span class="string">stable</span></span><br><span class="line">        <span class="attr">env:</span> <span class="string">test</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">myapp</span></span><br><span class="line">          <span class="attr">image:</span> <span class="string">wangyanglinux/myapp:v1</span></span><br><span class="line">          <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span></span><br><span class="line">          <span class="attr">ports:</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">http</span></span><br><span class="line">              <span class="attr">containerPort:</span> <span class="number">80</span></span><br></pre></td></tr></table></figure>

<p><strong>创建myapp-service.yaml文件</strong></p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">myapp-service</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">default</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">type:</span> <span class="string">ClusterIP</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">myapp</span></span><br><span class="line">    <span class="attr">release:</span> <span class="string">stable</span></span><br><span class="line">  <span class="attr">ports:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">http</span></span><br><span class="line">      <span class="attr">port:</span> <span class="number">80</span>		<span class="comment"># Service port</span></span><br><span class="line">      <span class="attr">targetPort:</span> <span class="number">80</span>  <span class="comment"># Pod port</span></span><br></pre></td></tr></table></figure>



<h2 id="4-2-Headless-Service"><a href="#4-2-Headless-Service" class="headerlink" title="4.2 Headless Service"></a>4.2 Headless Service</h2><p>有时<strong>不需要或不想要负载均衡，以及单独的Service IP</strong>。遇到这种情况，可以通过指定ClusterIP（spec.clusterIP）的值为“None”来创建<strong>Headless Service</strong>。<strong>这类Service并不会分配Cluster IP，kube-proxy不会处理它们，而且平台也不会为它们进行负载均衡和路由。</strong></p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">myapp-headless</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">default</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">myapp</span></span><br><span class="line">  <span class="attr">clusterIP:</span> <span class="string">"None"</span></span><br><span class="line">  <span class="attr">ports:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">port:</span> <span class="number">80</span></span><br><span class="line">      <span class="attr">targetPort:</span> <span class="number">80</span></span><br></pre></td></tr></table></figure>

<p>SVC一旦创建成功，会写入到CoreDNS中，写入的格式为：<code>SVC_NAME.NAMESPACE.svc.cluster.local.</code></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> dig -t A myapp-headless.default.svc.cluster.local. @10.96.0.10</span></span><br></pre></td></tr></table></figure>



<h2 id="4-3-NodePort"><a href="#4-3-NodePort" class="headerlink" title="4.3 NodePort"></a>4.3 NodePort</h2><p><strong>NodePort</strong>的原理在于<strong>在node上开了一个端口，将向该端口的流量导入到kube-proxy，然后由kube-proxy进一步转发给对应的Pod</strong>。</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">myapp-nodeport</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">default</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">type:</span> <span class="string">NodePort</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">myapp</span></span><br><span class="line">    <span class="attr">release:</span> <span class="string">stable</span></span><br><span class="line">  <span class="attr">ports:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">http</span></span><br><span class="line">      <span class="attr">port:</span> <span class="number">80</span></span><br><span class="line">      <span class="attr">targetPort:</span> <span class="number">80</span></span><br></pre></td></tr></table></figure>

<p><strong>查询流程</strong></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> ipvsadm -Ln</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> iptables -t nat -nvL</span></span><br></pre></td></tr></table></figure>



<h2 id="4-4-LoadBalancer"><a href="#4-4-LoadBalancer" class="headerlink" title="4.4 LoadBalancer"></a>4.4 LoadBalancer</h2><p>LoadBalancer和NodePort其实是同一种方式。区别在于LoadBalancer比NodePort多了一步，就是<strong>可以调用cloud provider去创建LB来向节点导流</strong>。</p>
<img src="https://blog-love70-img.oss-cn-chengdu.aliyuncs.com/blog.love70.cn/image-20200317113258867.png" alt="image-20200317155134956" style="zoom:50%;" />



<h2 id="4-5-ExternalName"><a href="#4-5-ExternalName" class="headerlink" title="4.5 ExternalName"></a>4.5 ExternalName</h2><p>这种类型的 Service 通过返回 CNAME 和它的值，可以将服务映射到 externalName 字段的内容（例如：hub.atguigu.com）。ExternalName Service 是 Service 的特例，它没有 selector，也没有定义任何的端口和Endpoint。相反的，对于运行在集群外部的服务，它通过返回该外部服务的别名这种方式来提供服务。</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">myapp-external</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">default</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">type:</span> <span class="string">ExternalName</span></span><br><span class="line">  <span class="attr">externalName:</span> <span class="string">hub.atguigu.com</span></span><br></pre></td></tr></table></figure>

<p>当查询主机 myapp-external.default.svc.cluster.local (SVC_NAME.NAMESPACE.svc.cluster.local.) 时，集群的DNS服务将返回一个值 my.database.example.com 的 CNAME记录。因此集群内部只需要使用SVC域名，当extenalName变化时改SVC即可，集群内部不用变。访问这个服务的工作方式和其他的相同，唯一不同的是重定向发生在DNS层，而且不会进行代理或转发。</p>
<h1 id="5-Ingress"><a href="#5-Ingress" class="headerlink" title="5. Ingress"></a>5. Ingress</h1><h2 id="5-1-Ingress-介绍"><a href="#5-1-Ingress-介绍" class="headerlink" title="5.1 Ingress 介绍"></a>5.1 Ingress 介绍</h2><p>Ingress提供了一个API接口暴露方式，拿Ingress实现的方案有很多（LVS、HAPROXY、NGINX），这里用到的是ingress-nginx。（70：简单来说ingress-nginx会帮我们部署一个nginx，会自动帮我们进行nginx规则的配置，可以进入ingress-nginx的Pod节点查看nginx.conf）</p>
<p>Ingress-Nginx github地址：<a href="https://github.com/kubernetes/ingress-nginx" target="_blank" rel="noopener">https://github.com/kubernetes/ingress-nginx</a></p>
<p>Ingress-Nginx 官网网站地址：<a href="https://kubernetes.github.io/ingress-nginx/" target="_blank" rel="noopener">https://kubernetes.github.io/ingress-nginx/</a></p>
<img src="https://blog-love70-img.oss-cn-chengdu.aliyuncs.com/blog.love70.cn/image-20200317161218700.png" alt="image-20200317161145733" style="zoom:50%;" />

<img src="https://blog-love70-img.oss-cn-chengdu.aliyuncs.com/blog.love70.cn/image-20200317155134956.png" alt="image-20200317161218700" style="zoom:50%;" />



<h2 id="5-2-部署-Ingress-Nginx"><a href="#5-2-部署-Ingress-Nginx" class="headerlink" title="5.2 部署 Ingress-Nginx"></a>5.2 部署 Ingress-Nginx</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> kubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/nginx-0.30.0/deploy/static/mandatory.yaml</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> kubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/nginx-0.30.0/deploy/static/provider/baremetal/service-nodeport.yaml</span></span><br></pre></td></tr></table></figure>



<h2 id="5-3-Ingress-HTTP-代理访问"><a href="#5-3-Ingress-HTTP-代理访问" class="headerlink" title="5.3 Ingress HTTP 代理访问"></a>5.3 Ingress HTTP 代理访问</h2><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">extensions/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Deployment</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">nginx-deployment</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">replicas:</span> <span class="number">2</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line">          <span class="attr">image:</span> <span class="string">wangyanglinux/myapp:v1</span></span><br><span class="line">          <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span></span><br><span class="line">          <span class="attr">ports:</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">80</span></span><br><span class="line">        </span><br><span class="line"><span class="meta">---</span></span><br><span class="line"></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">nginx-svc</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">type:</span> <span class="string">ClusterIP</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line">  <span class="attr">ports:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">port:</span> <span class="number">80</span></span><br><span class="line">    <span class="attr">targetPort:</span> <span class="number">80</span></span><br><span class="line">    <span class="attr">protocol:</span> <span class="string">TCP</span></span><br><span class="line">    </span><br><span class="line"><span class="meta">---</span></span><br><span class="line"></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">extensions/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Ingress</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">nginx-ingress</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">rules:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">host:</span> <span class="string">www1.atguigu.com</span></span><br><span class="line">      <span class="attr">http:</span></span><br><span class="line">        <span class="attr">paths:</span></span><br><span class="line">          <span class="bullet">-</span> <span class="attr">path:</span> <span class="string">/</span></span><br><span class="line">            <span class="attr">backend:</span></span><br><span class="line">              <span class="attr">serviceName:</span> <span class="string">nginx-svc</span></span><br><span class="line">              <span class="attr">servicePort:</span> <span class="number">80</span></span><br></pre></td></tr></table></figure>

<p>70：这里访问是通过ingress-nginx的端口进行访问，即安装ingress-nginx时创建的svc，通过<code>kubectl get svc -n ingress-nginx</code>查看，不是上诉yaml文件创建的svc。</p>
<p>70：用chrome验证负载均衡效果可能无效，好像是与浏览器相关，之前在做nginx的轮询实验时也遇到过，改用命令行curl验证。</p>
<p>70：这里也可以创建多个svc通过ingress-nginx进行代理，方法同上面相同 </p>
<h2 id="5-4-Ingress-HTTPS-代理访问"><a href="#5-4-Ingress-HTTPS-代理访问" class="headerlink" title="5.4 Ingress HTTPS 代理访问"></a>5.4 Ingress HTTPS 代理访问</h2><p><strong>创建证书，以及cert存储方式</strong></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> openssl req -x509 -sha256 -nodes -days 365 -newkey rsa:2048 -keyout tls.key -out tls.crt -subj <span class="string">"/CN=nginxsvc/0=nginxsvc"</span></span></span><br><span class="line"><span class="meta">$</span><span class="bash"> kubectl create secret tls tls-secret --key tls.key --cert tls.crt</span></span><br></pre></td></tr></table></figure>

<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">extensions/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Ingress</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">nginx-ingress</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">tls:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">hosts:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="string">www3.atguigu.com</span></span><br><span class="line">      <span class="attr">secretName:</span> <span class="string">tls-secret</span></span><br><span class="line">  <span class="attr">rules:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">host:</span> <span class="string">www3.atguigu.com</span></span><br><span class="line">      <span class="attr">http:</span></span><br><span class="line">        <span class="attr">paths:</span></span><br><span class="line">          <span class="bullet">-</span> <span class="attr">path:</span> <span class="string">/</span></span><br><span class="line">            <span class="attr">backend:</span></span><br><span class="line">              <span class="attr">serviceName:</span> <span class="string">nginx-svc</span></span><br><span class="line">              <span class="attr">servicePort:</span> <span class="number">80</span></span><br></pre></td></tr></table></figure>



<h2 id="5-5-Nginx-进行-BasicAuth"><a href="#5-5-Nginx-进行-BasicAuth" class="headerlink" title="5.5 Nginx 进行 BasicAuth"></a>5.5 Nginx 进行 BasicAuth</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> yum -y install httpd</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> htpasswd -c auth foo</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> kubectl create secret generic basic-auth --from-file=auth</span></span><br></pre></td></tr></table></figure>

<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">extensions/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Ingress</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">nginx-ingress-with-auth</span></span><br><span class="line">  <span class="attr">annotations:</span></span><br><span class="line">    <span class="attr">nginx.ingress.kubernetes.io/auth-type:</span> <span class="string">basic</span></span><br><span class="line">    <span class="attr">nginx.ingress.kubernetes.io/auth-secret:</span> <span class="string">basic-auth</span></span><br><span class="line">    <span class="attr">nginx.ingress.kubernetes.io/auth-realm:</span> <span class="string">'Authentication Required - foo'</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">rules:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">host:</span> <span class="string">auth.atguigu.com</span></span><br><span class="line">      <span class="attr">http:</span></span><br><span class="line">        <span class="attr">paths:</span></span><br><span class="line">          <span class="bullet">-</span> <span class="attr">path:</span> <span class="string">/</span></span><br><span class="line">            <span class="attr">backend:</span></span><br><span class="line">              <span class="attr">serviceName:</span> <span class="string">nginx-svc</span></span><br><span class="line">              <span class="attr">servicePort:</span> <span class="number">80</span></span><br></pre></td></tr></table></figure>



<h2 id="5-6-Nginx-进行重写"><a href="#5-6-Nginx-进行重写" class="headerlink" title="5.6 Nginx 进行重写"></a>5.6 Nginx 进行重写</h2><table>
<thead>
<tr>
<th>名称</th>
<th>描述</th>
<th>值</th>
</tr>
</thead>
<tbody><tr>
<td>nginx.ingress.kubernetes.io/rewrite-target</td>
<td>必须重定向流量的目标URI</td>
<td>串</td>
</tr>
<tr>
<td>nginx.ingress.kubernetes.io/ssl-redirect</td>
<td>指示位置部分是否仅可访问SSL（当Ingress包含证书时默认为True）</td>
<td>布尔</td>
</tr>
<tr>
<td>nginx.ingress.kubernetes.io/force-ssl-redirect</td>
<td>即使Ingress为启动TLS，也强制重定向到HTTPS</td>
<td>布尔</td>
</tr>
<tr>
<td>nginx.ingress.kubernetes.io/app-root</td>
<td>定义Controller必须重定向的应用程序根，如果它在‘/’上下文中</td>
<td>串</td>
</tr>
<tr>
<td>nginx.ingress.kubernetes.io/use-regex</td>
<td>指示Ingress上定义的路径是否使用正则表达式</td>
<td>布尔</td>
</tr>
</tbody></table>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">extensions/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Ingress</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">nginx-ingress</span></span><br><span class="line">  <span class="attr">annotations:</span></span><br><span class="line">    <span class="attr">nginx.ingress.kubernetes.io/rewrite-target:</span> <span class="string">http://foo.bar.com:795/hostname.html</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">rules:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">host:</span> <span class="string">foo10.bar.com</span></span><br><span class="line">      <span class="attr">http:</span></span><br><span class="line">        <span class="attr">paths:</span></span><br><span class="line">          <span class="bullet">-</span> <span class="attr">path:</span> <span class="string">/</span></span><br><span class="line">            <span class="attr">backend:</span></span><br><span class="line">              <span class="attr">serviceName:</span> <span class="string">nginx-svc</span></span><br><span class="line">              <span class="attr">servicePort:</span> <span class="number">80</span></span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>Kubernetes</category>
      </categories>
  </entry>
  <entry>
    <title>四、Kubernetes 资源控制器</title>
    <url>/2020/03/04/kubernetes%E7%AC%94%E8%AE%B0/4.Kubernetes%E8%B5%84%E6%BA%90%E6%8E%A7%E5%88%B6%E5%99%A8/</url>
    <content><![CDATA[<h1 id="1-什么是资源控制器"><a href="#1-什么是资源控制器" class="headerlink" title="1. 什么是资源控制器"></a>1. 什么是资源控制器</h1><p>Kubernetes中内建了很多controller（控制器），这些相当于一个状态机，用来控制Pod的具体状态和行为。</p>
<a id="more"></a>



<h1 id="2-控制器类型"><a href="#2-控制器类型" class="headerlink" title="2. 控制器类型"></a>2. 控制器类型</h1><ul>
<li>ReplicationController和ReplicaSet</li>
<li>Deployment</li>
<li>DaemonSet</li>
<li>Job/CronJob</li>
<li>StatefulSet</li>
<li>Horizontal Pod Autoscaling</li>
</ul>
<h1 id="3-ReplicationController-和-ReplicaSet"><a href="#3-ReplicationController-和-ReplicaSet" class="headerlink" title="3. ReplicationController 和 ReplicaSet"></a>3. ReplicationController 和 ReplicaSet</h1><p><strong>ReplicationController（RC）</strong>用来<strong>确保应用容器的副本数始终保持在用户定义的副本数</strong>，即如果有容器异常退出，会自动创建新的Pod来替代；而异常多出来的容器也会自动回收。</p>
<p>在新版本的Kubernetes中建议使用<strong>ReplicaSet（RS）</strong>来取代ReplicationController。ReplicaSet跟ReplicationController没有本质的不同，只是名字不一样，并且<strong>ReplicaSet支持集合式的selector</strong>（70：RS根据Pod的标签匹配来判断Pod的副本数是否达到期望值）。</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">extensions/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ReplicaSet</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">frontend</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">replicas:</span> <span class="number">3</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">tier:</span> <span class="string">frontend</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">tier:</span> <span class="string">frontend</span></span><br><span class="line">      <span class="attr">spec:</span></span><br><span class="line">        <span class="attr">containers:</span></span><br><span class="line">          <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">php-redis</span></span><br><span class="line">            <span class="attr">image:</span> <span class="string">gcr.io/google_samples/gb-frontend:v3</span></span><br><span class="line">            <span class="attr">env:</span></span><br><span class="line">              <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">GET_HOSTS_FROM</span></span><br><span class="line">                <span class="attr">value:</span> <span class="string">dns</span></span><br><span class="line">            <span class="attr">ports:</span></span><br><span class="line">              <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">80</span></span><br></pre></td></tr></table></figure>



<h1 id="4-Deployment"><a href="#4-Deployment" class="headerlink" title="4. Deployment"></a>4. Deployment</h1><p><strong>Deployment</strong>为Pod和ReplicaSet提供了一个<strong>声明式定义</strong>（declarative）方法，用来替代以前的ReplicationController来方便的管理应用。典型的应用场景包括：</p>
<ul>
<li>定义Deployment来创建Pod和ReplicaSet</li>
<li>滚动升级和回滚应用</li>
<li>扩容和缩容</li>
<li>暂停和继续Deployment</li>
</ul>
<p><strong>RS与Deployment的关联：</strong></p>
<img src="assets/4.Kubernetes资源控制器.assets/image-20200313181245321.png" alt="image-20200313181245321" style="zoom:50%;" />

<p><strong>Ⅰ、部署一个简单的Nginx应用</strong></p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">extensions/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Deployment</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">nginx-deployment</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">replicas:</span> <span class="number">3</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">app:</span> <span class="string">nginx</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line">          <span class="attr">image:</span> <span class="string">nginx:1.7.9</span></span><br><span class="line">          <span class="attr">ports:</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">80</span></span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kubctl apply -f https://kubernetes.io/docs/user-guide/nginx-deployment.yaml --record</span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># --record参数可以记录命令，我们可以很方便的查看每次reversion的变化</span></span></span><br></pre></td></tr></table></figure>

<p><strong>Ⅱ、扩容</strong></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kubctl scale deployment nginx-deployment --replicas 10</span><br></pre></td></tr></table></figure>

<p>70：扩缩容只是改变副本数目，不会改变template，即没有版本的变化，所以RS也不会变化。</p>
<p><strong>Ⅲ、如果集群支持Horizontal Pod Autoscalling的话，还可以为Deployment设置自动扩展</strong></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kubectl autoscale deployment nginx-deployment --min=10 --max=15 --cpu-percent=80</span><br></pre></td></tr></table></figure>

<p><strong>Ⅳ、更新镜像也比较简单</strong></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> kubectl <span class="built_in">set</span> image deployment/nginx-deployment nginx=nginx:1.9.1</span></span><br><span class="line">deployment "nginx-deployment" image updated</span><br></pre></td></tr></table></figure>

<p>还可以使用<code>edit</code>命令来编辑Deployment</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> kubectl edit deployment/nginx-deployment</span></span><br><span class="line">deployment "nginx-deployment" edited</span><br></pre></td></tr></table></figure>

<p>70：修改镜像即改变了template，发生了版本变化，会创建新的RS，并删除原有RS下的所有Pod副本，但保留原有RS。</p>
<p><strong>查看rollout的状态：</strong></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> kubectl rollout status deployment/nginx-deployment</span></span><br><span class="line">Waiting for rollout to finish: 2 out of 3 new replicas have been updated...</span><br><span class="line">deployment "nginx-deployment" successfully rolled out</span><br></pre></td></tr></table></figure>

<p><strong>查看历史RS：</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ kubectl get rs</span><br><span class="line">NAME                          DESIRED   CURRENT   READY   AGE</span><br><span class="line">nginx-deployment-1564180365   3         3         0       6s</span><br><span class="line">nginx-deployment-2035384211   0         0         0       36s</span><br></pre></td></tr></table></figure>

<p><strong>Deployment更新策略：</strong></p>
<p>Deployment可以保证在升级时只有一定数量的Pod是down的。默认的，它会确保至少有比期望的Pod数量少一个是up状态（最多一个不可用）。</p>
<p>Deployment同时也可以确保只创建出超过期望数量的一定数量的Pod。默认的，它会确保最多比期望的Pod数量多一个的Pod是up的（最多一个surge）。（70：多创建一个新版本的Pod，再删除一个旧版本的Pod）</p>
<p>未来的Kubernetes版本中，将从1-1变成25%-25%。</p>
<p><strong>Rollover（多个rollout并行）：</strong></p>
<p>假如创建了一个有5个nginx:1.7.9 replica的Deployment，但是当还只有3个nginx:1.7.9的replica创建出来的时候就开始更新含有5个nginx:1.9.1 replica的Deployment。在这种情况下，Deployment会立即杀掉已创建的3个nginx:1.7.9的Pod，并开始创建nginx:1.9.1的Pod。它不会等到所有5个nginx:1.7.9的Pod都创建完成后才开始改变航道。</p>
<p><strong>Ⅴ、回滚</strong></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kubectl rollout undo deployment/nginx-deployment</span><br></pre></td></tr></table></figure>

<p>默认回滚到上一个版本（两次默认回滚就又回到当前版本了）。</p>
<p><strong>查看版本历史记录</strong>（Deployment部署时添加了<strong>–record</strong>参数），以及回滚到指定版本：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kubectl rollout history deployment/nginx-deployment</span><br><span class="line"><span class="meta">#</span><span class="bash"> 使用--to-revision参数指定某个历史版本</span></span><br><span class="line">kubectl rollout undo deployment/nginx-deployment --to-revision=2</span><br><span class="line"><span class="meta">#</span><span class="bash"> 暂停Deploytment的更新</span></span><br><span class="line">kubectl rollout pause deployment/nginx-deployment</span><br></pre></td></tr></table></figure>

<p><strong>查看rollout的状态</strong>：通过<code>kubectl rollout status</code>查看rollout是否完成。如果rollout成功完成，将返回一个0值的Exit Code。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> kubectl rollout status deployment/nginx-deployment</span></span><br><span class="line">Waiting for rollout to finish: 2 out of 3 new replicas have been updated...</span><br><span class="line">deployment "nginx-deployment" successfully rolled out</span><br><span class="line"><span class="meta">$</span><span class="bash"> <span class="built_in">echo</span> $?</span></span><br><span class="line">0</span><br></pre></td></tr></table></figure>

<p><strong>清理Policy：</strong></p>
<p>可以通过设置<code>.spec.revisionHistoryLimit</code>来指定Deployment最多保留多少revision历史记录。默认会保留所有的revision；如果该项设置为0，Deployment就不允许回退了。</p>
<h1 id="5-DaemonSet"><a href="#5-DaemonSet" class="headerlink" title="5. DaemonSet"></a>5. DaemonSet</h1><p><strong>DaemonSet</strong>确保全部（或者一些）Node上运行一个Pod的副本。当有Node加入集群时，也会为它们新增一个Pod。当有Node从集群移除时，这些Pod也会被回收。删除DaemonSet将会删除它所创建的所有Pod。使用DaemonSet的一些典型用法：</p>
<ul>
<li>运行集群存储daemon，例如在每个Node上运行glusterd、ceph</li>
<li>在每个Node上运行日志收集daemon，例如fluentd、logstash</li>
<li>在每个Node上运行监控daemon，例如Prometheus Node Exporter、collectd、Datadog代理、New Relic代理，或Ganglia gmond</li>
</ul>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">DaemonSet</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">daemonset-example</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">daemonset</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">name:</span> <span class="string">daemonset-example</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">name:</span> <span class="string">daemonset-example</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">daemonset-example</span></span><br><span class="line">          <span class="attr">image:</span> <span class="string">wangyanglinux/mapp:v1</span></span><br></pre></td></tr></table></figure>



<h1 id="6-Job-CronJob"><a href="#6-Job-CronJob" class="headerlink" title="6. Job/CronJob"></a>6. Job/CronJob</h1><p><strong>Job</strong>负责批处理任务，即执行一次的任务，它保证批处理任务的一个或多个Pod成功结束。</p>
<p><strong>特殊说明：</strong></p>
<ul>
<li>spec.template格式同Pod</li>
<li>restartPolicy仅支持Never或OnFailure</li>
<li>单个Pod时，默认Pod运行成功后Job即结束</li>
<li><code>.spec.completions</code>标志Job结束需要成功运行的Pod个数，默认为1</li>
<li><code>.spec.parallelism</code>标志并行运行的Pod的个数，默认为1</li>
<li><code>.spec.activeDeadlineSeconds</code>标志失败Pod的重试最大时间，超过这个时间不会继续重试</li>
</ul>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">batch/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Job</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">pi</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">name:</span> <span class="string">pi</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">pi</span></span><br><span class="line">          <span class="attr">image:</span> <span class="string">perl</span></span><br><span class="line">          <span class="attr">command:</span> <span class="string">["perl",</span> <span class="string">"-Mbignum=bpi"</span><span class="string">,</span> <span class="string">"-wle"</span><span class="string">,</span> <span class="string">"print bpi(2000)"</span><span class="string">]</span></span><br><span class="line">      <span class="attr">restartPolicy:</span> <span class="string">Never</span></span><br></pre></td></tr></table></figure>

<hr>
<p><strong>CronJob</strong>管理基于时间的Job，即：</p>
<ul>
<li>在给定的时间点只运行一次</li>
<li>周期性地在给定时间点运行</li>
</ul>
<p><strong>使用前提条件：当前使用地Kubernetes集群，版本&gt;=1.8（对CronJob）。对于先前版本的集群，版本&lt;1.8，启动API Server时，通过传递选项<code>--runtime-config=batch/v2alpha1=true</code>可以开启batch/v2alpha1 API。</strong></p>
<p>典型的用法如下所示：</p>
<ul>
<li>在给定的时间点调度Job运行</li>
<li>创建周期性运行的Job，例如：数据库备份、发送邮件</li>
</ul>
<p><strong>特殊说明：</strong></p>
<ul>
<li><p>同Job特殊说明</p>
</li>
<li><p><code>.spec.schedule</code>：调度，必需字段，指定任务运行周期。</p>
</li>
<li><p><code>.spec.jobTemplate</code>：Job模板，必需字段，指定需要运行的任务，格式同Job。</p>
</li>
<li><p><code>.spec.startingDeadlineSeconds</code>：启动Job的期限（秒级别），该字段是可选的。如果因为任何原因而错过了被调度的时间，那么错过执行时间的Job将被认为是失败的。如果没有指定，则没有期限。</p>
</li>
<li><p><code>.spec.concurrencyPolicy</code>：并发策略，该字段也是可选的。它指定了如何处理被CronJob创建的Job的并发执行。（70：对应这种情况，比如在1分钟的时候启动了一个Job，但到了第二分钟该起下一个Job的时候，上一个Job还没有运行完成）只允许指定下面策略中的一种：</p>
<ul>
<li><p>Allow（默认）：允许并发运行Job</p>
</li>
<li><p>Forbid：禁止并发运行，如果前一个还没有完成，则直接跳过下一个</p>
</li>
<li><p>Replace：取消当前正在运行的Job，用一个新的来替换</p>
<p>注意，当前策略只能应用于同一个CronJob创建的Job。如果存在多个CronJob，它们创建的Job之间总是允许并发运行。</p>
</li>
</ul>
</li>
<li><p><code>.spec.suspend</code>：挂起，该字段也是可选的。如果设置为true，后续所有执行都会被挂起。它对已经开始执行的Job不起作用。默认值为false。</p>
</li>
<li><p><code>.spec.successfulJobsHistoryLimit</code>和<code>.spec.failedJobsHistoryLimit</code>：历史限制，是可选字段。它们指定了可以保留多少完成和失败的Job。默认情况下，它们分别设置为3和1。设置限制的值为0，相关类型的Job完成后将不会被保留。</p>
</li>
</ul>
<p><strong>CronJob本身的一些限制：</strong>创建Job操作应该是<strong>幂等</strong>的。</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">batch/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">CronJob</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">hello</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">schedule:</span> <span class="string">"*/1 * * * *"</span>	<span class="comment"># 分/时/日/月/周</span></span><br><span class="line">  <span class="attr">jobTemplate:</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">template:</span></span><br><span class="line">        <span class="attr">spec:</span></span><br><span class="line">          <span class="attr">containers:</span></span><br><span class="line">            <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">hello</span></span><br><span class="line">              <span class="attr">image:</span> <span class="string">busybox</span></span><br><span class="line">              <span class="attr">args:</span></span><br><span class="line">                <span class="bullet">-</span> <span class="string">/bin/sh</span></span><br><span class="line">                <span class="bullet">-</span> <span class="string">-c</span></span><br><span class="line">                <span class="bullet">-</span> <span class="string">date;</span> <span class="string">echo</span> <span class="string">Hello</span> <span class="string">from</span> <span class="string">the</span> <span class="string">Kubernetes</span> <span class="string">cluster</span></span><br><span class="line">          <span class="attr">restartPolicy:</span> <span class="string">OnFailure</span></span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> kubectl get cronjob</span></span><br><span class="line">NAME      SCHEDULE      SUSPEND      ACTIVE      LAST-SCHEDULE</span><br><span class="line">hello     */1 * * * *   False        0           &lt;none&gt;</span><br><span class="line"><span class="meta">$</span><span class="bash"> kubectl get <span class="built_in">jobs</span></span></span><br><span class="line">NAME               DESIRED   SUCCESSFUL   AGE</span><br><span class="line">hello-1202039034   1         1            49s</span><br><span class="line"><span class="meta">$</span><span class="bash"> pods=$(kubectl get pods --selector=job-name=hello-1202039034 --output=jsonpath=&#123;.items..metadata.name&#125;)</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> kuberctl logs <span class="variable">$pods</span></span></span><br><span class="line">Mon Aug 29 21:34:09 UTC 2016</span><br><span class="line">Hello from the kubernetes cluster</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 注意，删除CronJob的时候不会自动删除Job，这些Job可以用kubectl delete job来删除</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> kubectl delete cronjob hello</span></span><br><span class="line">conjob "hello" deleted</span><br></pre></td></tr></table></figure>



<h1 id="7-StatefulSet"><a href="#7-StatefulSet" class="headerlink" title="7. StatefulSet"></a>7. StatefulSet</h1><p><strong>StatefulSet</strong>作为Controller为Pod提供唯一的标识。它可以保证部署和scale的顺序。</p>
<p>StatefulSet是为了解决有状态服务的问题（对应Deployment和ReplicaSet是为无状态服务而设计），其应用场景包括：</p>
<ul>
<li>稳定的持久化存储，即Pod重新调度后还是能访问到相同的持久化数据，基于PVC来实现</li>
<li>稳定的网络标志，即Pod重新调度后其PodName和HostName不变，基于Headless Service（即没有Cluster IP的Service）来实现</li>
<li>有序部署，有序扩展，即Pod是有顺序的，在部署或者扩展的时候要依据定义的顺序依次进行（即从0到N-1，在下一个Pod运行之前所有之前的Pod必须都是Running和Ready状态），基于init containers来实现</li>
<li>有序收缩，有序删除（即从N-1到0）</li>
</ul>
<h1 id="8-Horizontal-Pod-Autoscaling"><a href="#8-Horizontal-Pod-Autoscaling" class="headerlink" title="8. Horizontal Pod Autoscaling"></a>8. Horizontal Pod Autoscaling</h1><p>应用的资源使用率通常都有高峰和低谷的时候，如何削峰填谷，提高集群的整体资源利用率，让Service中的Pod个数自动调整呢？这就有赖于Horizontal Pod Autoscalling了，顾名思义，使Pod水平自动缩放。</p>
]]></content>
      <categories>
        <category>Kubernetes</category>
      </categories>
  </entry>
  <entry>
    <title>三、Kubernetes 资源清单</title>
    <url>/2020/03/03/kubernetes%E7%AC%94%E8%AE%B0/3.Kubernetes%E8%B5%84%E6%BA%90%E6%B8%85%E5%8D%95/</url>
    <content><![CDATA[<h1 id="1-K8S-中的资源"><a href="#1-K8S-中的资源" class="headerlink" title="1. K8S 中的资源"></a>1. K8S 中的资源</h1><p>K8S种所有的内容都抽象为资源，资源实例化之后，叫做对象</p>
<a id="more"></a>

<p>K8S中的资源分类：</p>
<ul>
<li><strong>名称空间级</strong>资源（仅在此名称空间下生效）：<ul>
<li>工作负载型资源(workload)：Pod、ReplicaSet、Deployment、StatefulSet、DaemonSet、Job、CronJob</li>
<li>服务发现及负载均衡型资源(ServiceDiscovery LoadBalance)：Service、Ingress、…</li>
<li>配置与存储型资源：Volume（存储卷）、CSI（容器存储接口，可以扩展各种各样的第三方存储卷）</li>
<li>特殊类型的存储卷：ConfigMap（当配置中心来使用的资源类型）、Secret（保存敏感数据）、DownwardAPI（把外部环境中信息输出给容器）</li>
</ul>
</li>
<li><strong>集群级</strong>资源（在全集群中可见以及被调用）：Namespace、Node、Role、ClusterRole、RoleBinding、ClusterRoleBinding</li>
<li><strong>元数据型</strong>资源（通过指标进行操作）：HPA、PodTemplate、LimitRange</li>
</ul>
<h1 id="2-资源清单"><a href="#2-资源清单" class="headerlink" title="2. 资源清单"></a>2. 资源清单</h1><p>在K8S中，一般使用<strong>yaml</strong>格式的文件来创建符合我们预期期望的Pod，这样的yaml文件我们一般称为<strong>资源清单</strong></p>
<p><strong>资源清单的常用命令：</strong></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kubectl api-version  # 获取apiversion版本信息</span><br><span class="line">kubectl explain xx资源[.xxx]  # 获取资源清单字段设置的帮助文档</span><br><span class="line">kubctl create -f xx.yaml</span><br><span class="line">kubctl apply -f xx.yaml</span><br><span class="line"></span><br><span class="line">kubectl get pod xx.xx.xx -o yaml  # 使用-o参数可以将资源的配置输出</span><br><span class="line"></span><br><span class="line">kubectl describe pod podName  # 查看Pod内的信息</span><br><span class="line">kubectl log podName -c containerName  # 查看containerName容器的日志信息</span><br></pre></td></tr></table></figure>

<p><strong>通过定义清单文件创建Pod：</strong></p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">pod-demo</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">default</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">myapp</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">myapp-1</span></span><br><span class="line">      <span class="attr">image:</span> <span class="string">hub.atguigu.com/library/myapp:v1</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">busybox-1</span></span><br><span class="line">      <span class="attr">image:</span> <span class="string">busybox:latest</span></span><br><span class="line">      <span class="attr">command:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="string">"/bin/sh"</span></span><br><span class="line">        <span class="bullet">-</span> <span class="string">"-c"</span></span><br><span class="line">        <span class="bullet">-</span> <span class="string">"sleep 3600"</span></span><br></pre></td></tr></table></figure>



<h1 id="3-常用字段的解释"><a href="#3-常用字段的解释" class="headerlink" title="3. 常用字段的解释"></a>3. 常用字段的解释</h1><p>必须存在的属性:</p>
<table>
<thead>
<tr>
<th>参数名</th>
<th align="center">字段类型</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td>version</td>
<td align="center">String</td>
<td>K8S API的版本，目前基本上是v1，可以用kubectl api-versions命令查询</td>
</tr>
<tr>
<td>kind</td>
<td align="center">String</td>
<td>yaml文件定义的资源类型和角色，比如：Pod</td>
</tr>
<tr>
<td>metadata</td>
<td align="center">Object</td>
<td>元数据对象，固定值就写metadata</td>
</tr>
<tr>
<td>metadata.name</td>
<td align="center">String</td>
<td>元数据对象的名字，这里由我们编写，比如命名Pod的名字</td>
</tr>
<tr>
<td>metadata.namespace</td>
<td align="center">String</td>
<td>元数据对象的命名空间，由我们自身定义</td>
</tr>
<tr>
<td>spec</td>
<td align="center">Object</td>
<td>详细定义对象，固定值就写Spec</td>
</tr>
<tr>
<td>spec.containers[]</td>
<td align="center">list</td>
<td>spec对象的容器列表定义</td>
</tr>
<tr>
<td>spec.containers[].name</td>
<td align="center">String</td>
<td>容器的名字</td>
</tr>
<tr>
<td>spec.containers[].iamge</td>
<td align="center">String</td>
<td>容器用到的镜像名称</td>
</tr>
</tbody></table>
<h1 id="4-容器生命周期"><a href="#4-容器生命周期" class="headerlink" title="4. 容器生命周期"></a>4. 容器生命周期</h1><p>70：首先kubectl向kube api接口发送指令后，kube api会通过etcd调度kubelet，kubelet去操作对应地CRI，CRI完成容器环境的初始化。初始化过程中会先启动一个pause基础容器（负责网络和存储卷的共享）。接着会运行零个或一个或多个Init C容器进行初始化。Init C初始化，如果错误退出，则根据重启策略重新执行，如果全部都正常运行结束了，则开始进入到Main C的运行。Main C在刚开始运行时，允许执行一个命令；在结束运行时也允许执行一个命令；在执行过程中，可以通过readiness和liveness探针进行检测。只有readiness检测成成功后，Pod才会显示为running和ready。当liveness检测失败时，根据重启策略进行操作。</p>
<img src="https://blog-love70-img.oss-cn-chengdu.aliyuncs.com/blog.love70.cn/image-20200312155010959.png" alt="image-20200312155010959" style="zoom:50%;" />



<h2 id="4-1-Init-容器"><a href="#4-1-Init-容器" class="headerlink" title="4.1 Init 容器"></a>4.1 Init 容器</h2><p>Pod能够具有多个容器，应用运行在容器里面，但是它也可能有<strong>一个或多个先于应用容器启动的Init容器</strong>。</p>
<p>Init容器与普通的容器非常像，除了以下两点：</p>
<ul>
<li><strong>Init容器总是运行到成功完成为止</strong></li>
<li><strong>每个Init容器都必须在下一个Init容器启动之前完成</strong></li>
</ul>
<p>如果Pod的Init容器失败，Kubernetes会不断地重启该Pod，知道Init容器成功为止。然而，如果Pod对应地restartPolicy为Never，它不会重新启动。</p>
<p><strong>因为Init容器具有与应用程序容器分离的单独镜像，所以它们的启动相关代码具有如下优势：</strong></p>
<ul>
<li>它们可以包含并运行使用工具，但是出于安全考虑，是不建议在应用程序容器镜像中包含这些使用工具的。</li>
<li>它们可以包含使用工具和定制化代码来安装，但是不能出现在应用程序镜像中。例如，创建镜像没必要FROM另一个镜像，只需要在安装过程中使用类似sed、awk、python或dig这样的工具。</li>
<li>应用程序镜像可以分离出创建和部署的角色，而没有必要联合它们构成一个单独的镜像。</li>
<li>Init容器使用Linux Namespace，所以相对应用程序容器来说具有不同的文件系统视图。因此，他们能够具有访问Secret的权限，而应用程序则不能。</li>
<li>它们必须在应用程序容器启动之前运行完成，而应用程序容器是并行运行的，所以Init容器能够提供一种简单的阻塞或延迟应用容器的启动的方法，知道满足了一组先决条件。</li>
</ul>
<p>Init模板：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">myapp-pod</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">myapp</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">myapp-container</span></span><br><span class="line">      <span class="attr">image:</span> <span class="string">busybox</span></span><br><span class="line">      <span class="attr">command:</span> <span class="string">['sh',</span> <span class="string">'-c'</span><span class="string">,</span> <span class="string">'echo The app is running! &amp;&amp; sleep 3600'</span><span class="string">]</span></span><br><span class="line">  <span class="attr">initContainers:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">init-myservice</span></span><br><span class="line">      <span class="attr">image:</span> <span class="string">busybox</span></span><br><span class="line">      <span class="attr">command:</span> <span class="string">['sh',</span> <span class="string">'-c'</span><span class="string">,</span> <span class="string">'until nslookup myservice; do echo waiting for myservice; sleep 2; done;'</span><span class="string">]</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">init-mydb</span></span><br><span class="line">      <span class="attr">image:</span> <span class="string">busybox</span></span><br><span class="line">      <span class="attr">command:</span> <span class="string">['sh',</span> <span class="string">'-c'</span><span class="string">,</span> <span class="string">'until nslookup mydb; do echo waiting fo mydb; sleep 2; done;'</span><span class="string">]</span></span><br></pre></td></tr></table></figure>

<img src="https://blog-love70-img.oss-cn-chengdu.aliyuncs.com/blog.love70.cn/image-20200313100715995.png" alt="image-20200313100407034" style="zoom:50%;" />

<img src="https://blog-love70-img.oss-cn-chengdu.aliyuncs.com/blog.love70.cn/image-20200313100959654.png" alt="image-20200313100715995" style="zoom:50%;" />

<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">myservice</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">ports:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">protocol:</span> <span class="string">TCP</span></span><br><span class="line">      <span class="attr">port:</span> <span class="number">80</span></span><br><span class="line">      <span class="attr">targetPort:</span> <span class="number">9376</span></span><br><span class="line"></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">mydb</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">ports:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">protocol:</span> <span class="string">TCP</span></span><br><span class="line">      <span class="attr">port:</span> <span class="number">80</span></span><br><span class="line">      <span class="attr">targetPort:</span> <span class="number">9377</span></span><br></pre></td></tr></table></figure>

<p><img src="https://blog-love70-img.oss-cn-chengdu.aliyuncs.com/blog.love70.cn/image-20200313100407034.png" alt="image-20200313100909939" style="zoom:50%;" /><img src="https://blog-love70-img.oss-cn-chengdu.aliyuncs.com/blog.love70.cn/image-20200313100909939.png" alt="image-20200313100959654"></p>
<p><img src="https://blog-love70-img.oss-cn-chengdu.aliyuncs.com/blog.love70.cn/image-20200313100909939.png" alt="image-20200313100959654"></p>
<p><strong>特殊说明：</strong></p>
<ul>
<li>在Pod启动过程中，Init容器会按顺序在网络和数据卷初始化（pause中完成）之后启动。每个容器必须在下一个容器启动之前成功退出。</li>
<li>如果由于运行时失败退出，将导致容器启动失败，它会根据Pod的restartPolicy指定的策略进行重试。</li>
<li>在所有的Init容器没有成功之前，Pod将不会变成Ready状态。Init容器的端口将不会在Service中进行聚集。正在初始化中的Pod处于Pending状态，但应该会将Initializing状态设置为true。</li>
<li>如果Pod重启，所有Init容器必须重新执行。</li>
<li>对Init容器spec的修改被限制在容器image字段，修改其他字段都不会生效。更改Init容器的image字段，等价于重启该Pod。（通过kubectl edit pod xxx修改）</li>
<li>Init容器具有应用容器的所有字段。除了readinessProb，因为Init容器无法定义不同于完成（completion）就绪（readiness）之外的其他状态。这会在验证过程中强制执行。</li>
<li>在Pod中的每个app和Init容器的名称必须唯一；与任何其他容器共享同一个名字，会在验证时抛出错误。</li>
</ul>
<h2 id="4-2-容器探针"><a href="#4-2-容器探针" class="headerlink" title="4.2 容器探针"></a>4.2 容器探针</h2><p>探针是由kubelet对容器执行的定期诊断。要执行诊断，kubelet调用由容器实现的Handler。有三种类型的处理程序：</p>
<ul>
<li>ExecAction：在容器内执行指定命令。如果命令退出时返回码为0则认为诊断成功。</li>
<li>TCPSocketAction：对指定端口上的容器的IP地址进行TCP检查。如果端口打开，则诊断被认为是成功的。</li>
<li>HTTPGetAction：对指定端口和路径上的容器的IP地址执行HTTP Get请求。如果响应的状态码大于等于200且小于400，则诊断被认为是成功的。</li>
</ul>
<p>每次探测都将获得以下三种结果之一：</p>
<ul>
<li>成功：容器通过了诊断。</li>
<li>失败：容器未通过诊断。</li>
<li>未知：诊断失败，因此不会采取任何行动。</li>
</ul>
<p><strong>探测方式：</strong></p>
<ul>
<li><strong>livenessProbe：</strong>指示容器是否正在运行。如果存活探测失败，则kubelet会杀死容器，并且容器将受到其重启策略的影响。如果容器不提供存活探针，则默认状态为Success。</li>
<li><strong>readinessProbe：</strong>指示容器是否准备好服务请求。如果就绪探测失败，端点控制器将从与Pod匹配的所有Service的端点中删除该Pod的IP地址。初始延迟之前的就绪状态默认为Failure。如果容器不提供就绪探针，则默认状态为Success。</li>
</ul>
<p><strong>Pod phase：</strong></p>
<p>Pod的status字段是一个PodStatus对象，PadStatus中有一个phase字段。</p>
<p>Pod的相位（phase）是Pod在其生命周期中的简单宏观概述。该字段并不是对容器或Pod的综合汇总，也不是为了作为综合状态机。</p>
<p>Pod相位的数量和含义是严格指定的。除了以下列举的状态外，不应该在假定Pod有其他的phase值。</p>
<ul>
<li>挂起（Pending）：Pod已被Kubernetes系统接受，但有一个或者多个容器镜像尚未构建。等待时间包括调度Pod的时间和通过网络下载镜像的时间，这可能需要花点时间。</li>
<li>运行中（Running）：该Pod已经绑定到了一个节点上，Pod中所有的容器都已被创建。至少有一个容器正在运行，或者正处于启动或重启状态。</li>
<li>成功（Succeeded）：Pod中的所有容器都被成功终止，并且不会再重启。</li>
<li>失败（Failed）：Pod中的所有容器都已终止了，并且至少有一个容器是因为失败终止。也就是说，容器以非0状态退出或者被系统终止。</li>
<li>未知（Unknown）：因为某些原因无法取得Pod的状态，通常是因为与Pod所在的主机通信失败。</li>
</ul>
<p><strong>检测探针-就绪检测：</strong></p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">readiness-httpget-pod</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">default</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">readiness-httpget-container</span></span><br><span class="line">      <span class="attr">image:</span> <span class="string">hub.atguigu.com/library/myapp:v1</span></span><br><span class="line">      <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span></span><br><span class="line">      <span class="attr">readinessProbe:</span></span><br><span class="line">        <span class="attr">httpGet:</span></span><br><span class="line">          <span class="attr">port:</span> <span class="number">80</span></span><br><span class="line">          <span class="attr">path:</span> <span class="string">/index1.html</span></span><br><span class="line">        <span class="attr">initialDelaySeconds:</span> <span class="number">1</span></span><br><span class="line">        <span class="attr">periodSeconds:</span> <span class="number">3</span></span><br></pre></td></tr></table></figure>

<img src="https://blog-love70-img.oss-cn-chengdu.aliyuncs.com/blog.love70.cn/image-20200313150959770.png" alt="image-20200313150959770" style="zoom:50%;" />

<img src="https://blog-love70-img.oss-cn-chengdu.aliyuncs.com/blog.love70.cn/image-20200313151709779.png" alt="image-20200313151159888" style="zoom:50%;" />

<p><strong>检测探针-存活检测：</strong></p>
<p>疑问：如果同时含有就绪检测和存活检测，这两者有先后顺序吗？就是说必须就绪检测通过后才进行存活检测？因为如果就绪检测卡了一小会，如果存活检测失败那不就要重启了吗？</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">liveness-exec-pod</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">default</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">liveness-exec-container</span></span><br><span class="line">      <span class="attr">image:</span> <span class="string">hub.atguigu.com/library/busybox</span></span><br><span class="line">      <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span></span><br><span class="line">      <span class="attr">command:</span> <span class="string">["/bin/sh",</span> <span class="string">"-c"</span><span class="string">,</span> <span class="string">"touch /tmp/live; sleep 60; rm -rf /tmp/live; sleep 3600"</span><span class="string">]</span></span><br><span class="line">      <span class="attr">livenessProbe:</span></span><br><span class="line">        <span class="attr">exec:</span></span><br><span class="line">          <span class="attr">command:</span> <span class="string">["test",</span> <span class="string">"-e"</span><span class="string">,</span> <span class="string">"/tmp/live"</span><span class="string">]</span></span><br><span class="line">        <span class="attr">initialDelaySeconds:</span> <span class="number">1</span></span><br><span class="line">        <span class="attr">periodSeconds:</span> <span class="number">3</span></span><br></pre></td></tr></table></figure>

<img src="https://blog-love70-img.oss-cn-chengdu.aliyuncs.com/blog.love70.cn/image-20200313151159888.png" alt="image-20200313151709779" style="zoom:50%;" />

<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">liveness-httpget-pod</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">default</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">liveness-httpget-container</span></span><br><span class="line">      <span class="attr">image:</span> <span class="string">hub.atguigu.com/library/myapp:v1</span></span><br><span class="line">      <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span></span><br><span class="line">      <span class="attr">ports:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">http</span></span><br><span class="line">          <span class="attr">comtainerPort:</span> <span class="number">80</span></span><br><span class="line">      <span class="attr">livenessProbe:</span></span><br><span class="line">        <span class="attr">httpGet:</span></span><br><span class="line">          <span class="attr">port:</span> <span class="string">http</span></span><br><span class="line">          <span class="attr">path:</span> <span class="string">/index.html</span></span><br><span class="line">        <span class="attr">initialDelaySeconds:</span> <span class="number">1</span></span><br><span class="line">        <span class="attr">periodSeconds:</span> <span class="number">3</span></span><br><span class="line">        <span class="attr">timeoutSeconds:</span> <span class="number">10</span></span><br></pre></td></tr></table></figure>

<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">probe-tcp</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">default</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line">      <span class="attr">image:</span> <span class="string">hub.atguigu.com/library/myapp:v1</span></span><br><span class="line">      <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span></span><br><span class="line">      <span class="attr">livenessProbe:</span></span><br><span class="line">        <span class="attr">initialDelaySeconds:</span> <span class="number">5</span></span><br><span class="line">        <span class="attr">periodSeconds:</span> <span class="number">3</span></span><br><span class="line">        <span class="attr">timeoutSeconds:</span> <span class="number">1</span></span><br><span class="line">        <span class="attr">tcpSocket:</span></span><br><span class="line">          <span class="attr">port:</span> <span class="number">80</span></span><br></pre></td></tr></table></figure>

<p><strong>启动、退出动作：</strong></p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">lifecycle-demo</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">default</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">lifecycle-demo-container</span></span><br><span class="line">      <span class="attr">image:</span> <span class="string">nginx</span></span><br><span class="line">      <span class="attr">lifecycle:</span></span><br><span class="line">        <span class="attr">postStart:</span></span><br><span class="line">          <span class="attr">exec:</span></span><br><span class="line">            <span class="attr">command:</span> <span class="string">["/bin/sh",</span> <span class="string">"-c"</span><span class="string">,</span> <span class="string">"echo Hello from the postStart handler &gt; /usr/share/message"</span><span class="string">]</span></span><br><span class="line">        <span class="attr">preStop:</span></span><br><span class="line">          <span class="attr">exec:</span></span><br><span class="line">            <span class="attr">command:</span> <span class="string">["/bin/sh",</span> <span class="string">"-c"</span><span class="string">,</span> <span class="string">"echo Hello from the preStop handler &gt; /usr/share/message"</span><span class="string">]</span></span><br></pre></td></tr></table></figure>



<h1 id="5-Kubernetes-状态示例"><a href="#5-Kubernetes-状态示例" class="headerlink" title="5. Kubernetes 状态示例"></a>5. Kubernetes 状态示例</h1><p><strong>Pod中只有一个容器并且正在运行，容器成功退出</strong></p>
<ul>
<li><p>记录事件完成</p>
</li>
<li><p>如果restartPolicy为：</p>
<ul>
<li>Always：重启容器；Pod phase仍为Running</li>
<li>OnFailure：Pod phase变成succeeded</li>
<li>Never：Pod phase变成succeeded</li>
</ul>
</li>
</ul>
<p><strong>Pod中只有一个容器并且正在运行，容器退出失败</strong></p>
<ul>
<li><p>记录失败事件</p>
</li>
<li><p>如果restartPolicy为：</p>
<ul>
<li>Always：重启容器；Pod phase仍为Running</li>
<li>OnFailure：重启容器；Pod phase仍为Running</li>
<li>Never：Pod phase变成Failed</li>
</ul>
</li>
</ul>
<p><strong>Pod中有两个容器并且正在运行，容器1退出失败</strong></p>
<ul>
<li><p>记录失败事件</p>
</li>
<li><p>如果restartPolicy为：</p>
<ul>
<li>Always：重启容器；Pod phase仍为Running</li>
<li>OnFailure：重启容器；Pod phase仍为Running</li>
<li>Never：不重启容器；Pod phase仍为Running</li>
</ul>
</li>
<li><p>如果有容器1没有处于运行状态，并且容器2退出：</p>
<ul>
<li>记录失败事件</li>
<li>如果restartPolicy为：<ul>
<li>Always：重启容器；Pod phase仍为Running</li>
<li>OnFailure：重启容器；Pod phase仍为Running</li>
<li>Never：Pod phase变成Failed</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><strong>Pod中只有一个容器并处于运行状态，容器运行时内存超出限制</strong></p>
<ul>
<li><p>容器以失败状态终止</p>
</li>
<li><p>记录OOM事件</p>
</li>
<li><p>如果restartPolicy为：</p>
<ul>
<li>Always：重启容器；Pod phase仍为Running</li>
<li>OnFailure：重启容器；Pod phase仍为Running</li>
<li>Never：记录失败事件；Pod phase变成Failed</li>
</ul>
</li>
</ul>
<p><strong>Pod正在运行，磁盘故障</strong></p>
<ul>
<li>杀掉所有容器，记录适当事件</li>
<li>Pod phase变成Failed</li>
<li>如果使用控制器来运行，Pod将在别处重建</li>
</ul>
<p><strong>Pod正在运行，其节点被分段</strong></p>
<ul>
<li>节点控制器等待直到超时</li>
<li>节点控制器将Pod phase设置为Failed</li>
<li>如果是用控制器来运行，Pod将在别处重建</li>
</ul>
]]></content>
      <categories>
        <category>Kubernetes</category>
      </categories>
  </entry>
  <entry>
    <title>二、Kubernets 基础概念</title>
    <url>/2020/03/02/kubernetes%E7%AC%94%E8%AE%B0/2.Kubernetes%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5/</url>
    <content><![CDATA[<h1 id="1-Pod-概念"><a href="#1-Pod-概念" class="headerlink" title="1. Pod 概念"></a>1. Pod 概念</h1><p>70：Pod 由一个或多个容器组成。只要是有 Pod，便会启动 pause 容器，Pod 中的其他容器共用 pause 网络栈和存储卷。即其他容器没有自己独立的 IP 地址，同一个 Pod 内容器的端口不能冲突。</p>
<a id="more"></a>

<h2 id="1-1-Pod-分类："><a href="#1-1-Pod-分类：" class="headerlink" title="1.1 Pod 分类："></a>1.1 Pod 分类：</h2><ul>
<li>自主式 Pod：Pod 退出了，此类型的 Pod 不会被创建</li>
<li>控制器管理的 Pod：在控制器的生命周期里，始终要维持 Pod 的副本数目</li>
</ul>
<p>70：比如 Pod 运行起来后，我通过 <code>kubectl delete pod xx</code> 的方式手动删除一个 Pod，如果是自主式 Pod 就不会再启动了，如果是控制器管理的 Pod，则会重新启动一个 Pod 以保持期望的副本数目。注意这里要和 Pod 的 restartPolicy 区分开来。</p>
<h2 id="1-2-Pod-控制器类型："><a href="#1-2-Pod-控制器类型：" class="headerlink" title="1.2 Pod 控制器类型："></a>1.2 Pod 控制器类型：</h2><ul>
<li><p>ReplicationController(RC) &amp; ReplicationSet(RS) &amp; Deployment</p>
<p>  HorizontalPodAutoScale(HPA)</p>
</li>
<li><p>StatefulSet</p>
</li>
<li><p>DaemonSet</p>
</li>
<li><p>Job, CronJob</p>
</li>
</ul>
<p><strong>各控制器基础概念：</strong></p>
<p><strong>ReplicationController</strong> 用来确保容器应用的副本数始终保持在用户定义的副本数，即如果有容器异常退出，会自动创建新的 Pod 来代替；而如果异常多出来的容器也会自动回收。在新版本的 Kubernetes 中建议使用 ReplicaSet 来取代 ReplicationController。</p>
<p><strong>ReplicaSet</strong> 跟 ReplicationController 没有本质的不同，只是名字不一样，并且 ReplicaSet 支持集合式的 selector。</p>
<p>虽然 ReplicaSet 可以独立使用，但一般还是建议使用 <strong>Deployment</strong> 来自动管理 ReplicaSet，这样就无需担心跟其他机制的不兼容问题（比如 ReplicaSet 不支持 rolling-update 但 Deployment 支持）。</p>
<p>Deployment 为 Pod和 ReplicaSet 提供了一个<strong>声明式定义</strong>（declarative）方法，用来替代以前的 ReplicationController 来方便的管理应用。典型的应用场景包括：</p>
<ul>
<li><strong>定义 Deployment 来创建 Pod 和 ReplicaSet</strong></li>
<li><strong>滚动升级和回滚应用</strong></li>
<li><strong>扩容和缩容</strong></li>
<li><strong>暂停和继续 Deployment</strong></li>
</ul>
<p><strong>Horizontal Pod Autoscaling</strong>仅适用于Deployment和ReplicaSet，在V1版本中仅支持根据Pod的CPU利用率扩缩容，在v1alpha版本中，支持根据内存和用户自定义的metric扩缩容。</p>
<p><strong>StatefulSet</strong>是<strong>为了解决有状态服务的问题</strong>（对应Deployment和ReplicaSet是为无状态服务而设计），其应用场景包括：</p>
<ul>
<li><strong>稳定的持久化存储</strong>，即Pod重新调度后还是能访问到相同的持久化数据，基于PVC来实现</li>
<li><strong>稳定的网络标志</strong>，即Pod重新调度后其PodName和HostName不变，基于Headless Service（即没有Cluster IP的Service）来实现</li>
<li><strong>有序部署，有序扩展</strong>，即Pod是有顺序的，在部署或者扩展的时候要依据定义的顺序依次进行（即从0到N-1，在下一个Pod运行之前，所有之前的Pod必须都是Running和Ready状态）</li>
<li><strong>有序收缩，有序删除</strong>（即从N-1到0）</li>
</ul>
<p><strong>DaemonSet</strong>确保全部（或者一些）Node上运行一个Pod的副本。当有Node加入集群时，也会为他们新增一个Pod。当有Node从集群移除时，这些Pod也会被回收。删除DaemonSet将会删除它创建的所有Pod。</p>
<p>使用DaemonSet的一些典型用法：</p>
<ul>
<li>运行<strong>集群存储daemon</strong>，例如在每个Node上运行glusterd、ceph</li>
<li>在每个Node上运行<strong>日志收集daemon</strong>，例如fluentd、logstash</li>
<li>在每个Node上运行<strong>监控daemon</strong>，例如Prometheus Node Exporter</li>
</ul>
<p><strong>Job</strong>负责批处理任务，即仅执行一次的任务，它保证批处理任务的一个或多个Pod成功结束。</p>
<p><strong>Cron Job</strong>管理基于时间的Job，即：</p>
<ul>
<li>在给定时间点只运行一次</li>
<li>周期性地在给定时间点运行</li>
</ul>
<h1 id="2-网络通讯方式"><a href="#2-网络通讯方式" class="headerlink" title="2. 网络通讯方式"></a>2. 网络通讯方式</h1><p>Kubernetes的网络模型假定了<strong>所有Pod都在一个可以直接连通的扁平的网络空间中</strong>，这在GCE(Google Compute Engine)里面是现成的网络模型，Kubernetes假定这个网络已经存在。而在私有云里搭建Kubernetes集群，就不能假定这个网络已经存在了。我们需要自己实现这个网络假设，将不同节点上的docker容器之间的访问先打通，然后运行Kubernetes。</p>
<p><strong>Flannel</strong>是CoreOS团队针对Kubernetes设计的一个网络规划服务，简单来说，<strong>它的功能是让集群中的不同节点主机创建的Docker容器都具有全集群唯一的虚拟IP地址。而且它还能在这些IP地址之间建立一个覆盖网络（Overlay Network）</strong>，通过这个覆盖网络，将数据包原封不动地传递到目标容器中。</p>
<img src="https://blog-love70-img.oss-cn-chengdu.aliyuncs.com/blog.love70.cn/image-20200312111011675.png" alt="image-20200312111011675" style="zoom:50%;" />

<p>ETCD为Flannel提供说明：</p>
<ul>
<li>存储管理Flannel可分配地IP地址段资源</li>
<li>监控ETCD中每个Pod的实际地址，并在内存中建立维护Pod节点路由表</li>
</ul>
<p><strong>Kubernetes集群内的各种网络通讯方式：</strong></p>
<ul>
<li><strong>通过一个Pod内的多个容器之间：lo</strong></li>
<li><strong>各Pod之间的通讯：Overlay Network</strong></li>
<li><strong>Pod与Service之间的通讯：各节点的Iptables规则</strong></li>
</ul>
<p><strong>同一个Pod内部通讯：</strong>同一个Pod共享一个网络命名空间，共享同一个Linux协议栈</p>
<p><strong>Pod1至Pod2：</strong></p>
<ul>
<li>Pod1与Pod2不在同一台主机，Pod的地址是与docker0在同一个网段的，但docker0网段与宿主机网卡是两个完全不同的IP网段，并且不同Node之间的通信只能通过宿主机的物理网卡进行。将Pod的IP和所在Node的IP关联起来，通过这个关联让Pod可以互通。</li>
<li>Pod1与Pod2在同一台主机，由docker0网桥直接转发请求至Pod2，不需要经过Flannel。</li>
</ul>
<p><strong>Pod至Service的网络：</strong>目前基于性能考虑，全部为iptables（目前已经是使用<strong>LVS</strong>了）维护和转发。</p>
<p><strong>Pod至外网：</strong>Pod向外网发送请求，查找路由表，转发数据包到宿主机的网卡，宿主网卡完成路由选择后，iptables执行Masquerade，把源IP更改为宿主网卡的IP，然后向外网服务器发送请求。</p>
<p><strong>外网访问Pod：</strong>Service NodePort。</p>
<img src="https://blog-love70-img.oss-cn-chengdu.aliyuncs.com/blog.love70.cn/image-20200312112122662.png" alt="image-20200312112122662" style="zoom:50%;" />

<img src="https://blog-love70-img.oss-cn-chengdu.aliyuncs.com/blog.love70.cn/image-20200312112231812.png" alt="image-20200312112231812" style="zoom:50%;" />





]]></content>
      <categories>
        <category>Kubernetes</category>
      </categories>
  </entry>
  <entry>
    <title>一、Kubernetes 介绍</title>
    <url>/2020/03/01/kubernetes%E7%AC%94%E8%AE%B0/1.Kubernetes%E4%BB%8B%E7%BB%8D/</url>
    <content><![CDATA[<h1 id="1-发展经历"><a href="#1-发展经历" class="headerlink" title="1. 发展经历"></a>1. 发展经历</h1><p>Kubernetes  Google    10年容器化基础架构  borg   GO 语言   Borg </p>
<a id="more"></a>

<p>特点：</p>
<ul>
<li>轻量级：消耗资源小</li>
<li>开源</li>
<li>弹性伸缩</li>
<li>负载均衡：IPVS</li>
</ul>
<h1 id="2-知识图谱"><a href="#2-知识图谱" class="headerlink" title="2. 知识图谱"></a>2. 知识图谱</h1><img src="https://blog-love70-img.oss-cn-chengdu.aliyuncs.com/blog.love70.cn/Kubernetes-1583942379040-1583945698411.png" alt="image-20200312000451257" style="zoom:50%;" />



<h1 id="3-组件说明"><a href="#3-组件说明" class="headerlink" title="3. 组件说明"></a>3. 组件说明</h1><img src="https://blog-love70-img.oss-cn-chengdu.aliyuncs.com/blog.love70.cn/image-20200312000116152.png" alt="Kubernetes-1583942379040" style="zoom:50%;" />

<img src="https://blog-love70-img.oss-cn-chengdu.aliyuncs.com/blog.love70.cn/image-20200312000247841.png" alt="image-20200312000409400" style="zoom:50%;" />

<img src="https://blog-love70-img.oss-cn-chengdu.aliyuncs.com/blog.love70.cn/image-20200312000409400.png" alt="image-20200312000116152" style="zoom:50%;" />



<img src="https://blog-love70-img.oss-cn-chengdu.aliyuncs.com/blog.love70.cn/image-20200312000451257.png" alt="image-20200312000247841" style="zoom:50%;" />









]]></content>
      <categories>
        <category>Kubernetes</category>
      </categories>
  </entry>
  <entry>
    <title>Docker解析</title>
    <url>/2018/02/19/Docker%E7%AC%94%E8%AE%B0/Docker%E8%A7%A3%E6%9E%90/</url>
    <content><![CDATA[<hr>
<h1 id="写在前面"><a href="#写在前面" class="headerlink" title="写在前面"></a>写在前面</h1><p>通过上一篇博客，我们大概知道docker是怎么玩的了。下面我们进一步来对docker进行解析。</p>
<a id="more"></a>

<h1 id="不一样的Docker"><a href="#不一样的Docker" class="headerlink" title="不一样的Docker"></a>不一样的Docker</h1><p>我这里也只能很简单的列一下目前这个阶段我们很容发现的几点：</p>
<ul>
<li>docker image的体积非常的小，注意看下之前我们用到的几个image的size，一个完整功能的ubuntu才100多mb。docker image如此小的体积，让我们可以方便的在网络上传输和分享，对于公司来说就提供了对大量image的管理和分发的可能。</li>
<li>docker的系统启动的耗时为0.如果大家已经尝试启动hello-world就知道，<code>docker run hello-world</code>的命令是瞬间完成的，你并没有感觉到加载image、启动系统的耗时，命令完成后就直接输出了结果。程序执行完成后container也跟着关闭，也并没有保存镜像的时间，但下次再运行还是会保留你处理过的状态。</li>
<li>docker系统占用的资源极少，我们知道如果我们开启了一个VM的系统，不论是linux还是windows，就算什么都不运行也会占用一部分内存，但docker container启动后如果不运行程序，你是看不到系统资源被占用的。</li>
</ul>
<p>这些特点是不是完全和VM不同？并且有了这些特点，是不是很多之前没有的应用场景就会产生？比如，我们可以吧一个项目build成一个image，然后方便地分发出去，<strong>别人拿到后也不用关心你的项目需要什么环境或依赖，只要docker run一下就能运行</strong>。而且速度很快，我们可以管理成百上千的container，没有业务处理的时候也不会占用的系统资源。</p>
<h1 id="Docker是如何做到的"><a href="#Docker是如何做到的" class="headerlink" title="Docker是如何做到的"></a>Docker是如何做到的</h1><p>我们先思考一下，一台服务器给我们开发的项目到底提供了哪些能力让他运行起来呢？cpu、内存、硬盘、网络、操作系统、工具软件还有项目的运行环境（jre等）。当具备了这些能力的机器，我们会说这台机器给项目提供了可以运行的环境。</p>
<p>我们知道VM技术可以将一台物理机器部署为多台虚拟机器，解决了很多物力资源的浪费以及方便的管理能力。那么VM是怎么做到的呢？关键词：<strong>Hypervisor</strong>，VM在物理机器的操作系统上建立了一个中间软件层Hypervisor，Hypervisor利用物理机器的资源，虚拟出多个新虚拟的硬件环境，这些硬件环境可以共享宿主机的资源。这些新的虚拟的硬件环境，安装操作系统和相应的软件后便形成了一台台的虚拟机器。</p>
<p>那么Docker有什么不同呢？Docker很聪明的利用linux的一些技术走了一条捷径：Docker选择了和虚拟化完全不同的思路，并不去虚拟化任何硬件，而是对硬件资源在不同的docker container之间做了 <strong>“隔离”</strong> 。隔离使每个docker container之间拥有了不同的环境（硬盘空间、网络、系统的工具包），并且又可以共享需要的硬件资源（cpu、内存、系统内核），达到了和虚拟机能提供的同样的功能。<br><img src="http://oxtgpqjno.bkt.clouddn.com/ba6d92b3ee037c9ed576f47ae5edf091.jpg" alt="此处输入图片的描述"></p>
<h1 id="Docker入门指南"><a href="#Docker入门指南" class="headerlink" title="Docker入门指南"></a>Docker入门指南</h1>]]></content>
      <categories>
        <category>Docker</category>
      </categories>
  </entry>
  <entry>
    <title>Docker初体验</title>
    <url>/2018/02/15/Docker%E7%AC%94%E8%AE%B0/Docker%E5%88%9D%E4%BD%93%E9%AA%8C/</url>
    <content><![CDATA[<hr>
<h1 id="写在前面"><a href="#写在前面" class="headerlink" title="写在前面"></a>写在前面</h1><p>这学期有机会接触了一些深度学习方面的知识，虽说即将就要踏上自娱自乐的网络之路了，面对当下如此火热的炼丹行业，兴趣广泛的我自然也是要一窥究竟。</p>
<a id="more"></a>

<p>在部署炼丹环境时，偶然接触到了Docker，了解到Docker是今年来非常火的容器技术，顺便也就学习了一波，毕竟技多不压身啊！其实对于一项技术，学习最直接的方式就是去它的官网上进行学习，docker也不例外，在其官网上有详细的学习资料，唯一的障碍可能就是语言关了，鼓励英语好的同志直接移步其官网进行学习: <a href="https://docs.docker.com/" target="_blank" rel="noopener">https://docs.docker.com/</a>。</p>
<p>这篇文章是我边学习边写下的，我也是docker的初学者，并没有丰富的使用经验，所以内容若有不妥，请大家指正，希望日后能不断完善。</p>
<h1 id="什么是Docker"><a href="#什么是Docker" class="headerlink" title="什么是Docker"></a>什么是Docker</h1><p>Docker用Go语言开发实现，基于Linux内核的cgroup，namespace，和AUFS类的Union FS等技术，对进程进行封装隔离，属于操作系统层面的虚拟化技术。由于隔离的进程独立于宿主和其它的隔离的进程，因此也称其为容器。Docker 在容器的基础上，进行了进一步的封装，从文件系统、网络互联到进程隔离等等，极大的简化了容器的创建和维护。使得 Docker 技术比虚拟机技术更为轻便、快捷。</p>
<h1 id="Docker概念"><a href="#Docker概念" class="headerlink" title="Docker概念"></a>Docker概念</h1><p>Docker是开发人员和系统管理员使用容器<strong>开发、部署和运行应用程序</strong>的平台。使用Linux容器来部署应用程序成为<strong>集装箱化</strong>。容器不是新的，但他们用于轻松部署应用程序。<br>Docker由下面几样东西组成，先简单认识一下：</p>
<ul>
<li><strong>Docker Client</strong>：Docker提供给用户的客户端。Docker Client提供给用户一个终端，用户输入Docker提供的命令来管理本地或者远程的服务器。</li>
<li><strong>Docker Daemon</strong>：Docker服务的守护进程。每台服务器（物理机或虚拟机）上只要安装了Docker的环境，基本上就跑了一个后台程序Docker Daemon，Docker Daemon会接收Docker Client发过来的指令,并对服务器的进行具体操作。</li>
<li><strong>Docker Images</strong>：俗称Docker的镜像，一个独立的文件系统，类似虚拟机里的镜像，包含运行时需要的系统、软件、代码、库、环境变量、配置文件等。</li>
<li><strong>Docker Registry</strong>：这个可认为是Docker Images的仓库，就像git的仓库一样，用来管理Docker镜像的，提供了Docker镜像的上传、下载和浏览等功能，并且提供安全的账号管理可以管理只有自己可见的私人image。就像git的仓库一样，docker也提供了官方的Registry，叫做<strong>Dock Hub</strong>(<a href="http://hub.Docker.com" target="_blank" rel="noopener">http://hub.Docker.com</a>)</li>
<li><strong>Docker Container</strong>：俗称Docker的容器，这个是最关键的东西了。Docker Container是真正跑项目程序、消耗机器资源、提供服务的地方，Docker Container通过Docker Images启动，在Docker Images的基础上运行你需要的代码。 你<strong>可以认为Docker Container提供了系统硬件环境，然后使用了Docker Images这些制作好的系统盘，再加上你的项目代码，跑起来就可以提供服务了。</strong> 听到这里，可能你会觉得是不是有点像一个VM利用保存的备份或者快照跑起来环境一样，其实是挺像的，但是实际上是有本质的区别，之后会提到。</li>
</ul>
<h1 id="镜像和容器"><a href="#镜像和容器" class="headerlink" title="镜像和容器"></a>镜像和容器</h1><p>容器通过运行镜像来启动。<strong>镜像</strong>是一个可执行程序包，其中包含运行应用程序所需的所有内容-the code, a runtime, libraries, environment variables, and configuration files。</p>
<p><strong>容器</strong>是镜像runtime实例-执行时镜像在内存中的内容(即具有状态或用户进程的镜像)。你可以使用命令<code>docker ps</code>查看正在运行的容器的列表，就像在Linux中一样。</p>
<h1 id="容器和虚拟机"><a href="#容器和虚拟机" class="headerlink" title="容器和虚拟机"></a>容器和虚拟机</h1><p>一个<strong>容器</strong>在Linux上本地运行，并与其它容器共享主机的内核(共享同一个操作系统)。它运行一个独立的进程，不占用任何其它可执行文件的内存，使其轻量化。</p>
<p>相比之下，<strong>虚拟机</strong>(VM)运行一个完整的“guest”操作系统，通过虚拟机管理程序虚拟访问主机资源。一般来说，虚拟机提供的环境比大多数应用程序需要的资源更多。<br><img src="http://oxtgpqjno.bkt.clouddn.com/TIM%E6%88%AA%E5%9B%BE20180215162524.png" alt="此处输入图片的描述"></p>
<h1 id="Docker是怎么玩的？"><a href="#Docker是怎么玩的？" class="headerlink" title="Docker是怎么玩的？"></a>Docker是怎么玩的？</h1><p>一下接触这么多东西肯定有一些晕吧，没关系，我们把这些串起来走一遍就会了。</p>
<ol>
<li>首先你得安装一下docker的环境，针对你的系统安装对应的版本，具体查看docker的官网<a href="http://www.docker.com/products/docker" target="_blank" rel="noopener">http://www.docker.com/products/docker</a>。(我是在windows平台上进行学习的)</li>
<li>安装好后，我们在terminal中就有了docker的命令了，所有的操作都是通过docker命令完成的。比如: <code>docker version</code><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">C:\Users\love_70&gt;docker version</span><br><span class="line">Client:</span><br><span class="line"> Version:       17.12.0-ce</span><br><span class="line"> API version:   1.35</span><br><span class="line"> Go version:    go1.9.2</span><br><span class="line"> Git commit:    c97c6d6</span><br><span class="line"> Built: Wed Dec 27 20:05:22 2017</span><br><span class="line"> OS&#x2F;Arch:       windows&#x2F;amd64</span><br><span class="line"></span><br><span class="line">Server:</span><br><span class="line"> Engine:</span><br><span class="line">  Version:      17.12.0-ce</span><br><span class="line">  API version:  1.35 (minimum version 1.12)</span><br><span class="line">  Go version:   go1.9.2</span><br><span class="line">  Git commit:   c97c6d6</span><br><span class="line">  Built:        Wed Dec 27 20:12:29 2017</span><br><span class="line">  OS&#x2F;Arch:      linux&#x2F;amd64</span><br><span class="line">  Experimental: true</span><br></pre></td></tr></table></figure>
查看一下我们拥有哪些images吧: <code>docker images</code><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">C:\Users\love_70&gt;docker images</span><br><span class="line">REPOSITORY          TAG             IMAGE ID            CREATED             SIZE</span><br><span class="line">job1                latest          de714ebe3a54        29 hours ago        1.093 MB</span><br><span class="line">ubuntu              latest          f753707788c5        3 weeks ago         127.2 MB</span><br><span class="line">busybox             latest          e02e811dd08f        4 weeks ago         1.093 MB</span><br></pre></td></tr></table></figure>
再查看一下我们有哪些Docker Container吧: <code>docker ps</code><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">C:\Users\love_70&gt;docker ps</span><br><span class="line">CONTAINER ID        IMAGE           COMMAND             CREATED</span><br><span class="line">2c08ddb62c77        ubuntu          &quot;&#x2F;bin&#x2F;bash&quot;         28 hours ago</span><br><span class="line">5aa853bdb033        ubuntu          &quot;&#x2F;bin&#x2F;bash&quot;         28 hours ago</span><br></pre></td></tr></table></figure>
这里看到的都是正在运行的Continer，如果要查看所有的Container就使用<code>docker ps -a</code></li>
</ol>
<p>下面我们从Docker hub的Registry下载一个Image，命令: <code>docker pull image-name</code></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">C:\Users\love_70&gt;docker pull hello-world</span><br><span class="line">Using default tag: latest</span><br><span class="line">latest: Pulling from library&#x2F;hello-world</span><br><span class="line">ca4f61b1923c: Pull complete</span><br><span class="line">Digest: sha256:083de497cff944f969d8499ab94f07134c50bcf5e6b9559b27182d3fa80ce3f7</span><br><span class="line">Status: Downloaded newer image for hello-world:latest</span><br></pre></td></tr></table></figure>
<p>在看一下现在的images: <code>docker image</code></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">C:\Users\love_70&gt;docker images</span><br><span class="line">REPOSITORY          TAG             IMAGE ID            CREATED             SIZE</span><br><span class="line">job1                latest          de714ebe3a54        29 hours ago        1.093 MB</span><br><span class="line">ubuntu              latest          f753707788c5        3 weeks ago         127.2 MB</span><br><span class="line">busybox             latest          e02e811dd08f        4 weeks ago         1.093 MB</span><br><span class="line">hello-world         latest          c54a2cc56cbb        4 months ago        1.848 kB</span><br></pre></td></tr></table></figure>
<p>可以看到我们刚从docker hub上面下载了一个docker官方已经制作好的叫做hello-world的image，下载完成后，就在本地可以查看到这个image了。</p>
<p>我们把hello-world放到一个docker container里面让它跑起来: <code>docker run image-name</code></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">C:\Users\love_70&gt;docker run hello-world</span><br><span class="line"></span><br><span class="line">Hello from Docker!</span><br><span class="line">This message shows that your installation appears to be working correctly.</span><br><span class="line"></span><br><span class="line">To generate this message, Docker took the following steps:</span><br><span class="line"> 1. The Docker client contacted the Docker daemon.</span><br><span class="line"> 2. The Docker daemon pulled the &quot;hello-world&quot; image from the Docker Hub.</span><br><span class="line">    (amd64)</span><br><span class="line"> 3. The Docker daemon created a new container from that image which runs the</span><br><span class="line">    executable that produces the output you are currently reading.</span><br><span class="line"> 4. The Docker daemon streamed that output to the Docker client, which sent it</span><br><span class="line">    to your terminal.</span><br></pre></td></tr></table></figure>
<p>这个image运行后很简单，就是打印了这段话。告诉我们，我们已经成功的让docker daemon从docker hub上拉了一个”hello-world”的image，并且通过这个image创建了一个container，并且通过daemon将输出的内容传回了docker client，也就是我们现在看到的这段话。</p>
<p>我们最后再看一下是否真的创建了docker container: <code>docker ps -a</code></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">C:\Users\love_70&gt;docker ps -a</span><br><span class="line">CONTAINER ID    IMAGE        COMMAND      CREATED           STATUS</span><br><span class="line">3d9b24449cb3    hello-world  &quot;&#x2F;hello&quot;     9 minutes ago     Exited (0) 9 minutes ago</span><br><span class="line">c08ddb62c77     ubuntu       &quot;&#x2F;bin&#x2F;bash&quot;  28 hours ago      Up 28 hours</span><br></pre></td></tr></table></figure>
<p>可以看到，确实已经创建了docker container了，可见<code>docker run</code>的命令实际上是create和start的结合命令，基于hello-world的image创建并启动了container。container启动后执行了打印的程序，打印完上面我们看到的那句话，程序执行完成，container也会跟着关闭了。从STATUS可以看到，在9分钟之前hello-world的这个container已经exited了。</p>
<p>通过上面的步骤，我们大概知道docker是怎么玩的了。初步的印象可能会觉得和现在的VM的部署方式也挺像的，比如docker image就是一个系统备份文件，docker container就是一个跑起来的VM，那docker到底又有什么特别的呢？下一次再来分析。</p>
]]></content>
      <categories>
        <category>Docker</category>
      </categories>
  </entry>
  <entry>
    <title>博客绑定域名</title>
    <url>/2018/02/14/%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA%E7%AC%94%E8%AE%B0/%E5%8D%9A%E5%AE%A2%E7%BB%91%E5%AE%9A%E5%9F%9F%E5%90%8D/</url>
    <content><![CDATA[<hr>
<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><blockquote>
<p>博客搭建完成后，还得拥有一个自己的域名，这样感觉才算完整。下面就介绍一下基于GithubPages和Hexo搭建的博客如何绑定域名。</p>
</blockquote>
<a id="more"></a>

<h1 id="购买域名"><a href="#购买域名" class="headerlink" title="购买域名"></a>购买域名</h1><p>我的域名是双十一的时候在阿里云进行购买的，好像10来块一年，个人感觉还是蛮便宜的嘛。所以我就以阿里云域名为例，介绍如何绑定。<br>注册登陆啥的自己去弄吧，现在产品中找到<strong>域名注册</strong>。<br><img src="http://oxtgpqjno.bkt.clouddn.com/TIM%E6%88%AA%E5%9B%BE20180214084203.png" alt="此处输入图片的描述"><br>输入我们想要的域名，进行查询，选择未被注册的域名进行购买：<br><img src="http://oxtgpqjno.bkt.clouddn.com/TIM%E6%88%AA%E5%9B%BE20180214084405.png" alt="此处输入图片的描述"><br>接下来就是下订单购买流程了。<br>对于域名的选择，这里有几个建议：</p>
<blockquote>
<ul>
<li>域名尽量见名知意，与网站内容相近为宜</li>
<li>域名长度尽可能短，方便他人记住自己的网站</li>
<li>个人博客域名推荐：.com、.cn</li>
</ul>
</blockquote>
<h1 id="域名解析"><a href="#域名解析" class="headerlink" title="域名解析"></a>域名解析</h1><p> 购买域名后，登陆进入阿里云官网的控制台，在域名列表中查看自己购买的域名：<br><img src="http://oxtgpqjno.bkt.clouddn.com/TIM%E6%88%AA%E5%9B%BE20180214085101.png" alt="此处输入图片的描述"><br>点击列表中对应的域名所在列的解析，进入解析界面：<br><img src="http://oxtgpqjno.bkt.clouddn.com/TIM%E6%88%AA%E5%9B%BE20180214122000.png" alt="此处输入图片的描述"><br>点击<strong>添加解析</strong>按钮，如下图依次输入:<strong>CNAME</strong>、<strong>@</strong>、<strong>Github博客域名</strong>。<br><img src="http://oxtgpqjno.bkt.clouddn.com/TIM%E6%88%AA%E5%9B%BE20180214122016.png" alt="此处输入图片的描述"><br>选择保存完成个人域名向个人博客的映射。添加解析后，在浏览器输入我们新注册的域名：<br><img src="http://oxtgpqjno.bkt.clouddn.com/TIM%E6%88%AA%E5%9B%BE20180214085150.png" alt="此处输入图片的描述"><br>可以看到网站报出了404错误，这说明我们的域名已经成功映射到了Github网站，但是它找不到我们的博客的位置，所以我们需要实现个人博客向个人域名的映射，进入Github博客的仓库：<br><img src="http://oxtgpqjno.bkt.clouddn.com/TIM%E6%88%AA%E5%9B%BE20180214085250.png" alt="此处输入图片的描述"><br>点击上图上方偏右的<strong>Create new file</strong>按钮，创建一个文件：<br><img src="http://oxtgpqjno.bkt.clouddn.com/TIM%E6%88%AA%E5%9B%BE20180214085311.png" alt="此处输入图片的描述"><br>文件名为<strong>CNAME</strong>(注意：没有扩展名)，文件内容为个人域名(注意：没有http://，没有www)，然后选择下方的<strong>Commit new file</strong>按钮。然后在浏览器端重新输入我们的域名，我们可以看到域名绑定成功。</p>
<p>但是这时候我们不能高兴得太早，这时候问题开始出现了。</p>
<h1 id="问题及解决"><a href="#问题及解决" class="headerlink" title="问题及解决"></a>问题及解决</h1><p>当我们在本地使用<code>hexo deploy</code>命令再一次部署博客时，会发现博客网页的<strong>css样式丢失</strong>或是<strong>404错误</strong>，这是因为本地的博客工程里面还没有CNAME，当我们重新部署后，远程的博客工程会和本地保持同步，将CNAME文件删除，所以我们要在本地添加CNAME文件：<br><img src="http://oxtgpqjno.bkt.clouddn.com/TIM%E6%88%AA%E5%9B%BE20180214085413.png" alt="此处输入图片的描述"><br>这里我们需要注意的是：CNAME文件添加的目录是在根目录下的source文件夹，而不是.deploy_git文件夹，完成添加后重新部署，博客网站又会恢复正常。</p>
]]></content>
      <categories>
        <category>Hexo</category>
      </categories>
  </entry>
  <entry>
    <title>博客相关配置</title>
    <url>/2018/02/13/%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA%E7%AC%94%E8%AE%B0/%E5%8D%9A%E5%AE%A2%E7%9B%B8%E5%85%B3%E9%85%8D%E7%BD%AE/</url>
    <content><![CDATA[<hr>
<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><blockquote>
<p>在Hexo中有两份主要的配置文件，其名称都是_config.yml。其中，一份位于站点根目录下，主要包含Hexo本身的配置,我们称之为全局配置文件；另一份位于主题目录下，这份配置由主题作者提供，主要用于配置主题相关的选项,我们称之为主题配置文件。</p>
</blockquote>
<a id="more"></a>

<h1 id="Hexo站点配置"><a href="#Hexo站点配置" class="headerlink" title="Hexo站点配置"></a>Hexo站点配置</h1><p>hexo的官方网站：<a href="https://hexo.io/" target="_blank" rel="noopener">https://hexo.io/</a>，里面有hexo的详细说明文档，不过是英文的。没关系，英语不好的请往下看。</p>
<p>注意：配置文件中每个字段后面的冒号是英文格式的，且在其后要加一个空格再写值</p>
<p>比如：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">title: Myblog</span><br></pre></td></tr></table></figure>

<p>编辑hexo目录下的_config.yml文件，具体配置如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># Site 站点信息配置，根据自己的需要进行修改</span><br><span class="line">title: love70&#39;s Blog                          #站点名，会在浏览器页面标签左上角显示</span><br><span class="line">subtitle: Challenge is needed for success.    #副标题</span><br><span class="line">description:                                  #对站点的描述，给搜索引擎看的，可以自定义</span><br><span class="line">author: Zheng                                 #网站作者</span><br><span class="line">language: zh-Hans                             #网站语言</span><br><span class="line">timezone: Asia&#x2F;Shanghai                       #时区</span><br><span class="line"></span><br><span class="line"># URL 博客地址,与申请的GitHub一致</span><br><span class="line">url: love70.github.io</span><br><span class="line">root: &#x2F;</span><br><span class="line">permalink: :year&#x2F;:month&#x2F;:day&#x2F;:title&#x2F;</span><br><span class="line">permalink_defaults:</span><br><span class="line"></span><br><span class="line"># Directory</span><br><span class="line">source_dir: source         #资源文件夹，放在里面的文件会上传到github中</span><br><span class="line">public_dir: public         #公共文件夹，存放生成的静态文件</span><br><span class="line">tag_dir: tags              #标签文件夹，默认是tags。实际存放在source&#x2F;tags中。</span><br><span class="line">archive_dir: archives      #档案文件夹，默认是archives。</span><br><span class="line">category_dir: categories   #分类文件夹，默认是categories。实际存放在source&#x2F;categories中。</span><br><span class="line">code_dir: downloads&#x2F;code   #代码文件夹，默认是downloads&#x2F;code</span><br><span class="line">i18n_dir: :lang            #国际化文件夹，默认跟language相同</span><br><span class="line">skip_render:               #跳过指定文件的渲染，您可使用 glob 来配置路径。</span><br><span class="line"></span><br><span class="line"># Writing 这是文章布局、写作格式的定义，一般不修改</span><br><span class="line">new_post_name: :title.md # File name of new posts</span><br><span class="line">default_layout: post</span><br><span class="line">titlecase: false # Transform title into titlecase</span><br><span class="line">external_link: true # Open external links in new tab</span><br><span class="line">filename_case: 0</span><br><span class="line">render_drafts: false</span><br><span class="line">post_asset_folder: false</span><br><span class="line">relative_link: false</span><br><span class="line">future: true</span><br><span class="line">highlight:</span><br><span class="line">  enable: true</span><br><span class="line">  line_number: true</span><br><span class="line">  auto_detect: false</span><br><span class="line">  tab_replace:</span><br><span class="line"></span><br><span class="line"># Home page setting</span><br><span class="line"># path: Root path for your blogs index page. (default &#x3D; &#39;&#39;)</span><br><span class="line"># per_page: Posts displayed per page. (0 &#x3D; disable pagination)</span><br><span class="line"># order_by: Posts order. (Order by date descending by default)</span><br><span class="line">index_generator:</span><br><span class="line">  path: &#39;&#39;</span><br><span class="line">  per_page: 10</span><br><span class="line">  order_by: -date</span><br><span class="line"></span><br><span class="line"># Category &amp; Tag #分类和标签，一般不修改</span><br><span class="line">default_category: uncategorized</span><br><span class="line">category_map:</span><br><span class="line">tag_map:</span><br><span class="line"></span><br><span class="line"># Date &#x2F; Time format #日期、时间格式，一般不修改</span><br><span class="line">## Hexo uses Moment.js to parse and display date</span><br><span class="line">## You can customize the date format as defined in</span><br><span class="line">## http:&#x2F;&#x2F;momentjs.com&#x2F;docs&#x2F;#&#x2F;displaying&#x2F;format&#x2F;</span><br><span class="line">date_format: YYYY-MM-DD</span><br><span class="line">time_format: HH:mm:ss</span><br><span class="line"></span><br><span class="line"># Pagination  #可根据自己需要修改</span><br><span class="line">## Set per_page to 0 to disable pagination</span><br><span class="line">per_page: 5   #分页，每页文章数量</span><br><span class="line">pagination_dir: page</span><br><span class="line"></span><br><span class="line">search:</span><br><span class="line">  path: search.xml</span><br><span class="line">  field: post</span><br><span class="line">  format: html</span><br><span class="line">  limit: 10000</span><br><span class="line"></span><br><span class="line"># Extensions</span><br><span class="line">## Plugins: https:&#x2F;&#x2F;hexo.io&#x2F;plugins&#x2F;</span><br><span class="line">## Themes: https:&#x2F;&#x2F;hexo.io&#x2F;themes&#x2F;</span><br><span class="line">theme: next</span><br><span class="line"></span><br><span class="line"># Deployment</span><br><span class="line">## Docs: https:&#x2F;&#x2F;hexo.io&#x2F;docs&#x2F;deployment.html</span><br><span class="line">deploy:</span><br><span class="line">  type: git</span><br><span class="line">  repo: https:&#x2F;&#x2F;github.com&#x2F;love70&#x2F;love70.github.io.git</span><br><span class="line">  branch: master</span><br></pre></td></tr></table></figure>

<h1 id="Hexo使用主题"><a href="#Hexo使用主题" class="headerlink" title="Hexo使用主题"></a>Hexo使用主题</h1><p>Hexo 安装主题的方式非常简单，只需要将主题文件拷贝至站点目录的 themes 目录下， 然后修改下配置文件即可。</p>
<p>hexo官方主题下载地址：<a href="https://hexo.io/themes/" target="_blank" rel="noopener">https://hexo.io/themes/</a>，里面有多种多样的主题模板供大家选择。</p>
<p>这里推荐一款很火的主题：next，下面的配置也是以这个主题为例。如果你使用的是其他的主题，那么请你自己根据说明文档进行配置。</p>
<p>next主题的官网，有很详细的配置文档：<a href="http://theme-next.iissnan.com/" target="_blank" rel="noopener">http://theme-next.iissnan.com/</a></p>
<h2 id="下载主题"><a href="#下载主题" class="headerlink" title="下载主题"></a>下载主题</h2><p>next下载地址：<a href="https://github.com/iissnan/hexo-theme-next" target="_blank" rel="noopener">https://github.com/iissnan/hexo-theme-next</a><br><img src="http://oxtgpqjno.bkt.clouddn.com/2-1.png" alt="此处输入图片的描述"><br>到Gtihub下载此主题后解压，打开可以看到里面很多主题相关的文件，我们将此文件夹改名为next，然后将它复制到站点目录的/themes/目录下。</p>
<h3 id="启用主题"><a href="#启用主题" class="headerlink" title="启用主题"></a>启用主题</h3><p>hexo默认是使用的landscape主题，我们可以在站点目录下的/themes/目录下看到landscape文件夹。</p>
<p>我们的themes文件夹里可以放很多主题的文件夹，但是实际上我们的网站采用哪一个主题，这是需要我们进行配置的，打开编辑全局配置文件，找到下面的内容：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># Extensions</span><br><span class="line">## Plugins: https:&#x2F;&#x2F;hexo.io&#x2F;plugins&#x2F;</span><br><span class="line">## Themes: https:&#x2F;&#x2F;hexo.io&#x2F;themes&#x2F;</span><br><span class="line">theme: next</span><br></pre></td></tr></table></figure>
<p>在theme字段这里填上你下载的主题的文件夹的名字，例如我们使用next主题就填上next。这样配置文件就和我们的主题文件关联起来了。</p>
<h3 id="配置主题配置文件"><a href="#配置主题配置文件" class="headerlink" title="配置主题配置文件"></a>配置主题配置文件</h3><p>主题配置文件位于站点目录下的/themes/next/目录下的_config.yml，打开编辑。详细的配置可参考next主题官网：<a href="http://theme-next.iissnan.com/" target="_blank" rel="noopener">http://theme-next.iissnan.com/</a></p>
<h3 id="测试配置效果"><a href="#测试配置效果" class="headerlink" title="测试配置效果"></a>测试配置效果</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ hexo clean #用于清除缓存</span><br><span class="line">$ hexo generate #生成静态网页</span><br><span class="line">$ hexo server #开启本地预览</span><br></pre></td></tr></table></figure>

<h3 id="解决遇到的问题"><a href="#解决遇到的问题" class="headerlink" title="解决遇到的问题"></a>解决遇到的问题</h3><p>到这里会发现点击左侧菜单的分类、标签和关于会提示找不到页面。<br>这是因为我们只是创建了菜单，还没有创建相应的页面。<br>新建页面的hexo命令是：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ hexo new page &quot;pageName&quot;</span><br></pre></td></tr></table></figure>
<p>我们新建分类、标签、关于页面：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ hexo new page &#39;categories&#39;</span><br><span class="line">$ hexo new page &#39;tags&#39;</span><br><span class="line">$ hexo new page &#39;about&#39;</span><br></pre></td></tr></table></figure>
<p>分别执行完这三条命令后，我们会发现站点目录下的/source/目录下多了三个文件夹：categories，tags，about，每个文件夹里面都会生成一个index.md文件，如下：</p>
<p>默认都只会生成title和date字段，我们要为其添加上type字段，并赋值。</p>
<blockquote>
<p><strong>注意：</strong>博客文章的抬头信息中每个字段后面的冒号是英文格式的，而且其后要加一个空格再写值</p>
</blockquote>
<h2 id="配置第三方服务"><a href="#配置第三方服务" class="headerlink" title="配置第三方服务"></a>配置第三方服务</h2><p>静态站点拥有一定的局限性，因此我们需要借助于第三方服务来扩展站点的功能。以下是Next目前支持的第三方服务，可以根据需要集成一些功能进来：</p>
<ul>
<li>评论系统</li>
<li>数据统计与分析</li>
<li>内容分享服务</li>
<li>搜索服务</li>
<li>其它服务</li>
</ul>
<h2 id="Next主题个性化"><a href="#Next主题个性化" class="headerlink" title="Next主题个性化"></a>Next主题个性化</h2><p>可以看到有些next主题的网站很炫酷，那么是怎么配置的呢？在网上有很多相关的教程，下面的这篇博客总结了很多：<br><a href="http://blog.csdn.net/qq_33699981/article/details/72716951" target="_blank" rel="noopener">hexo的next主题个性化教程：打造炫酷网站</a><br>主要有以下32种：</p>
<ul>
<li>在右上角或者左上角实现fork me on github </li>
<li>添加RSS </li>
<li>添加动态背景 </li>
<li>实现点击出现桃心效果 </li>
<li>修改文章内链接文本样式</li>
<li>修改文章底部的那个带#号的标签 </li>
<li>在每篇文章末尾统一添加“本文结束”标记 </li>
<li>修改作者头像并旋转 </li>
<li>博文压缩 </li>
<li>修改“代码块自定义样式</li>
<li>侧边栏社交小图标设置</li>
<li>主页文章添加阴影效果 </li>
<li>在网站底部加上访问量 </li>
<li>添加热度 </li>
<li>网站底部字数统计 </li>
<li>添加README.md文件</li>
<li>设置网站的图标Favicon</li>
<li>实现统计功能 </li>
<li>添加顶部加载条 </li>
<li>在文章底部增加版权信息 </li>
<li>添加网易云跟帖(跟帖关闭，已失效，改为来必力)</li>
<li>隐藏网页底部powered By Hexo/强力驱动</li>
<li>修改网页底部的桃心 </li>
<li>文章加密访问 </li>
<li>添加jiathis分享 </li>
<li>博文置顶 </li>
<li>修改字体大小</li>
<li>修改打赏字体不闪动 </li>
<li>自定义鼠标样式 </li>
<li>为博客加上萌萌的宠物</li>
<li>DaoVoice在线联系 </li>
<li>点击爆炸效果</li>
</ul>
<p>当然，每个人的需要都不太相同，大家也可以根据自己的喜好去选择使用第三方服务和个性化来让自己的博客站点更完善更强大。</p>
]]></content>
      <categories>
        <category>Hexo</category>
      </categories>
  </entry>
  <entry>
    <title>博客的编写与发布</title>
    <url>/2018/02/13/%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA%E7%AC%94%E8%AE%B0/%E5%8D%9A%E5%AE%A2%E7%9A%84%E7%BC%96%E5%86%99%E4%B8%8E%E5%8F%91%E5%B8%83/</url>
    <content><![CDATA[<hr>
<h1 id="认识与入门MarkDown"><a href="#认识与入门MarkDown" class="headerlink" title="认识与入门MarkDown"></a>认识与入门MarkDown</h1><p>博客的编写使用的是Markdown标记语言。Markdown是一种轻量级的「标记语言」，它的优点很多，目前也被越来越多的写作爱好者，撰稿者广泛使用。看到这里请不要被「标记」、「语言」所迷惑，Markdown的语法十分简单。常用的标记符号也不超过十个，这种相对于更为复杂的HTML标记语言来说，Markdown可谓是十分轻量的，学习成本也不需要太多，且一旦熟悉这种语法规则，会有一劳永逸的效果。</p>
<a id="more"></a>

<h2 id="Markdown官方文档"><a href="#Markdown官方文档" class="headerlink" title="Markdown官方文档"></a>Markdown官方文档</h2><p>这里可以看到官方的Markdown语法规则文档，当然，后文我也会用自己的方式，阐述这些语法在实际使用中的用法。</p>
<ul>
<li><a href="https://daringfireball.net/projects/markdown/syntax" target="_blank" rel="noopener">创始人John Gruber的Markdown语法说明</a></li>
<li><a href="http://wowubuntu.com/markdown/#list" target="_blank" rel="noopener">Markdown中文版语法说明</a></li>
</ul>
<h2 id="使用Markdown的优点"><a href="#使用Markdown的优点" class="headerlink" title="使用Markdown的优点"></a>使用Markdown的优点</h2><ul>
<li>专注你的文字内容而不是排版样式。</li>
<li>轻松的导出 HTML、PDF 和本身的 .md 文件。</li>
<li>纯文本内容，兼容所有的文本编辑器与字处理软件。</li>
<li>可读，直观。适合所有人的写作语言。</li>
</ul>
<h2 id="用什么工具"><a href="#用什么工具" class="headerlink" title="用什么工具"></a>用什么工具</h2><p>推荐<a href="https://www.typora.io/" target="_blank" rel="noopener">Typora</a>、<a href="https://www.zybuluo.com/cmd/" target="_blank" rel="noopener">Cmd Markdown</a>等，在各编辑器中一般都会有关于Markdown语法的说明，遗忘时随时查看即可。</p>
<h1 id="博客编写与发布"><a href="#博客编写与发布" class="headerlink" title="博客编写与发布"></a>博客编写与发布</h1><h2 id="新建博客文章"><a href="#新建博客文章" class="headerlink" title="新建博客文章"></a>新建博客文章</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ hexo new &quot;postName&quot; #新建文章</span><br></pre></td></tr></table></figure>
<p>实例：新建博客《搭建我的第一个博客》</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ hexo new &quot;搭建我的第一个博客&quot;</span><br></pre></td></tr></table></figure>
<p>到站点目录下的/source/_posts/目录下可以看到生成了名为：搭建我的第一个博客.md的文件，这是Markdown格式的文件，可以用sublime text3或者notepad++等编辑器打开，也可以下载一个上述的Markdown编辑器来编辑Markdown文件。</p>
<h2 id="编辑博客"><a href="#编辑博客" class="headerlink" title="编辑博客"></a>编辑博客</h2><p>Hexo默认新建的文章抬头已有title、date、tags等属性，可能缺乏categories和meta标签，想要指定目录就需要添加categories属性，而meta标签则是为了便于搜索引擎的收录。如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">---</span><br><span class="line">title: 搭建我的第一个博客</span><br><span class="line">date: 2017-10-15 20:41</span><br><span class="line">categories: Hexo</span><br><span class="line">comments: true</span><br><span class="line">---</span><br></pre></td></tr></table></figure>
<p>categories字段，对博客进行分类管理，然后点击主页左侧菜单的分类就可看到具体的分类。</p>
<p><strong>如何实现上图的阅读全文功能？</strong><br>在自己喜欢的位置添加一个：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;!--more--&gt;</span><br></pre></td></tr></table></figure>
<p>即可，主题会自动识别这个标签，生成对应的阅读全文按钮。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">以上是文章摘要</span><br><span class="line">&lt;!--more--&gt;</span><br><span class="line">以下是余下全文</span><br></pre></td></tr></table></figure>

<h2 id="发布博客"><a href="#发布博客" class="headerlink" title="发布博客"></a>发布博客</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ hexo clean  #清除缓存 网页正常情况下可以忽略此条命令</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ hexo generate  #生成静态页面至public目录</span><br></pre></td></tr></table></figure>
<p>写好之后可以现在本地预览，确定无误之后再部署到Github上。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ hexo server  #开启预览访问端口（默认端口4000，&#39;ctrl + c&#39;关闭server）</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ hexo deploy  #将.deploy目录部署到GitHub</span><br></pre></td></tr></table></figure>
<p>需要说明的是：<br>我们博客文章的编写都是Markdown文件，但是发布到github上的其实是html文件，将Markdown转换成html这个工作我们只要输入hexo generate命令即可，hexo会帮我们完成转换。</p>
<p><strong>hexo命令简写形式</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">hexo n &quot;我的博客&quot; &#x3D;&#x3D; hexo new &quot;我的博客&quot;</span><br><span class="line">hexo g &#x3D;&#x3D; hexo generate</span><br><span class="line">hexo s &#x3D;&#x3D; hexo server</span><br><span class="line">hexo d &#x3D;&#x3D; hexo deploy</span><br></pre></td></tr></table></figure>

<h1 id="博客图片存放"><a href="#博客图片存放" class="headerlink" title="博客图片存放"></a>博客图片存放</h1><p>Markdown编辑器支持插入图片，可以直接给出图片的链接，因此我们可以将图片存放在我们hexo项目的目录下，再填写对应的路径，也可以将其存放在云服务器上，然后给出链接。</p>
<p>在这里，我们介绍使用七牛云来进行图片托管。七牛云是国内领先的企业级云服务商,致力于打造以数据为核心的场景化PaaS服务，图片加载速度还不错，一般也不会出现图片挂掉的情况。</p>
<h2 id="注册账号"><a href="#注册账号" class="headerlink" title="注册账号"></a>注册账号</h2><p>注册申请一个个人账号，然后激活邮箱完成注册。<br>官网地址：<a href="http://www.qiniu.com/" target="_blank" rel="noopener">http://www.qiniu.com/</a></p>
<h2 id="存储图片"><a href="#存储图片" class="headerlink" title="存储图片"></a>存储图片</h2><p>（1）点击左侧菜单的对象存储<br><img src="http://oxtgpqjno.bkt.clouddn.com/3-1.png" alt="此处输入图片的描述"><br>（2）点击上端的添加来创建存储空间<br><img src="http://oxtgpqjno.bkt.clouddn.com/3-2.png" alt="此处输入图片的描述"><br>（3）填写好基本信息，点击确定创建<br><img src="http://oxtgpqjno.bkt.clouddn.com/3-3.png" alt="此处输入图片的描述"><br>（4）来到新创建的存储空间，点击内容管理<br><img src="http://oxtgpqjno.bkt.clouddn.com/3-4.png" alt="此处输入图片的描述"><br>（5）在内容管理中可以看到文件列表，点击上传文件<br><img src="http://oxtgpqjno.bkt.clouddn.com/3-5.png" alt="此处输入图片的描述"><br>（6）可以设置上传的文件的前缀，以便进行分类管理<br><img src="http://oxtgpqjno.bkt.clouddn.com/3-6.png" alt="此处输入图片的描述"><br>（7）点击关闭，回到内容管理页面查看上传的文件，复制图片链接<br><img src="http://oxtgpqjno.bkt.clouddn.com/3-7.png" alt="此处输入图片的描述"><br>至此，我们就将我们博客需要的图片存储到了七牛云，然后我们只要将复制的图片链接插入到博客人文章中即可显示图片，感觉显示速度还是蛮快的。</p>
<p>以上简单介绍了Markdown标记语言，博客的搭建与编写以及博客中图片的插入。此外，为使我们的博客更加的美观，我们还需进行Hexo的站点配置、主题配置和使用以及一些第三方服务的使用。</p>
]]></content>
      <categories>
        <category>Hexo</category>
      </categories>
  </entry>
  <entry>
    <title>搭建我的第一个博客</title>
    <url>/2017/10/15/%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA%E7%AC%94%E8%AE%B0/%E6%90%AD%E5%BB%BA%E6%88%91%E7%9A%84%E7%AC%AC%E4%B8%80%E4%B8%AA%E5%8D%9A%E5%AE%A2/</url>
    <content><![CDATA[<hr>
<h1 id="基于GithubPages和Hexo搭建博客"><a href="#基于GithubPages和Hexo搭建博客" class="headerlink" title="基于GithubPages和Hexo搭建博客"></a>基于GithubPages和Hexo搭建博客</h1><h2 id="Github-Pages是什么？"><a href="#Github-Pages是什么？" class="headerlink" title="Github Pages是什么？"></a>Github Pages是什么？</h2><p>Github Pages本用于介绍托管在Github上的项目，不过由于它的空间免费稳定，所以用来搭建一个博客再好不过了。</p>
<a id="more"></a>

<h2 id="为什么-选择GIthub-Pages"><a href="#为什么-选择GIthub-Pages" class="headerlink" title="为什么 选择GIthub Pages?"></a>为什么 选择GIthub Pages?</h2><ul>
<li>GitHub Pages有300M免费空间，搭建的博客可以很方便的进行管理，并且保存可靠；</li>
<li>GitHub 是趋势，GitHub上面有很多大牛，学IT的人应该尽早融入这样的环境 ;</li>
<li>程序员应该学会使用Git来管理项目，熟悉版本控制 ;</li>
<li>Github上有很多的开源项目，多学习学习，眼界会开阔很多。</li>
</ul>
<h2 id="接下来应该怎么做？"><a href="#接下来应该怎么做？" class="headerlink" title="接下来应该怎么做？"></a>接下来应该怎么做？</h2><p>Hexo 是一个简单地、轻量地、基于Node的一个静态博客框架，可以方便的生成静态网页托管在github。我们要使用Github Pages + Hexo搭建博客站点，就必须注册Github账号，安装git、node.js以及hexo等，接下来就一起来实践吧！</p>
<h2 id="Github注册与配置"><a href="#Github注册与配置" class="headerlink" title="Github注册与配置"></a>Github注册与配置</h2><h3 id="注册"><a href="#注册" class="headerlink" title="注册"></a>注册</h3><p>如果你还没有自己的Github账号，那请到Github官网注册账号：<a href="https://github.com/" target="_blank" rel="noopener">https://github.com/</a><br>注册成功后github会发送验证邮件到你的邮箱，请查收邮件并进行验证。</p>
<h3 id="新建版本库"><a href="#新建版本库" class="headerlink" title="新建版本库"></a>新建版本库</h3><p>注册完成后，点击Start a project来新建一个版本库<br><img src="http://oxtgpqjno.bkt.clouddn.com/%E6%96%B0%E5%BB%BA%E7%89%88%E6%9C%AC%E5%BA%931.png" alt="新建版本库1"></p>
<p>如果你已经注册，则在自己的主页，点击”New repository”，即可新建一个版本库</p>
<p><img src="http://oxtgpqjno.bkt.clouddn.com/%E6%96%B0%E5%BB%BA%E7%89%88%E6%9C%AC%E5%BA%932.png" alt="新建版本库2"></p>
<p>输入Repository name:yourname.github.io(yourname与你的注册用户名一致,这个就是你博客的域名了)</p>
<h3 id="启用GitHub-Page"><a href="#启用GitHub-Page" class="headerlink" title="启用GitHub Page"></a>启用GitHub Page</h3><p>进入版本库后，点击右上方的setting</p>
<p><img src="http://oxtgpqjno.bkt.clouddn.com/%E6%96%B0%E5%BB%BA%E7%89%88%E6%9C%AC%E5%BA%9333.png" alt="新建版本库3"></p>
<p>来到Githubs pages栏目，点击Choose a theme</p>
<p><img src="http://oxtgpqjno.bkt.clouddn.com/%E6%96%B0%E5%BB%BA%E7%89%88%E6%9C%AC%E5%BA%934.png" alt="新建版本库4"></p>
<p>最后点击”Publish page”,发布github默认生成的一个静态站点</p>
<p><img src="http://oxtgpqjno.bkt.clouddn.com/%E6%96%B0%E5%BB%BA%E7%89%88%E6%9C%AC%E5%BA%935.png" alt="新建版本库5"></p>
<p>至此，我们已经配置好了github默认的静态站点，并且可以访问：你的github用户名.github.io测试我们刚刚建立好的站点主页。</p>
<h2 id="下载并安装Git"><a href="#下载并安装Git" class="headerlink" title="下载并安装Git"></a>下载并安装Git</h2><h3 id="下载"><a href="#下载" class="headerlink" title="下载"></a>下载</h3><p>根据自己电脑操作系统的位数到git官网下载相应的版本：<a href="https://git-scm.com/download/win" target="_blank" rel="noopener">https://git-scm.com/download/win</a></p>
<h3 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h3><p>根据自己的需要安装到相应的路径下，其他的一路点击next即可。</p>
<h3 id="配置环境变量"><a href="#配置环境变量" class="headerlink" title="配置环境变量"></a>配置环境变量</h3><p>选中桌面图标计算机，右键选择属性，打开左边的高级系统设置，打开弹出窗口的环境变量，找到path进行编辑。<br>找到git的安装目录，将其复制后粘贴到path后面。注意每一个加进来的路径后面都要带英文格式的分号。<br>安装与配置过程可参考图文教程：<a href="http://jingyan.baidu.com/article/9f7e7ec0b17cac6f2815548d.html" target="_blank" rel="noopener">git的安装和配置</a></p>
<h3 id="测试是否安装成功"><a href="#测试是否安装成功" class="headerlink" title="测试是否安装成功"></a>测试是否安装成功</h3><p>windows+R输入cmd打开命令提示符窗口，输入如下命令：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ git --version</span><br></pre></td></tr></table></figure>
<p>若安装成功会打印出本机安装的git的版本。</p>
<h3 id="添加SSH-KEY到Github"><a href="#添加SSH-KEY到Github" class="headerlink" title="添加SSH KEY到Github"></a>添加SSH KEY到Github</h3><p>Git是分布式的代码管理器，远程的代码管理是基于SSH的，所以要使用远程的Git则需要SSH的配置。Github的SSH配置步骤如下：</p>
<h4 id="1-设置Git-user的name和email："><a href="#1-设置Git-user的name和email：" class="headerlink" title="1 设置Git user的name和email："></a>1 设置Git user的name和email：</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ git config --global user.name <span class="string">"your user name"</span></span><br><span class="line">$ git config --global user.email <span class="string">"your email address"</span></span><br></pre></td></tr></table></figure>

<h4 id="2-生成SSH密钥："><a href="#2-生成SSH密钥：" class="headerlink" title="2 生成SSH密钥："></a>2 生成SSH密钥：</h4><h5 id="2-1-检查-ssh-密钥是否已存在"><a href="#2-1-检查-ssh-密钥是否已存在" class="headerlink" title="2.1 检查 ssh 密钥是否已存在"></a>2.1 检查 ssh 密钥是否已存在</h5><p>查看C:\Users\YourUserName.ssh是否存在<br>如果该文件夹存在，则说明密钥已存在，则备份删除</p>
<h5 id="2-2-生成-ssh-密钥"><a href="#2-2-生成-ssh-密钥" class="headerlink" title="2.2 生成 ssh 密钥"></a>2.2 生成 ssh 密钥</h5><p>在命令行中输入</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ ssh-keygen -t rsa -C “your email address”</span><br></pre></td></tr></table></figure>
<p>连续按3个回车（密码默认为空），得到 id_rsa 和 id_rsa.pub 文件，说明生成成功。</p>
<h4 id="3-添加密钥到-Github"><a href="#3-添加密钥到-Github" class="headerlink" title="3 添加密钥到 Github"></a>3 添加密钥到 Github</h4><p>打开 <a href="https://github.com/" target="_blank" rel="noopener">Github</a>，登录自己的账号后<br>点击自己的头像-&gt;settings-&gt;SSH Keys-&gt;Add SSH key<br>将本地 id_rsa.pub 中的内容粘贴到 Key 文本框中，随意输入一个 title，点击 Add Key 即可。</p>
<h4 id="4-测试"><a href="#4-测试" class="headerlink" title="4 测试"></a>4 测试</h4><p>在命令行中输入</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ ssh git@github.com</span><br></pre></td></tr></table></figure>
<p>会出现如下询问：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Are you sure you want to continue connecting (yes&#x2F;no)?</span><br></pre></td></tr></table></figure>
<p>键入yes后回车，如果出现：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Hi xxx! You’ve successfully authenticated, but GitHub does not provide shell accessConnection to github.com closed.</span><br></pre></td></tr></table></figure>
<p>则说明验证成功，否则可能是上述步骤中的其中几步出错了，需重新来过。</p>
<h2 id="下载并安装node-js"><a href="#下载并安装node-js" class="headerlink" title="下载并安装node.js"></a>下载并安装node.js</h2><h3 id="下载-1"><a href="#下载-1" class="headerlink" title="下载"></a>下载</h3><p>根据自己电脑操作系统的位数到git官网下载相应的版本：<a href="https://nodejs.org/en/download/" target="_blank" rel="noopener">https://nodejs.org/en/download/</a></p>
<h3 id="安装-1"><a href="#安装-1" class="headerlink" title="安装"></a>安装</h3><p>根据自己的需要安装到响应的地方，其他的一路点击next即可</p>
<h3 id="配置环境变量-1"><a href="#配置环境变量-1" class="headerlink" title="配置环境变量"></a>配置环境变量</h3><p>选中桌面图标计算机，右键选择属性，打开左边的高级系统设置，打开弹出窗口的环境变量，找到path进行编辑。</p>
<p>找到node.js的安装目录，将其复制后粘贴到path后面。注意每一个加进来的路径后面都要带英文格式的分号。</p>
<h3 id="测试是否安装成功-1"><a href="#测试是否安装成功-1" class="headerlink" title="测试是否安装成功"></a>测试是否安装成功</h3><p>windows+R输入cmd打开命令提示符窗口，输入如下命令：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">node -v</span><br></pre></td></tr></table></figure>
<p>若安装成功会打印出本机安装的node.js的版本。</p>
<h2 id="下载并安装Hexo"><a href="#下载并安装Hexo" class="headerlink" title="下载并安装Hexo"></a>下载并安装Hexo</h2><p>hexo是基于node.js的静态博客，官网也是搭建在GitHub上。</p>
<h3 id="安装-2"><a href="#安装-2" class="headerlink" title="安装"></a>安装</h3><p>在你喜欢的路径下新建一个文件夹blog，用来存放博客的文件，在此文件夹中右键打开Git Bash</p>
<p>输入如下指令进行安装：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ npm install -g hexo-cli</span><br></pre></td></tr></table></figure>
<p>如果执行这条命令时长时间未成功，那么请先使用下面的命令将npm镜像源更改为国内的镜像，再执行上面的安装命令，因为国外的镜像源很有可能被墙了。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ npm config <span class="built_in">set</span> registry https://registry.npm.taobao.org</span><br></pre></td></tr></table></figure>
<p>初始化hexo</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo init hexo</span><br></pre></td></tr></table></figure>
<p>这里会将Github上的hexo项目clone下来，得到hexo文件夹。<br>初始化成功后会在最后打印一行：INFO Start blogging with Hexo!</p>
<h3 id="安装依赖文件"><a href="#安装依赖文件" class="headerlink" title="安装依赖文件"></a>安装依赖文件</h3><p>进入到hexo文件夹</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> hexo</span><br></pre></td></tr></table></figure>
<p>安装依赖文件：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ npm install</span><br></pre></td></tr></table></figure>
<p>部署形成文件：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>
<p>本地测试：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>
<p>下图所示则表示搭建成功了：<br><img src="http://oxtgpqjno.bkt.clouddn.com/hexo-s.png" alt="enter image description here"><br>在浏览器输入：<a href="http://localhost:4000/" target="_blank" rel="noopener">http://localhost:4000/ </a>即可访问到我们搭建好的hexo站点。<br><img src="http://oxtgpqjno.bkt.clouddn.com/hexo-first.png" alt="enter image description here"></p>
<h2 id="将本地hexo项目托管到Github"><a href="#将本地hexo项目托管到Github" class="headerlink" title="将本地hexo项目托管到Github"></a>将本地hexo项目托管到Github</h2><h3 id="将本地hexo项目托管到Github-1"><a href="#将本地hexo项目托管到Github-1" class="headerlink" title="将本地hexo项目托管到Github"></a>将本地hexo项目托管到Github</h3><h4 id="修改全局配置文件-config-yml"><a href="#修改全局配置文件-config-yml" class="headerlink" title="修改全局配置文件_config.yml"></a>修改全局配置文件_config.yml</h4><blockquote>
<p><strong>说明：</strong>hexo文件夹下一个_config.yml，我们称之为全局配置文件，在每个主题文件夹内还会有一个_config.yml文件，我们称之为主题配置文件。</p>
</blockquote>
<p>用sublime text3或者notepad++等编辑器打开hexo文件夹下的_config.yml文件。</p>
<blockquote>
<p><strong>注意：</strong>配置文件中每个字段后面的冒号是英文格式的，且在其后要加一个空格再写值。</p>
</blockquote>
<p>编辑最后面的deploy属性，加入代码：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">type: git</span><br><span class="line">repository: https:&#x2F;&#x2F;github.com&#x2F;你的Github用户名&#x2F;你的Github用户名.github.io.git</span><br><span class="line">branch: master</span><br></pre></td></tr></table></figure>

<p>type使用是git。</p>
<p>repository属性改成你的刚才创建仓库git地址。</p>
<p>分支branch填写master。</p>
<h4 id="安装hexo-deployer-git插件"><a href="#安装hexo-deployer-git插件" class="headerlink" title="安装hexo-deployer-git插件"></a>安装hexo-deployer-git插件</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ npm install hexo-deployer-git --save</span><br></pre></td></tr></table></figure>

<h4 id="部署到Github上"><a href="#部署到Github上" class="headerlink" title="部署到Github上"></a>部署到Github上</h4><p>依次执行以下三条命令：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo clean  <span class="comment">#清除缓存 网页正常情况下可以忽略此条命令</span></span><br></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo generate  <span class="comment">#生成静态页面至public目录</span></span><br></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo deploy  <span class="comment">#将.deploy目录部署到GitHub</span></span><br></pre></td></tr></table></figure>

<p>执行hexo deploy命令之后，如果最后一行打印出如下信息则表示部署成功：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">INFO  Deploy done: git</span><br></pre></td></tr></table></figure>
<p>然后你再去访问你创建的Github pages地址，也就是：你的Github用名.github.io，即可看到你本地的hexo项目已经被部署到github上去了。此时博客的默认主题是landscape，即上面本地测试时的样子。</p>
<p>至此，基于Github Pages和Hexo的博客就已经搭建完毕了，至于Hexo站点的配置、主题配置和使用内容甚多，还需要再以后慢慢学习。我的第一篇博客的搭建就讲解到这了。</p>
]]></content>
      <categories>
        <category>Hexo</category>
      </categories>
  </entry>
</search>
